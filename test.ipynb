{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d8e98dbe",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "d8e98dbe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup envoirement"
      ],
      "metadata": {
        "id": "G6wFF41DtQ4b"
      },
      "id": "G6wFF41DtQ4b"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device in uso:\", device)"
      ],
      "metadata": {
        "id": "kGMl6Pu2rSYk",
        "outputId": "880ebfbc-6645-4f97-c05e-8427c503e2b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kGMl6Pu2rSYk",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device in uso: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rbghhrvbrkuF",
        "outputId": "f96df1b8-0bda-43bc-a183-d7946a315214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rbghhrvbrkuF",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "UtEsNOoRtWa2"
      },
      "id": "UtEsNOoRtWa2"
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = \"/content/drive/MyDrive/AML_MistakeDetection_DATA/features/gopro/segments/1s/video/omnivore.zip\"\n",
        "extract_dir = \"/content/omnivore_extracted\"\n",
        "\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "extract_dir = \"/content/omnivore_extracted/omnivore\"\n",
        "\n",
        "print(\"Extracted files:\", len(os.listdir(extract_dir)))"
      ],
      "metadata": {
        "id": "EfekzBNAtZ_S",
        "outputId": "6708b2fd-7f99-4528-e353-0294d7c43749",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EfekzBNAtZ_S",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: 384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/drive/MyDrive/AML_MistakeDetection_DATA/annotation_json/complete_step_annotations.json\") as f:\n",
        "    annotations = json.load(f)"
      ],
      "metadata": {
        "id": "G7sq4nHfy-AZ"
      },
      "id": "G7sq4nHfy-AZ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoFeatureDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "e8N7MZHSuh4N"
      },
      "id": "e8N7MZHSuh4N",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels_for_npz(npz_file, annotations):\n",
        "    # es: \"10_3_360.mp4_1s_1s.npz\"\n",
        "    base = os.path.basename(npz_file)\n",
        "    activity, attempt = base.split(\"_\")[:2]  # \"10\", \"3\"\n",
        "    recording_id = f\"{activity}_{attempt}\"\n",
        "\n",
        "    # carica feature\n",
        "    data = np.load(npz_file)\n",
        "    arr = data[list(data.keys())[0]]  # shape (N, 400)\n",
        "    N = arr.shape[0]\n",
        "\n",
        "    labels = np.zeros(N, dtype=np.int64)  # default: no-error = 0\n",
        "\n",
        "    # trova annotation di questo recording\n",
        "    info = annotations[recording_id]\n",
        "    steps = info[\"steps\"]\n",
        "\n",
        "    # assegnazione label per ogni secondo\n",
        "    for step in steps:\n",
        "        has_error = int(step[\"has_errors\"])  # True→1, False→0\n",
        "        start = step[\"start_time\"]\n",
        "        end   = step[\"end_time\"]\n",
        "\n",
        "        if start == -1 or end == -1 or has_error == 0:\n",
        "            continue\n",
        "\n",
        "        for sec in range(int(start), int(end) + 1, 1):\n",
        "            sec_start = sec\n",
        "            sec_end   = sec + 1\n",
        "\n",
        "            # check overlap\n",
        "            if sec_start >= start and sec_end <= end:\n",
        "                labels[sec] = has_error\n",
        "\n",
        "    return arr, labels"
      ],
      "metadata": {
        "id": "TAUlHVSAykFa"
      },
      "id": "TAUlHVSAykFa",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "extract_dir = \"/content/omnivore_extracted/omnivore\"\n",
        "\n",
        "for f in sorted(os.listdir(extract_dir)):\n",
        "    if f.endswith(\".npz\"):\n",
        "        X, y = get_labels_for_npz(os.path.join(extract_dir, f), annotations)\n",
        "        all_X.append(X)\n",
        "        all_y.append(y)\n",
        "\n",
        "X = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "print(X.shape, y.shape)\n"
      ],
      "metadata": {
        "id": "w6VeoKhMuHuZ",
        "outputId": "fc55de05-7735-4aa7-af82-8accfe1d9694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "w6VeoKhMuHuZ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(340320, 1024) (340320,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "metadata": {
        "id": "DZDtlZE8up0H"
      },
      "id": "DZDtlZE8up0H",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = VideoFeatureDataset(X_train, y_train)\n",
        "test_dataset  = VideoFeatureDataset(X_test,  y_test)"
      ],
      "metadata": {
        "id": "WprZqP5g-zGI",
        "outputId": "45dcbb8f-bef9-495c-cb27-56b8bb157906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "id": "WprZqP5g-zGI",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected np.ndarray (got list)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-973345401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFeatureDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataset\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mVideoFeatureDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1626272719.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVideoFeatureDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got list)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataset = Dataset(train_data)\n",
        "test_dataset = Dataset(test_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "FQ-eX8oeuwVg"
      },
      "id": "FQ-eX8oeuwVg",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "SigNHU8ctaWJ"
      },
      "id": "SigNHU8ctaWJ"
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPCapitainCook(nn.Module):\n",
        "  def __init__(self, in_features: int) -> None:\n",
        "    super(MLPCapitainCook, self).__init__()\n",
        "    self.fc1 = nn.Linear(in_features, 256)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(256, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.fc1(x))\n",
        "    return self.sigmoid(self.fc2(x))"
      ],
      "metadata": {
        "id": "O74QGf1Qo2sK"
      },
      "id": "O74QGf1Qo2sK",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLPCapitainCook(1024).to(device)"
      ],
      "metadata": {
        "id": "UWoFzaKgp-I_"
      },
      "id": "UWoFzaKgp-I_",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "criterion = nn.BCELoss(torch.tensor([1, 1.5]))\n",
        "epochs = 1"
      ],
      "metadata": {
        "id": "6FdOuKJopr3m"
      },
      "id": "6FdOuKJopr3m",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "\n",
        "for t in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {t+1}/{epochs} - Train Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "4u_a6jPgq7OI"
      },
      "id": "4u_a6jPgq7OI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}