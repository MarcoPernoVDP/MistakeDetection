{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZjzMZ7aErcr"
      },
      "source": [
        "# RUNNARE SOLO SU COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6RX9Vq-icJw",
        "outputId": "4c4242c2-71a7-4c5d-c597-cc3d0dd964f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:10\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "# 1. Installa Conda su Colab\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FeL4K0H9i3y1",
        "outputId": "4fd5ebfc-f406-433d-e7af-ad5bce5c077c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n",
            "Cloning into 'EgoVLP'...\n",
            "remote: Enumerating objects: 268, done.\u001b[K\n",
            "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
            "remote: Compressing objects: 100% (111/111), done.\u001b[K\n",
            "remote: Total 268 (delta 85), reused 100 (delta 47), pack-reused 109 (from 1)\u001b[K\n",
            "Receiving objects: 100% (268/268), 2.00 MiB | 26.61 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n",
            "/content/EgoVLP\n",
            "Channels:\n",
            " - pytorch\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=11.3\n",
            "    - pytorch\n",
            "    - torchaudio\n",
            "    - torchvision\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-4.5          |       7_kmp_llvm           8 KB  conda-forge\n",
            "    aom-3.6.1                  |       h59595ed_0         2.6 MB  conda-forge\n",
            "    blas-2.116                 |              mkl          13 KB  conda-forge\n",
            "    blas-devel-3.9.0           |   16_linux64_mkl          12 KB  conda-forge\n",
            "    ca-certificates-2025.11.12 |       hbd8a1cb_0         149 KB  conda-forge\n",
            "    certifi-2025.11.12         |     pyhd8ed1ab_0         153 KB  conda-forge\n",
            "    conda-24.11.3              |  py311h38be061_0         1.1 MB  conda-forge\n",
            "    cpython-3.11.14            |  py311hd8ed1ab_2          46 KB  conda-forge\n",
            "    cudatoolkit-11.3.1         |      hb98b00a_13       603.5 MB  conda-forge\n",
            "    ffmpeg-4.4.2               | gpl_hdf48244_113         9.0 MB  conda-forge\n",
            "    filelock-3.20.1            |     pyhd8ed1ab_0          18 KB  conda-forge\n",
            "    font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge\n",
            "    font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge\n",
            "    font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge\n",
            "    font-ttf-ubuntu-0.83       |       h77eed37_3         1.5 MB  conda-forge\n",
            "    fontconfig-2.15.0          |       h7e30c49_1         259 KB  conda-forge\n",
            "    fonts-conda-ecosystem-1    |                0           4 KB  conda-forge\n",
            "    fonts-conda-forge-1        |       hc364b38_1           4 KB  conda-forge\n",
            "    freetype-2.14.1            |       ha770c72_0         169 KB  conda-forge\n",
            "    giflib-5.2.2               |       hd590300_0          75 KB  conda-forge\n",
            "    gmp-6.3.0                  |       hac33072_2         449 KB  conda-forge\n",
            "    gmpy2-2.2.1                |  py311h92a432a_2         198 KB  conda-forge\n",
            "    gnutls-3.7.9               |       hb077bed_0         1.9 MB  conda-forge\n",
            "    jinja2-3.1.6               |     pyhcf101f3_1         118 KB  conda-forge\n",
            "    lame-3.100                 |    h166bdaf_1003         496 KB  conda-forge\n",
            "    lcms2-2.17                 |       h717163a_0         242 KB  conda-forge\n",
            "    lerc-4.0.0                 |       h0aef613_1         258 KB  conda-forge\n",
            "    libblas-3.9.0              |   16_linux64_mkl          13 KB  conda-forge\n",
            "    libcblas-3.9.0             |   16_linux64_mkl          12 KB  conda-forge\n",
            "    libdeflate-1.23            |       h86f0d12_0          71 KB  conda-forge\n",
            "    libdrm-2.4.125             |       hb03c661_1         304 KB  conda-forge\n",
            "    libegl-1.7.0               |       ha4b6fd6_2          44 KB  conda-forge\n",
            "    libfreetype-2.14.1         |       ha770c72_0           7 KB  conda-forge\n",
            "    libfreetype6-2.14.1        |       h73754d4_0         378 KB  conda-forge\n",
            "    libgfortran-14.2.0         |       h69a702a_2          52 KB  conda-forge\n",
            "    libgfortran-ng-14.2.0      |       h69a702a_2          53 KB  conda-forge\n",
            "    libgfortran5-14.2.0        |       hf1ad2bd_2         1.4 MB  conda-forge\n",
            "    libgl-1.7.0                |       ha4b6fd6_2         132 KB  conda-forge\n",
            "    libglvnd-1.7.0             |       ha4b6fd6_2         129 KB  conda-forge\n",
            "    libglx-1.7.0               |       ha4b6fd6_2          74 KB  conda-forge\n",
            "    libhwloc-2.11.2            |default_h0d58e46_1001         2.3 MB  conda-forge\n",
            "    libidn2-2.3.8              |       hfac485b_1         136 KB  conda-forge\n",
            "    libjpeg-turbo-3.1.2        |       hb03c661_0         619 KB  conda-forge\n",
            "    liblapack-3.9.0            |   16_linux64_mkl          12 KB  conda-forge\n",
            "    liblapacke-3.9.0           |   16_linux64_mkl          12 KB  conda-forge\n",
            "    libpciaccess-0.18          |       hb9d3cd8_0          28 KB  conda-forge\n",
            "    libpng-1.6.53              |       h421ea60_0         310 KB  conda-forge\n",
            "    libtasn1-4.20.0            |       hb03c661_1         115 KB  conda-forge\n",
            "    libtiff-4.7.0              |       hd9ff511_3         418 KB  conda-forge\n",
            "    libunistring-0.9.10        |       h7f98852_0         1.4 MB  conda-forge\n",
            "    libva-2.22.0               |       h4f16b4b_2         212 KB  conda-forge\n",
            "    libvpx-1.13.1              |       h59595ed_0         982 KB  conda-forge\n",
            "    libwebp-1.6.0              |       h9635ea4_0          92 KB  conda-forge\n",
            "    libwebp-base-1.6.0         |       hd42ef1d_0         419 KB  conda-forge\n",
            "    libxcb-1.17.0              |       h8a09558_0         387 KB  conda-forge\n",
            "    llvm-openmp-15.0.7         |       h0cdce71_0         3.1 MB  conda-forge\n",
            "    markupsafe-3.0.3           |  py311h3778330_0          25 KB  conda-forge\n",
            "    mkl-2022.1.0               |     h84fe81f_915       199.6 MB  conda-forge\n",
            "    mkl-devel-2022.1.0         |     ha770c72_916          25 KB  conda-forge\n",
            "    mkl-include-2022.1.0       |     h84fe81f_915         745 KB  conda-forge\n",
            "    mpc-1.3.1                  |       h24ddda3_1         114 KB  conda-forge\n",
            "    mpfr-4.2.1                 |       h90cbb55_3         620 KB  conda-forge\n",
            "    mpmath-1.3.0               |     pyhd8ed1ab_1         429 KB  conda-forge\n",
            "    nettle-3.9.1               |       h7ab15ed_0         988 KB  conda-forge\n",
            "    networkx-3.6.1             |     pyhcf101f3_0         1.5 MB  conda-forge\n",
            "    numpy-2.3.5                |  py311h2e04523_0         9.0 MB  conda-forge\n",
            "    openh264-2.3.1             |       hcb278e6_2         702 KB  conda-forge\n",
            "    openjpeg-2.5.3             |       h55fea9a_1         349 KB  conda-forge\n",
            "    openssl-3.6.0              |       h26f9b46_0         3.0 MB  conda-forge\n",
            "    p11-kit-0.24.1             |       hc5aa10d_0         4.5 MB  conda-forge\n",
            "    pillow-11.3.0              |  py311h98278a2_3        1021 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    hb9d3cd8_1002           8 KB  conda-forge\n",
            "    pytorch-2.5.1              |     py3.11_cpu_0        92.0 MB  pytorch\n",
            "    pytorch-mutex-1.0          |              cpu           3 KB  pytorch\n",
            "    pyyaml-6.0.3               |  py311h3778330_0         207 KB  conda-forge\n",
            "    svt-av1-1.4.1              |       hcb278e6_0         2.4 MB  conda-forge\n",
            "    sympy-1.14.0               |   pyh2585a3b_105         4.4 MB  conda-forge\n",
            "    tbb-2021.13.0              |       hceb3a55_1         172 KB  conda-forge\n",
            "    torchaudio-2.5.1           |        py311_cpu         5.1 MB  pytorch\n",
            "    torchvision-0.20.1         |        py311_cpu         7.1 MB  pytorch\n",
            "    typing_extensions-4.15.0   |     pyhcf101f3_0          50 KB  conda-forge\n",
            "    wayland-1.23.1             |       h3e06ad9_0         314 KB  conda-forge\n",
            "    wayland-protocols-1.47     |       hd8ed1ab_0         137 KB  conda-forge\n",
            "    x264-1!164.3095            |       h166bdaf_2         877 KB  conda-forge\n",
            "    x265-3.5                   |       h924138e_3         3.2 MB  conda-forge\n",
            "    xorg-libx11-1.8.12         |       h4f16b4b_0         816 KB  conda-forge\n",
            "    xorg-libxau-1.0.12         |       hb03c661_1          15 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.5        |       hb03c661_1          20 KB  conda-forge\n",
            "    xorg-libxext-1.3.6         |       hb9d3cd8_0          49 KB  conda-forge\n",
            "    xorg-libxfixes-6.0.2       |       hb03c661_0          20 KB  conda-forge\n",
            "    yaml-0.2.5                 |       h280c20c_3          83 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       976.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  aom                conda-forge/linux-64::aom-3.6.1-h59595ed_0 \n",
            "  blas               conda-forge/linux-64::blas-2.116-mkl \n",
            "  blas-devel         conda-forge/linux-64::blas-devel-3.9.0-16_linux64_mkl \n",
            "  cpython            conda-forge/noarch::cpython-3.11.14-py311hd8ed1ab_2 \n",
            "  cudatoolkit        conda-forge/linux-64::cudatoolkit-11.3.1-hb98b00a_13 \n",
            "  ffmpeg             conda-forge/linux-64::ffmpeg-4.4.2-gpl_hdf48244_113 \n",
            "  filelock           conda-forge/noarch::filelock-3.20.1-pyhd8ed1ab_0 \n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 \n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.15.0-h7e30c49_1 \n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-hc364b38_1 \n",
            "  freetype           conda-forge/linux-64::freetype-2.14.1-ha770c72_0 \n",
            "  giflib             conda-forge/linux-64::giflib-5.2.2-hd590300_0 \n",
            "  gmp                conda-forge/linux-64::gmp-6.3.0-hac33072_2 \n",
            "  gmpy2              conda-forge/linux-64::gmpy2-2.2.1-py311h92a432a_2 \n",
            "  gnutls             conda-forge/linux-64::gnutls-3.7.9-hb077bed_0 \n",
            "  jinja2             conda-forge/noarch::jinja2-3.1.6-pyhcf101f3_1 \n",
            "  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003 \n",
            "  lcms2              conda-forge/linux-64::lcms2-2.17-h717163a_0 \n",
            "  lerc               conda-forge/linux-64::lerc-4.0.0-h0aef613_1 \n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-16_linux64_mkl \n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-16_linux64_mkl \n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.23-h86f0d12_0 \n",
            "  libdrm             conda-forge/linux-64::libdrm-2.4.125-hb03c661_1 \n",
            "  libegl             conda-forge/linux-64::libegl-1.7.0-ha4b6fd6_2 \n",
            "  libfreetype        conda-forge/linux-64::libfreetype-2.14.1-ha770c72_0 \n",
            "  libfreetype6       conda-forge/linux-64::libfreetype6-2.14.1-h73754d4_0 \n",
            "  libgfortran        conda-forge/linux-64::libgfortran-14.2.0-h69a702a_2 \n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-14.2.0-h69a702a_2 \n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-14.2.0-hf1ad2bd_2 \n",
            "  libgl              conda-forge/linux-64::libgl-1.7.0-ha4b6fd6_2 \n",
            "  libglvnd           conda-forge/linux-64::libglvnd-1.7.0-ha4b6fd6_2 \n",
            "  libglx             conda-forge/linux-64::libglx-1.7.0-ha4b6fd6_2 \n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.11.2-default_h0d58e46_1001 \n",
            "  libidn2            conda-forge/linux-64::libidn2-2.3.8-hfac485b_1 \n",
            "  libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-3.1.2-hb03c661_0 \n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-16_linux64_mkl \n",
            "  liblapacke         conda-forge/linux-64::liblapacke-3.9.0-16_linux64_mkl \n",
            "  libpciaccess       conda-forge/linux-64::libpciaccess-0.18-hb9d3cd8_0 \n",
            "  libpng             conda-forge/linux-64::libpng-1.6.53-h421ea60_0 \n",
            "  libtasn1           conda-forge/linux-64::libtasn1-4.20.0-hb03c661_1 \n",
            "  libtiff            conda-forge/linux-64::libtiff-4.7.0-hd9ff511_3 \n",
            "  libunistring       conda-forge/linux-64::libunistring-0.9.10-h7f98852_0 \n",
            "  libva              conda-forge/linux-64::libva-2.22.0-h4f16b4b_2 \n",
            "  libvpx             conda-forge/linux-64::libvpx-1.13.1-h59595ed_0 \n",
            "  libwebp            conda-forge/linux-64::libwebp-1.6.0-h9635ea4_0 \n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.6.0-hd42ef1d_0 \n",
            "  libxcb             conda-forge/linux-64::libxcb-1.17.0-h8a09558_0 \n",
            "  llvm-openmp        conda-forge/linux-64::llvm-openmp-15.0.7-h0cdce71_0 \n",
            "  markupsafe         conda-forge/linux-64::markupsafe-3.0.3-py311h3778330_0 \n",
            "  mkl                conda-forge/linux-64::mkl-2022.1.0-h84fe81f_915 \n",
            "  mkl-devel          conda-forge/linux-64::mkl-devel-2022.1.0-ha770c72_916 \n",
            "  mkl-include        conda-forge/linux-64::mkl-include-2022.1.0-h84fe81f_915 \n",
            "  mpc                conda-forge/linux-64::mpc-1.3.1-h24ddda3_1 \n",
            "  mpfr               conda-forge/linux-64::mpfr-4.2.1-h90cbb55_3 \n",
            "  mpmath             conda-forge/noarch::mpmath-1.3.0-pyhd8ed1ab_1 \n",
            "  nettle             conda-forge/linux-64::nettle-3.9.1-h7ab15ed_0 \n",
            "  networkx           conda-forge/noarch::networkx-3.6.1-pyhcf101f3_0 \n",
            "  numpy              conda-forge/linux-64::numpy-2.3.5-py311h2e04523_0 \n",
            "  openh264           conda-forge/linux-64::openh264-2.3.1-hcb278e6_2 \n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.5.3-h55fea9a_1 \n",
            "  p11-kit            conda-forge/linux-64::p11-kit-0.24.1-hc5aa10d_0 \n",
            "  pillow             conda-forge/linux-64::pillow-11.3.0-py311h98278a2_3 \n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-hb9d3cd8_1002 \n",
            "  pytorch            pytorch/linux-64::pytorch-2.5.1-py3.11_cpu_0 \n",
            "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cpu \n",
            "  pyyaml             conda-forge/linux-64::pyyaml-6.0.3-py311h3778330_0 \n",
            "  svt-av1            conda-forge/linux-64::svt-av1-1.4.1-hcb278e6_0 \n",
            "  sympy              conda-forge/noarch::sympy-1.14.0-pyh2585a3b_105 \n",
            "  tbb                conda-forge/linux-64::tbb-2021.13.0-hceb3a55_1 \n",
            "  torchaudio         pytorch/linux-64::torchaudio-2.5.1-py311_cpu \n",
            "  torchvision        pytorch/linux-64::torchvision-0.20.1-py311_cpu \n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.15.0-pyhcf101f3_0 \n",
            "  wayland            conda-forge/linux-64::wayland-1.23.1-h3e06ad9_0 \n",
            "  wayland-protocols  conda-forge/noarch::wayland-protocols-1.47-hd8ed1ab_0 \n",
            "  x264               conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 \n",
            "  x265               conda-forge/linux-64::x265-3.5-h924138e_3 \n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.12-h4f16b4b_0 \n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.12-hb03c661_1 \n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.5-hb03c661_1 \n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.6-hb9d3cd8_0 \n",
            "  xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-6.0.2-hb03c661_0 \n",
            "  yaml               conda-forge/linux-64::yaml-0.2.5-h280c20c_3 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates~ --> conda-forge/noarch::ca-certificates-2025.11.12-hbd8a1cb_0 \n",
            "  certifi                           2024.12.14-pyhd8ed1ab_0 --> 2025.11.12-pyhd8ed1ab_0 \n",
            "  conda                             24.11.2-py311h38be061_1 --> 24.11.3-py311h38be061_0 \n",
            "  openssl                                  3.4.0-h7b32b05_1 --> 3.6.0-h26f9b46_0 \n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-7_kmp_llvm \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   0% 0/1 [00:00<?, ?it/s]\n",
            "mkl-2022.1.0         | 199.6 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ffmpeg-4.4.2         | 9.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.3.5          | 9.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.20.1   | 7.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.5.1     | 5.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "p11-kit-0.24.1       | 4.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.6.0        | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aom-3.6.1            | 2.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "svt-av1-1.4.1        | 2.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gnutls-3.7.9         | 1.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.6.1       | 1.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   0% 7.766791050253607e-05/1 [00:00<21:30, 1290.89s/it]\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :   1% 0.007132396488350293/1 [00:00<00:13, 14.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ffmpeg-4.4.2         | 9.0 MB    | :   5% 0.05026631936763393/1 [00:00<00:01,  1.99s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.3.5          | 9.0 MB    | :   4% 0.03640449338339149/1 [00:00<00:02,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   1% 0.006316990054206267/1 [00:00<00:26, 27.05s/it]   \n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :   5% 0.05196460298655214/1 [00:00<00:03,  3.42s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ffmpeg-4.4.2         | 9.0 MB    | :  49% 0.49226326553131156/1 [00:00<00:00,  2.80it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.3.5          | 9.0 MB    | :  46% 0.4559229409443791/1 [00:00<00:00,  2.61it/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   1% 0.013307101999434513/1 [00:00<00:18, 19.25s/it]\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  10% 0.09628735259272897/1 [00:00<00:02,  2.77s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ffmpeg-4.4.2         | 9.0 MB    | :  88% 0.8839938923273553/1 [00:00<00:00,  3.31it/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.3.5          | 9.0 MB    | :  89% 0.8893097669371349/1 [00:00<00:00,  3.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   2% 0.02179879354771179/1 [00:00<00:15, 15.46s/it] \n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  14% 0.1436668435510559/1 [00:00<00:02,  2.47s/it] \u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   3% 0.029669141811968777/1 [00:00<00:14, 14.50s/it]\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  19% 0.19444271378954966/1 [00:00<00:01,  2.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ffmpeg-4.4.2         | 9.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.31it/s]               \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.3.5          | 9.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.40it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :   7% 0.07122565395046718/1 [00:00<00:06,  6.55s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.20.1   | 7.1 MB    | :   0% 0.0021898511679094845/1 [00:00<04:35, 276.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   4% 0.036581585846694485/1 [00:00<00:14, 15.57s/it]\n",
            "mkl-2022.1.0         | 199.6 MB  | :   9% 0.09157584079345779/1 [00:00<00:05,  5.92s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.20.1   | 7.1 MB    | :  44% 0.44234993591771593/1 [00:00<00:00,  1.19s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.5.1     | 5.1 MB    | :   0% 0.0030817255405904105/1 [00:00<03:52, 232.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  28% 0.2795220147577282/1 [00:00<00:01,  2.53s/it] \u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   4% 0.04305391172190583/1 [00:00<00:17, 18.16s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.20.1   | 7.1 MB    | :  72% 0.7248407365780395/1 [00:00<00:00,  1.27it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   5% 0.04880133709909349/1 [00:00<00:17, 18.44s/it]\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  32% 0.31942947129968813/1 [00:00<00:01,  2.92s/it]\u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :  13% 0.1254667288819768/1 [00:00<00:05,  6.56s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.5.1     | 5.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.43it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   5% 0.05436753735177524/1 [00:01<00:18, 19.55s/it]\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  35% 0.35492163477743127/1 [00:01<00:01,  3.09s/it]\u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :  14% 0.14104244881180422/1 [00:01<00:06,  7.24s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.20.1   | 7.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.22it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.20.1   | 7.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "p11-kit-0.24.1       | 4.5 MB    | :   0% 0.0034841064226090947/1 [00:01<04:59, 301.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | :   0% 0.0035489159712265746/1 [00:01<05:06, 307.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   6% 0.059597176658946004/1 [00:01<00:18, 19.96s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "p11-kit-0.24.1       | 4.5 MB    | :  73% 0.7281782423253008/1 [00:01<00:00,  1.15s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :  16% 0.15528757960189765/1 [00:01<00:06,  7.99s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   6% 0.06469736944861254/1 [00:01<00:19, 20.91s/it] \n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  43% 0.4294721599770927/1 [00:01<00:01,  3.26s/it] \u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :  17% 0.16953271039199108/1 [00:01<00:06,  7.72s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   7% 0.06953866920327062/1 [00:01<00:20, 21.67s/it]\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  46% 0.46122830624665234/1 [00:01<00:01,  3.51s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | :   0% 0.004880274801411181/1 [00:01<04:43, 284.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :  18% 0.18291687173872723/1 [00:01<00:06,  8.12s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | : 100% 1.0/1 [00:01<00:00,  1.01s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   7% 0.07419874383342279/1 [00:01<00:20, 21.73s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | :   1% 0.005012289041185573/1 [00:01<04:48, 290.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | :  75% 0.7466820446159107/1 [00:01<00:00,  1.44s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  49% 0.4906069870200952/1 [00:01<00:01,  3.61s/it] \u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   8% 0.07932482592659017/1 [00:01<00:19, 21.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | :  84% 0.8420645589191762/1 [00:01<00:00,  1.33s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.44s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  52% 0.518966754009488/1 [00:01<00:01,  3.65s/it] \u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :  21% 0.2105461638755568/1 [00:01<00:06,  8.02s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.33s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   8% 0.08455446523376092/1 [00:01<00:18, 20.49s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aom-3.6.1            | 2.6 MB    | :   1% 0.006117429708738807/1 [00:01<04:36, 278.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  55% 0.548345434782931/1 [00:01<00:01,  3.59s/it]\u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :  23% 0.227295933046326/1 [00:01<00:05,  7.36s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   9% 0.08947343289892154/1 [00:01<00:19, 21.72s/it]\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  58% 0.5829885034406324/1 [00:01<00:01,  3.37s/it]\u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :  24% 0.24122798403883497/1 [00:01<00:05,  7.46s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.6.0        | 3.0 MB    | : 100% 1.0/1 [00:01<00:00,  1.40s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aom-3.6.1            | 2.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.34s/it]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :   9% 0.0941335075290737/1 [00:01<00:19, 21.85s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "svt-av1-1.4.1        | 2.4 MB    | :   1% 0.006584708798246436/1 [00:01<04:45, 287.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | :   1% 0.006761307362165732/1 [00:01<04:39, 280.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  62% 0.615763563494242/1 [00:01<00:01,  3.28s/it] \u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  10% 0.09889713937322925/1 [00:01<00:19, 21.61s/it]\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  65% 0.6505764511159517/1 [00:02<00:01,  3.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | : 100% 1.0/1 [00:02<00:00,  1.47s/it]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | : 100% 1.0/1 [00:02<00:00,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  10% 0.10355721400338141/1 [00:02<00:19, 21.59s/it]\n",
            "\n",
            "\n",
            "ffmpeg-4.4.2         | 9.0 MB    | : 100% 1.0/1 [00:02<00:00,  3.31it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "svt-av1-1.4.1        | 2.4 MB    | : 100% 1.0/1 [00:02<00:00,  1.53s/it]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "svt-av1-1.4.1        | 2.4 MB    | : 100% 1.0/1 [00:02<00:00,  1.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gnutls-3.7.9         | 1.9 MB    | :   1% 0.0082959692344305/1 [00:02<04:10, 252.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  69% 0.6867478904497283/1 [00:02<00:00,  3.05s/it]\u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :  29% 0.28865957337288234/1 [00:02<00:04,  6.80s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  11% 0.10894218913155725/1 [00:02<00:18, 20.84s/it]\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  73% 0.728013898703755/1 [00:02<00:00,  2.84s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gnutls-3.7.9         | 1.9 MB    | : 100% 1.0/1 [00:02<00:00,  1.62s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gnutls-3.7.9         | 1.9 MB    | : 100% 1.0/1 [00:02<00:00,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "mkl-2022.1.0         | 199.6 MB  | :  30% 0.30368740365693697/1 [00:02<00:04,  7.03s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | : 100% 1.0/1 [00:02<00:00,  1.63s/it]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  11% 0.11375759958271449/1 [00:02<00:18, 21.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.6.1       | 1.5 MB    | :   1% 0.01032102650873514/1 [00:02<03:39, 221.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | :   1% 0.011206734985068174/1 [00:02<03:24, 206.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  76% 0.7635060621814981/1 [00:02<00:00,  3.10s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  12% 0.11852123142687003/1 [00:02<00:19, 21.63s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.6.1       | 1.5 MB    | : 100% 1.0/1 [00:02<00:00,  1.72s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.6.1       | 1.5 MB    | : 100% 1.0/1 [00:02<00:00,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | : 100% 1.0/1 [00:02<00:00, 206.68s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  80% 0.7964509411991161/1 [00:02<00:00,  3.21s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  12% 0.12315541675352135/1 [00:02<00:19, 22.09s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  83% 0.8282070874686758/1 [00:02<00:00,  3.27s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  13% 0.12892873143420985/1 [00:02<00:17, 20.48s/it]\n",
            "\n",
            "pytorch-2.5.1        | 92.0 MB   | :  87% 0.8679447250466275/1 [00:02<00:00,  3.02s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  13% 0.13384769909937047/1 [00:02<00:18, 21.42s/it]\n",
            "mkl-2022.1.0         | 199.6 MB  | :  38% 0.38375756188916543/1 [00:02<00:04,  6.51s/it]\u001b[A\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  14% 0.1401387998500759/1 [00:02<00:16, 19.52s/it] \n",
            "mkl-2022.1.0         | 199.6 MB  | :  40% 0.4005856010093307/1 [00:02<00:03,  6.34s/it] \u001b[A\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  15% 0.14632634338677794/1 [00:02<00:15, 18.43s/it]\n",
            "mkl-2022.1.0         | 199.6 MB  | :  42% 0.41647440073674263/1 [00:03<00:03,  6.43s/it]\u001b[A\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  15% 0.15181487572895716/1 [00:03<00:16, 19.17s/it]\n",
            "mkl-2022.1.0         | 199.6 MB  | :  43% 0.4321283906159662/1 [00:03<00:03,  6.51s/it] \u001b[A\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  16% 0.1580024192656592/1 [00:03<00:15, 18.24s/it] \n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  16% 0.16354273021484012/1 [00:03<00:15, 18.38s/it]\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  17% 0.16962671653753877/1 [00:05<01:31, 109.82s/it]\n",
            "mkl-2022.1.0         | 199.6 MB  | :  46% 0.4620275112852832/1 [00:05<00:22, 42.49s/it]\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  17% 0.17356189066966726/1 [00:05<01:50, 133.31s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  18% 0.18272670410896652/1 [00:06<01:06, 80.98s/it] \n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  19% 0.19101128122923702/1 [00:06<00:45, 56.56s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  20% 0.19994309093702867/1 [00:06<00:32, 40.54s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  21% 0.2081758894502975/1 [00:06<00:24, 31.57s/it] \n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  22% 0.21609801632155617/1 [00:06<00:20, 25.81s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  22% 0.22345057851579625/1 [00:06<00:17, 22.32s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  23% 0.2315798198150617/1 [00:06<00:14, 19.20s/it] \n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  24% 0.241573090966388/1 [00:06<00:12, 15.95s/it] \n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  25% 0.24988355739015936/1 [00:06<00:11, 14.85s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  26% 0.25850469545594085/1 [00:06<00:10, 13.87s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  27% 0.2681096270547545/1 [00:07<00:09, 12.75s/it] \n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  28% 0.2797080350231332/1 [00:07<00:08, 11.28s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  29% 0.2897530847814612/1 [00:07<00:07, 10.95s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  30% 0.3005748136448146/1 [00:07<00:07, 10.43s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  31% 0.31054219549264/1 [00:07<00:08, 12.80s/it]  \n",
            "\n",
            "\n",
            "\n",
            "numpy-2.3.5          | 9.0 MB    | : 100% 1.0/1 [00:07<00:00,  3.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  32% 0.3191633335584215/1 [00:07<00:08, 12.83s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  33% 0.32900126888874276/1 [00:07<00:08, 12.11s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  34% 0.33966766193109105/1 [00:07<00:07, 11.23s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  58% 0.5754156596097888/1 [00:09<00:04,  9.47s/it]\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  61% 0.6132917106315255/1 [00:12<00:12, 33.40s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  72% 0.7158133524948732/1 [00:12<00:02,  9.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  91% 0.9103714683037261/1 [00:14<00:00,  6.50s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  94% 0.941697525539749/1 [00:14<00:00,  6.52s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  96% 0.9572311076402561/1 [00:14<00:00,  6.89s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  97% 0.9719621213322371/1 [00:14<00:00,  6.97s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | :  99% 0.9870814745767308/1 [00:14<00:00,  6.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.6.0        | 3.0 MB    | : 100% 1.0/1 [00:14<00:00,  1.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "svt-av1-1.4.1        | 2.4 MB    | : 100% 1.0/1 [00:14<00:00,  1.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.11.2      | 2.3 MB    | : 100% 1.0/1 [00:15<00:00,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | : 100% 1.0/1 [00:15<00:00,  1.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "networkx-3.6.1       | 1.5 MB    | : 100% 1.0/1 [00:15<00:00,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | : 100% 1.0/1 [00:16<00:00, 15.46s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | : 100% 1.0/1 [00:16<00:00, 15.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gnutls-3.7.9         | 1.9 MB    | : 100% 1.0/1 [00:16<00:00,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | : 100% 1.0/1 [00:20<00:00,  6.86s/it]               \n",
            "\n",
            "cudatoolkit-11.3.1   | 603.5 MB  | : 100% 1.0/1 [01:10<00:00,  6.86s/it]\n",
            "mkl-2022.1.0         | 199.6 MB  | : 100% 1.0/1 [01:18<00:00,  3.53s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Installazione dipendenze Python...\n",
            "Collecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting decord\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Collecting h5py\n",
            "  Downloading h5py-3.15.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting regex\n",
            "  Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (4.67.1)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.11/site-packages (from timm==0.4.12) (2.5.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/site-packages (from timm==0.4.12) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.20.1)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2.3.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting wcwidth (from ftfy)\n",
            "  Downloading wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
            "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting sympy==1.13.1 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.4->timm==0.4.12) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.4->timm==0.4.12) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.4->timm==0.4.12) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from torchvision->timm==0.4.12) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.4->timm==0.4.12) (3.0.3)\n",
            "Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m155.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m144.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m153.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.15.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m800.4/800.4 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m158.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m149.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "Downloading wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\n",
            "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, wcwidth, tzdata, sympy, six, safetensors, regex, numpy, hf-xet, fsspec, python-dateutil, opencv-python, huggingface-hub, h5py, ftfy, decord, tokenizers, pandas, transformers, timm\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.5\n",
            "    Uninstalling numpy-2.3.5:\n",
            "      Successfully uninstalled numpy-2.3.5\n",
            "Successfully installed decord-0.6.0 fsspec-2025.12.0 ftfy-6.3.1 h5py-3.15.1 hf-xet-1.2.0 huggingface-hub-0.36.0 numpy-2.2.6 opencv-python-4.12.0.88 pandas-2.3.3 python-dateutil-2.9.0.post0 pytz-2025.2 regex-2025.11.3 safetensors-0.7.0 six-1.17.0 sympy-1.13.1 timm-0.4.12 tokenizers-0.22.1 transformers-4.57.3 tzdata-2025.3 wcwidth-0.2.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "numpy",
                  "six",
                  "wcwidth"
                ]
              },
              "id": "e01d5e72f5d949c3936750555f753dfb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 2. Verifica Conda e Clona il Repo\n",
        "import condacolab\n",
        "condacolab.check()\n",
        "\n",
        "# Clona il repository ufficiale (se non esiste giÃ )\n",
        "import os\n",
        "if not os.path.exists(\"EgoVLP\"):\n",
        "    !git clone https://github.com/showlab/EgoVLP.git\n",
        "\n",
        "%cd EgoVLP\n",
        "\n",
        "# Installa le dipendenze richieste tramite Conda\n",
        "# Nota: PyTorch Ã¨ giÃ  stato parzialmente installato nel passaggio precedente, qui ci assicuriamo delle versioni\n",
        "!conda install -y pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
        "\n",
        "# --- FIX PER L'ERRORE TOKENIZERS ---\n",
        "# Rimuoviamo \"==4.12.5\" da transformers per lasciare che pip trovi una versione compatibile con Python 3.11\n",
        "# Rimuoviamo anche il blocco su timm se dovesse dare problemi, ma proviamo a mantenerlo per ora.\n",
        "print(\"Installazione dipendenze Python...\")\n",
        "!pip install timm==0.4.12 transformers decord pandas h5py ftfy regex tqdm opencv-python\n",
        "\n",
        "# Patch per il path\n",
        "import sys\n",
        "if \"/content/EgoVLP\" not in sys.path:\n",
        "    sys.path.append(\"/content/EgoVLP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fuM0Cp9istW",
        "outputId": "546b21eb-73b3-4752-ad1f-efe672c7a0d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "â¬‡ï¸ Download dei pesi EgoVLP_PT_BEST in corso...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-cP3Gcg0NGDcMZalgJ_615BQdbFIbcj7\n",
            "From (redirected): https://drive.google.com/uc?id=1-cP3Gcg0NGDcMZalgJ_615BQdbFIbcj7&confirm=t&uuid=37db45f9-ac8d-4f83-ad48-8f864c41d1b4\n",
            "To: /content/EgoVLP/pretrained/model.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.17G/2.17G [00:29<00:00, 73.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Pesi scaricati correttamente in pretrained/model.pth\n",
            "ðŸ“‚ Estrazione video da /content/drive/MyDrive/MistakeDetection/captain_cook_4d_gopro_resized_3.zip...\n",
            "âœ… Video estratti.\n"
          ]
        }
      ],
      "source": [
        "# 3. Preparazione Dati e Download Pesi Automatico\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import gdown # Libreria per scaricare da Google Drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- CONFIGURAZIONE PERCORSI ---\n",
        "# Dove si trova lo zip dei tuoi video su Drive (questo deve essere corretto!)\n",
        "PATH_ZIP_VIDEO = \"/content/drive/MyDrive/MistakeDetection/captain_cook_4d_gopro_resized_3.zip\"\n",
        "\n",
        "# Dove salvare lo zip finale delle features\n",
        "OUTPUT_ZIP_PATH = \"/content/drive/MyDrive/MistakeDetection/egovlp_3.zip\"\n",
        "# -------------------------------\n",
        "\n",
        "# 1. Setup Cartelle\n",
        "if not os.path.exists(\"pretrained\"):\n",
        "    os.makedirs(\"pretrained\")\n",
        "if not os.path.exists(\"data/videos\"):\n",
        "    os.makedirs(\"data/videos\")\n",
        "if not os.path.exists(\"data/features\"):\n",
        "    os.makedirs(\"data/features\")\n",
        "\n",
        "# 2. Download Automatico dei Pesi (EgoVLP_PT_BEST.pth)\n",
        "weights_path = \"pretrained/model.pth\"\n",
        "if not os.path.exists(weights_path):\n",
        "    print(\"â¬‡ï¸ Download dei pesi EgoVLP_PT_BEST in corso...\")\n",
        "    # ID del file ufficiale dal GitHub di EgoVLP\n",
        "    file_id = '1-cP3Gcg0NGDcMZalgJ_615BQdbFIbcj7'\n",
        "    url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "    try:\n",
        "        gdown.download(url, weights_path, quiet=False)\n",
        "        print(\"âœ… Pesi scaricati correttamente in pretrained/model.pth\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Errore nel download: {e}\")\n",
        "        print(\"Prova a scaricarli manualmente da: https://drive.google.com/file/d/1-cP3Gcg0NGDcMZalgJ_615BQdbFIbcj7/view\")\n",
        "else:\n",
        "    print(\"âœ… Pesi giÃ  presenti.\")\n",
        "\n",
        "# 3. Estrazione Video\n",
        "# Controlla se abbiamo giÃ  estratto per non rifarlo ogni volta\n",
        "if len(os.listdir(\"data/videos\")) < 5: # Se la cartella Ã¨ quasi vuota\n",
        "    if os.path.exists(PATH_ZIP_VIDEO):\n",
        "        print(f\"ðŸ“‚ Estrazione video da {PATH_ZIP_VIDEO}...\")\n",
        "        !unzip -q \"{PATH_ZIP_VIDEO}\" -d \"data/videos\"\n",
        "        print(\"âœ… Video estratti.\")\n",
        "    else:\n",
        "        print(f\"âŒ ERRORE: Non trovo il file zip dei video in: {PATH_ZIP_VIDEO}\")\n",
        "        print(\"Verifica il percorso nel tuo Google Drive!\")\n",
        "else:\n",
        "    print(\"âœ… Video giÃ  presenti in locale.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaj5kpsdrRr7",
        "outputId": "52dfbdeb-f0e6-4aec-c890-e5ab9d26b503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬‡ï¸ Download backbone ViT (richiesto dal codice originale)...\n",
            "--2025-12-20 09:48:06--  https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/huggingface/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth [following]\n",
            "--2025-12-20 09:48:07--  https://github.com/huggingface/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/168799526/65360900-1a09-11eb-8b86-f0a014a6f156?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-20T10%3A28%3A54Z&rscd=attachment%3B+filename%3Djx_vit_base_p16_224-80ecf9dd.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-20T09%3A28%3A51Z&ske=2025-12-20T10%3A28%3A54Z&sks=b&skv=2018-11-09&sig=TZuwEbRndh1dsNAIv2BMiEBIEa0ZduM1OLxLpSCep8s%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjIyNzY4NywibmJmIjoxNzY2MjI0MDg3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.rabQNgOoVPsIBbvHvTbPlN1aV30DS0UmQGS6Xg0N3SY&response-content-disposition=attachment%3B%20filename%3Djx_vit_base_p16_224-80ecf9dd.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-20 09:48:07--  https://release-assets.githubusercontent.com/github-production-release-asset/168799526/65360900-1a09-11eb-8b86-f0a014a6f156?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-20T10%3A28%3A54Z&rscd=attachment%3B+filename%3Djx_vit_base_p16_224-80ecf9dd.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-20T09%3A28%3A51Z&ske=2025-12-20T10%3A28%3A54Z&sks=b&skv=2018-11-09&sig=TZuwEbRndh1dsNAIv2BMiEBIEa0ZduM1OLxLpSCep8s%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NjIyNzY4NywibmJmIjoxNzY2MjI0MDg3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.rabQNgOoVPsIBbvHvTbPlN1aV30DS0UmQGS6Xg0N3SY&response-content-disposition=attachment%3B%20filename%3Djx_vit_base_p16_224-80ecf9dd.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 346292833 (330M) [application/octet-stream]\n",
            "Saving to: â€˜pretrained/jx_vit_base_p16_224-80ecf9dd.pthâ€™\n",
            "\n",
            "pretrained/jx_vit_b 100%[===================>] 330.25M  81.6MB/s    in 4.1s    \n",
            "\n",
            "2025-12-20 09:48:11 (81.4 MB/s) - â€˜pretrained/jx_vit_base_p16_224-80ecf9dd.pthâ€™ saved [346292833/346292833]\n",
            "\n",
            "âœ… Backbone scaricato.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Crea la cartella se non esiste\n",
        "if not os.path.exists(\"pretrained\"):\n",
        "    os.makedirs(\"pretrained\")\n",
        "\n",
        "# Scarica il file dei pesi ImageNet richiesto hardcoded nel codice\n",
        "print(\"â¬‡ï¸ Download backbone ViT (richiesto dal codice originale)...\")\n",
        "!wget -nc https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth -O pretrained/jx_vit_base_p16_224-80ecf9dd.pth\n",
        "print(\"âœ… Backbone scaricato.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
      ],
      "metadata": {
        "id": "PshJTJAzMw_7",
        "outputId": "256ffdd7-f46c-448a-bf63-82b26dc0f1e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.1\n",
            "Uninstalling torch-2.5.1:\n",
            "  Successfully uninstalled torch-2.5.1\n",
            "Found existing installation: torchvision 0.20.1\n",
            "Uninstalling torchvision-0.20.1:\n",
            "  Successfully uninstalled torchvision-0.20.1\n",
            "Found existing installation: torchaudio 2.5.1\n",
            "Uninstalling torchaudio-2.5.1:\n",
            "  Successfully uninstalled torchaudio-2.5.1\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch) (3.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch) (2025.12.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m189.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m194.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading https://download.pytorch.org/whl/nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvqSzTke_G5s",
        "outputId": "f9d95de4-11b0-47a3-f090-9846c038fe26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting extract_custom.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile extract_custom.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import argparse\n",
        "import time\n",
        "import queue\n",
        "import threading\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from model.model import FrozenInTime\n",
        "from utils.util import state_dict_data_parallel_fix\n",
        "\n",
        "# --- CONFIGURAZIONE PARALLELISMO ---\n",
        "# Numero di video da leggere contemporaneamente (dipende dai core CPU)\n",
        "# Su Colab standard 2-3 Ã¨ ottimale. Su Pro anche 4-6.\n",
        "NUM_WORKERS = 3\n",
        "QUEUE_SIZE_PER_WORKER = 2\n",
        "GLOBAL_QUEUE_SIZE = NUM_WORKERS * QUEUE_SIZE_PER_WORKER\n",
        "\n",
        "# Parametri Normalizzazione (B, T, C, H, W)\n",
        "MEAN = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 3, 1, 1)\n",
        "STD = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 3, 1, 1)\n",
        "\n",
        "def load_model(ckpt_path, device):\n",
        "    print(f\"Costruzione modello FrozenInTime su {device}...\")\n",
        "    model = FrozenInTime(\n",
        "        video_params={\n",
        "            \"model\": \"SpaceTimeTransformer\",\n",
        "            \"arch_config\": \"base_patch16_224\",\n",
        "            \"num_frames\": 16,\n",
        "            \"pretrained\": True,\n",
        "            \"time_init\": \"zeros\"\n",
        "        },\n",
        "        text_params={\"model\": \"bert-base-uncased\", \"pretrained\": True, \"input\": \"text\"},\n",
        "        projection_dim=256,\n",
        "        load_checkpoint=None,\n",
        "        projection='minimal',\n",
        "        load_temporal_fix='zeros'\n",
        "    )\n",
        "    checkpoint = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
        "    if 'state_dict' in checkpoint:\n",
        "        state_dict = checkpoint['state_dict']\n",
        "    else:\n",
        "        state_dict = checkpoint\n",
        "    new_state_dict = state_dict_data_parallel_fix(state_dict, model.state_dict())\n",
        "    model.load_state_dict(new_state_dict, strict=False)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def preprocess_on_gpu(batch_uint8):\n",
        "    \"\"\"Normalizza batch uint8 [B, T, H, W, C] -> float32 [B, T, C, H, W]\"\"\"\n",
        "    batch = batch_uint8.float() / 255.0\n",
        "    batch = batch.permute(0, 1, 4, 2, 3).contiguous()\n",
        "    batch = (batch - MEAN) / STD\n",
        "    return batch\n",
        "\n",
        "def video_worker(vpath, clip_len, batch_size, global_queue):\n",
        "    \"\"\"\n",
        "    Worker che processa un singolo video e invia i batch alla coda globale.\n",
        "    Invia tuple: (vpath, batch_tensor, is_last_batch)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(vpath)\n",
        "        if not cap.isOpened():\n",
        "            # Segnala fine con errore\n",
        "            global_queue.put((vpath, None, True))\n",
        "            return\n",
        "\n",
        "        buffer = []\n",
        "        current_clip = []\n",
        "\n",
        "        # Pre-calcolo crop 224x224\n",
        "        resize_dim = 256\n",
        "        crop_dim = 224\n",
        "        start_y = (resize_dim - crop_dim) // 2\n",
        "        start_x = (resize_dim - crop_dim) // 2\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # CPU Preprocessing\n",
        "            frame = cv2.resize(frame, (resize_dim, resize_dim), interpolation=cv2.INTER_LINEAR)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = frame[start_y:start_y+crop_dim, start_x:start_x+crop_dim]\n",
        "\n",
        "            current_clip.append(frame)\n",
        "\n",
        "            if len(current_clip) == clip_len:\n",
        "                buffer.append(np.stack(current_clip))\n",
        "                current_clip = []\n",
        "\n",
        "                if len(buffer) >= batch_size:\n",
        "                    batch_np = np.stack(buffer)\n",
        "                    batch_tensor = torch.from_numpy(batch_np)\n",
        "                    # Mette in coda (blocca se piena per non saturare RAM)\n",
        "                    global_queue.put((vpath, batch_tensor, False))\n",
        "                    buffer = []\n",
        "\n",
        "        # Residui Clip\n",
        "        if len(current_clip) > 0:\n",
        "            last_frame = current_clip[-1]\n",
        "            pad_needed = clip_len - len(current_clip)\n",
        "            current_clip.extend([last_frame] * pad_needed)\n",
        "            buffer.append(np.stack(current_clip))\n",
        "\n",
        "        # Residui Batch\n",
        "        if len(buffer) > 0:\n",
        "            batch_np = np.stack(buffer)\n",
        "            batch_tensor = torch.from_numpy(batch_np)\n",
        "            global_queue.put((vpath, batch_tensor, False))\n",
        "\n",
        "        cap.release()\n",
        "        # Segnale di fine video\n",
        "        global_queue.put((vpath, None, True))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {vpath}: {e}\")\n",
        "        global_queue.put((vpath, None, True))\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--video_dir', type=str, required=True)\n",
        "    parser.add_argument('--output_dir', type=str, required=True)\n",
        "    parser.add_argument('--weights', type=str, required=True)\n",
        "    parser.add_argument('--batch_size', type=int, default=96)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda'\n",
        "        print(f\"ðŸš€ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"âš¡ MULTI-VIDEO MODE: {NUM_WORKERS} Workers Paralleli | Batch {args.batch_size}\")\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "        print(\"âš ï¸ CUDA non disponibile.\")\n",
        "\n",
        "    global MEAN, STD\n",
        "    MEAN = MEAN.to(device)\n",
        "    STD = STD.to(device)\n",
        "\n",
        "    model = load_model(args.weights, device)\n",
        "\n",
        "    # Lista video da processare\n",
        "    all_videos = []\n",
        "    for ext in ['*.mp4', '*.avi', '*.MOV']:\n",
        "        all_videos.extend(glob.glob(os.path.join(args.video_dir, \"**\", ext), recursive=True))\n",
        "\n",
        "    # Filtra quelli giÃ  fatti\n",
        "    videos_to_process = []\n",
        "    for vpath in all_videos:\n",
        "        vname = os.path.basename(vpath)\n",
        "        save_name = f\"{vname}_1s_1s.npz\"\n",
        "        save_path = os.path.join(args.output_dir, save_name)\n",
        "        if not os.path.exists(save_path):\n",
        "            videos_to_process.append(vpath)\n",
        "\n",
        "    print(f\"Trovati {len(all_videos)} video totali. Da elaborare: {len(videos_to_process)}\")\n",
        "\n",
        "    if not videos_to_process:\n",
        "        print(\"Tutti i video completati!\")\n",
        "        return\n",
        "\n",
        "    # Strutture dati condivise\n",
        "    global_queue = queue.Queue(maxsize=GLOBAL_QUEUE_SIZE)\n",
        "    results_buffer = {} # {vpath: [list_of_features]}\n",
        "    active_videos = set()\n",
        "    completed_videos = 0\n",
        "    start_times = {}\n",
        "\n",
        "    # Executor per i worker\n",
        "    executor = ThreadPoolExecutor(max_workers=NUM_WORKERS)\n",
        "\n",
        "    # Funzione helper per avviare un worker\n",
        "    video_iterator = iter(videos_to_process)\n",
        "\n",
        "    def start_next_worker():\n",
        "        try:\n",
        "            vpath = next(video_iterator)\n",
        "            active_videos.add(vpath)\n",
        "            results_buffer[vpath] = []\n",
        "            start_times[vpath] = time.time()\n",
        "            executor.submit(video_worker, vpath, 16, args.batch_size, global_queue)\n",
        "            print(f\"â–¶ï¸ Start: {os.path.basename(vpath)}\")\n",
        "            return True\n",
        "        except StopIteration:\n",
        "            return False\n",
        "\n",
        "    # Avvia i primi N worker\n",
        "    for _ in range(NUM_WORKERS):\n",
        "        start_next_worker()\n",
        "\n",
        "    # MAIN LOOP (GPU Consumer)\n",
        "    while active_videos:\n",
        "        try:\n",
        "            # Preleva un batch dalla coda (da qualsiasi video)\n",
        "            vpath, batch_cpu, is_last = global_queue.get(timeout=60) # Timeout per evitare deadlock\n",
        "\n",
        "            if is_last:\n",
        "                # Video finito: Salva e chiudi\n",
        "                features = np.concatenate(results_buffer[vpath], axis=0)\n",
        "\n",
        "                vname = os.path.basename(vpath)\n",
        "                save_name = f\"{vname}_1s_1s.npz\"\n",
        "                save_path = os.path.join(args.output_dir, save_name)\n",
        "                np.savez_compressed(save_path, features=features.astype(np.float32))\n",
        "\n",
        "                elapsed = time.time() - start_times[vpath]\n",
        "                fps = (features.shape[0] * 16) / elapsed\n",
        "                completed_videos += 1\n",
        "                print(f\"âœ… Saved: {vname} ({elapsed:.1f}s - {fps:.0f} fps) | Progress: {completed_videos}/{len(videos_to_process)}\")\n",
        "\n",
        "                # Pulizia\n",
        "                del results_buffer[vpath]\n",
        "                del start_times[vpath]\n",
        "                active_videos.remove(vpath)\n",
        "\n",
        "                # Avvia prossimo video\n",
        "                start_next_worker()\n",
        "                global_queue.task_done()\n",
        "                continue\n",
        "\n",
        "            if batch_cpu is not None:\n",
        "                # Inferenza GPU\n",
        "                batch_gpu = batch_cpu.to(device, non_blocking=True)\n",
        "                input_batch = preprocess_on_gpu(batch_gpu)\n",
        "\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    with torch.no_grad():\n",
        "                        v_embed = model.compute_video(input_batch)\n",
        "\n",
        "                # Salva risultato nel buffer specifico del video\n",
        "                results_buffer[vpath].append(v_embed.cpu().numpy().astype(np.float16))\n",
        "\n",
        "            global_queue.task_done()\n",
        "\n",
        "        except queue.Empty:\n",
        "            print(\"âš ï¸ Warning: GPU Queue empty for 60s. Workers might be stuck.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Critical Error in Main Loop: {e}\")\n",
        "            break\n",
        "\n",
        "    executor.shutdown()\n",
        "    print(\"ðŸŽ‰ Tutti i video elaborati.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Gyb1yOzmASW",
        "outputId": "429bf6dc-234b-46b8-bdad-47bc5e936a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/site-packages (0.8.1)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/site-packages (4.14.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (7.1.3)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/site-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/site-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/site-packages (16.0.1)\n",
            "Requirement already satisfied: dominate in /usr/local/lib/python3.11/site-packages (2.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (1.8.0)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.11/site-packages (2.6.4)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (2.2.6)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from tensorboardx) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/site-packages (from tensorboardx) (6.33.2)\n",
            "ðŸš€ GPU: Tesla T4\n",
            "âš¡ MULTI-VIDEO MODE: 3 Workers Paralleli | Batch 64\n",
            "Costruzione modello FrozenInTime su cuda...\n",
            "/content/EgoVLP/model/model.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  vit_model = torch.load(\"pretrained/jx_vit_base_p16_224-80ecf9dd.pth\", map_location=\"cpu\")\n",
            "######USING ATTENTION STYLE:  frozen-in-time\n",
            "Trovati 48 video totali. Da elaborare: 48\n",
            "â–¶ï¸ Start: 10_7_360p_224.mp4\n",
            "â–¶ï¸ Start: 9_22_360p_224.mp4\n",
            "â–¶ï¸ Start: 9_2_360p_224.mp4\n"
          ]
        }
      ],
      "source": [
        "!pip install einops\n",
        "!pip install humanize psutil\n",
        "!pip install ffmpeg-python\n",
        "!pip install av dominate scikit-learn tensorboardx\n",
        "\n",
        "# Crea cartella output\n",
        "!mkdir -p data/features\n",
        "\n",
        "# Esegui lo script\n",
        "# Assicurati che VIDEO_ROOT punti alla cartella dove ci sono effettivamente i file .mp4\n",
        "!python extract_custom.py \\\n",
        "  --video_dir \"data/videos/captain_cook_4d_gopro_resized_3\" \\\n",
        "  --output_dir \"data/features\" \\\n",
        "  --weights \"pretrained/model.pth\" \\\n",
        "  --batch_size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gMpkKYBmA0X",
        "outputId": "f76c3514-6ed7-49a3-a06d-cce16362db2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creazione archivio zip...\n",
            "Upload su Drive: /content/drive/MyDrive/MistakeDetection/egovlp_3.zip\n",
            "âœ… Completato!\n"
          ]
        }
      ],
      "source": [
        "print(\"Creazione archivio zip...\")\n",
        "!zip -r -q egovlp_features.zip data/features\n",
        "\n",
        "print(f\"Upload su Drive: {OUTPUT_ZIP_PATH}\")\n",
        "shutil.copy(\"egovlp_features.zip\", OUTPUT_ZIP_PATH)\n",
        "print(\"âœ… Completato!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}