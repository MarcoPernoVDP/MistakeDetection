{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990e2057",
   "metadata": {},
   "source": [
    "# Environement Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156c371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente locale rilevato.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "try:\n",
    "    from google.colab import drive, userdata\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "REPO_NAME = 'MistakeDetection'\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"‚òÅÔ∏è Colab rilevato.\")\n",
    "    if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
    "\n",
    "    GITHUB_USER = 'MarcoPernoVDP'\n",
    "    try:\n",
    "        TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "        REPO_URL = f'https://{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "    except:\n",
    "        REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "\n",
    "    ROOT_DIR = f'/content/{REPO_NAME}'\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        !git clone {REPO_URL}\n",
    "    else:\n",
    "        %cd {ROOT_DIR}\n",
    "        !git pull\n",
    "        %cd /content\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Ambiente locale rilevato.\")\n",
    "    ROOT_DIR = os.getcwd()\n",
    "    while not os.path.exists(os.path.join(ROOT_DIR, '.gitignore')) and ROOT_DIR != os.path.dirname(ROOT_DIR):\n",
    "        ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
    "\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c34ae",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a23d1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Progetto in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\n",
      "source_path: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "Setup Dati da: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "Inizio setup dati...\n",
      "   Sorgente: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "   Destinazione: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n",
      "Copia cartella: annotation_json...\n",
      "Copia cartella: omnivore...\n",
      "Estrazione ZIP: omnivore.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\marco\\_netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup completato! Dati pronti in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms339450\u001b[0m (\u001b[33ms339450-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Logged in.\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from utils import setup_project\n",
    "# Ora puoi passare agli import del modello\n",
    "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
    "from models.BaselineV2_Transformer import BaselineV2_Transformer\n",
    "from dataset.utils import SplitType\n",
    "\n",
    "# Esegue: Setup Dati (unzip/copy), Login WandB, Setup Device\n",
    "device = setup_project.initialize(ROOT_DIR)\n",
    "\n",
    "# Import wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc6bcd",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1334a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione esperimento\n",
    "DATASET_SOURCE = DatasetSource.HIERO\n",
    "\n",
    "config = {\n",
    "    \"dataset\": \"CaptainCook4D\",\n",
    "    \"feature_extractor\": DATASET_SOURCE.value,\n",
    "    \"input_dim\": DATASET_SOURCE.input_dims(),\n",
    "    \"batch_size\": 1,  # DEVE essere 1 per sequenze di lunghezza variabile\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"epochs\": 1,\n",
    "    \"pos_weight\": 0.75,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23efb6d",
   "metadata": {},
   "source": [
    "# Leave-One-Out Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd10075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\\hiero...\n",
      "Dataset creato: 384 video completi\n",
      "\n",
      "================================================================================\n",
      "LEAVE-ONE-OUT CROSS-VALIDATION SETUP\n",
      "================================================================================\n",
      "Total videos: 384\n",
      "Total recipes (activities): 24\n",
      "\n",
      "Videos per recipe:\n",
      "  Recipe 1: 18 videos\n",
      "  Recipe 10: 12 videos\n",
      "  Recipe 12: 18 videos\n",
      "  Recipe 13: 14 videos\n",
      "  Recipe 15: 15 videos\n",
      "  Recipe 16: 16 videos\n",
      "  Recipe 17: 20 videos\n",
      "  Recipe 18: 15 videos\n",
      "  Recipe 2: 16 videos\n",
      "  Recipe 20: 14 videos\n",
      "  Recipe 21: 19 videos\n",
      "  Recipe 22: 17 videos\n",
      "  Recipe 23: 16 videos\n",
      "  Recipe 25: 15 videos\n",
      "  Recipe 26: 17 videos\n",
      "  Recipe 27: 15 videos\n",
      "  Recipe 28: 18 videos\n",
      "  Recipe 29: 18 videos\n",
      "  Recipe 3: 13 videos\n",
      "  Recipe 4: 17 videos\n",
      "  Recipe 5: 15 videos\n",
      "  Recipe 7: 16 videos\n",
      "  Recipe 8: 16 videos\n",
      "  Recipe 9: 14 videos\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataset.capitain_cook_4d_mlp_dataset import DatasetSource\n",
    "from dataset.capitain_cook_4d_task2subtask2_dataset import CaptainCook4DTask2Subtask2_Dataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import defaultdict\n",
    "\n",
    "try:\n",
    "    full_dataset = CaptainCook4DTask2Subtask2_Dataset(\n",
    "        root_dir=ROOT_DIR\n",
    "    )\n",
    "    \n",
    "    # Raggruppa i video per recipe (activity_id)\n",
    "    # L'activity_id √® il primo numero del video_id (es: \"1_10\" -> activity_id = 1)\n",
    "    recipe_to_indices = defaultdict(list)\n",
    "    for idx, video_id in enumerate(full_dataset.video_ids):\n",
    "        activity_id = video_id.split('_')[0]\n",
    "        recipe_to_indices[activity_id].append(idx)\n",
    "    \n",
    "    # Ordina le ricette per avere un ordine consistente\n",
    "    recipes = sorted(recipe_to_indices.keys())\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"LEAVE-ONE-OUT CROSS-VALIDATION SETUP\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total videos: {len(full_dataset)}\")\n",
    "    print(f\"Total recipes (activities): {len(recipes)}\")\n",
    "    print(f\"\\nVideos per recipe:\")\n",
    "    for recipe_id in recipes:\n",
    "        print(f\"  Recipe {recipe_id}: {len(recipe_to_indices[recipe_id])} videos\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63186c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VIDEO DATASET ITEM [0]\n",
      "================================================================================\n",
      "Features shape:       torch.Size([8, 1024]) (num_steps, n_features)\n",
      "Number of steps:      8\n",
      "Label:                0 (No Errors)\n",
      "Video ID:             10_16\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# V2: quando accedi a dataset[idx], dove idx √® l'indice dello STEP\n",
    "full_dataset.print_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3926192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\notebooks\\wandb\\run-20251219_154557-zob6a9ok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/zob6a9ok' target=\"_blank\">LOO-Task2Subtask2-hiero</a></strong> to <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/zob6a9ok' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/zob6a9ok</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ W&B Run: LOO-Task2Subtask2-hiero (ID: zob6a9ok)\n",
      "\n",
      "================================================================================\n",
      "FOLD 1/24 - Testing on Recipe 1\n",
      "================================================================================\n",
      "Train videos: 366 | Test videos: 18\n",
      "  Epoch 1/1 - Train Loss: 0.6349 - Train Acc: 0.5109 - Train F1: 0.5491\n",
      "\n",
      "  Test Results for Recipe 1:\n",
      "    Accuracy: 0.7222\n",
      "    F1: 0.8387\n",
      "    Precision: 0.7222\n",
      "    Recall: 1.0000\n",
      "    AUC: 0.7846\n",
      "\n",
      "================================================================================\n",
      "FOLD 2/24 - Testing on Recipe 10\n",
      "================================================================================\n",
      "Train videos: 372 | Test videos: 12\n",
      "  Epoch 1/1 - Train Loss: 0.6451 - Train Acc: 0.4919 - Train F1: 0.5166\n",
      "\n",
      "  Test Results for Recipe 10:\n",
      "    Accuracy: 0.3333\n",
      "    F1: 0.0000\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    AUC: 0.6250\n",
      "\n",
      "================================================================================\n",
      "FOLD 3/24 - Testing on Recipe 12\n",
      "================================================================================\n",
      "Train videos: 366 | Test videos: 18\n",
      "  Epoch 1/1 - Train Loss: 0.6692 - Train Acc: 0.4536 - Train F1: 0.4318\n",
      "\n",
      "  Test Results for Recipe 12:\n",
      "    Accuracy: 0.6111\n",
      "    F1: 0.0000\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    AUC: 0.8961\n",
      "\n",
      "================================================================================\n",
      "FOLD 4/24 - Testing on Recipe 13\n",
      "================================================================================\n",
      "Train videos: 370 | Test videos: 14\n",
      "  Epoch 1/1 - Train Loss: 0.6277 - Train Acc: 0.5000 - Train F1: 0.5067\n",
      "\n",
      "  Test Results for Recipe 13:\n",
      "    Accuracy: 0.3571\n",
      "    F1: 0.0000\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    AUC: 0.7333\n",
      "\n",
      "================================================================================\n",
      "FOLD 5/24 - Testing on Recipe 15\n",
      "================================================================================\n",
      "Train videos: 369 | Test videos: 15\n",
      "  Epoch 1/1 - Train Loss: 0.6656 - Train Acc: 0.4770 - Train F1: 0.5349\n",
      "\n",
      "  Test Results for Recipe 15:\n",
      "    Accuracy: 0.3333\n",
      "    F1: 0.0000\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    AUC: 0.4600\n",
      "\n",
      "================================================================================\n",
      "FOLD 6/24 - Testing on Recipe 16\n",
      "================================================================================\n",
      "Train videos: 368 | Test videos: 16\n",
      "  Epoch 1/1 - Train Loss: 0.6547 - Train Acc: 0.4402 - Train F1: 0.4550\n",
      "\n",
      "  Test Results for Recipe 16:\n",
      "    Accuracy: 0.3750\n",
      "    F1: 0.0000\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    AUC: 0.5333\n",
      "\n",
      "================================================================================\n",
      "FOLD 7/24 - Testing on Recipe 17\n",
      "================================================================================\n",
      "Train videos: 364 | Test videos: 20\n",
      "  Epoch 1/1 - Train Loss: 0.6460 - Train Acc: 0.4808 - Train F1: 0.5166\n",
      "\n",
      "  Test Results for Recipe 17:\n",
      "    Accuracy: 0.4000\n",
      "    F1: 0.5714\n",
      "    Precision: 0.4000\n",
      "    Recall: 1.0000\n",
      "    AUC: 0.6458\n",
      "\n",
      "================================================================================\n",
      "FOLD 8/24 - Testing on Recipe 18\n",
      "================================================================================\n",
      "Train videos: 369 | Test videos: 15\n",
      "  Epoch 1/1 - Train Loss: 0.6550 - Train Acc: 0.4932 - Train F1: 0.5494\n",
      "\n",
      "  Test Results for Recipe 18:\n",
      "    Accuracy: 0.2667\n",
      "    F1: 0.0000\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    AUC: 0.8636\n",
      "\n",
      "================================================================================\n",
      "FOLD 9/24 - Testing on Recipe 2\n",
      "================================================================================\n",
      "Train videos: 368 | Test videos: 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     68\u001b[39m inputs = inputs.to(device)\n\u001b[32m     69\u001b[39m labels = labels.to(device).float()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m probs, logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m loss = criterion(logits, labels)\n\u001b[32m     73\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\models\\BaselineV2_Transformer.py:52\u001b[39m, in \u001b[36mBaselineV2_Transformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[33;03mx: (B=1, T, D)\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03mreturns: (B=1) probabilit√† per l'intero step\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pos_enc(x)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, T, D)\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# mean pooling sui sub-segmenti\u001b[39;00m\n\u001b[32m     55\u001b[39m x = x.mean(dim=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (B, D)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:524\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    521\u001b[39m is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[32m    532\u001b[39m     output = output.to_padded_tensor(\u001b[32m0.0\u001b[39m, src.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:933\u001b[39m, in \u001b[36mTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    931\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m._ff_block(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m        \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229\u001b[39m, in \u001b[36mLayerNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:2901\u001b[39m, in \u001b[36mlayer_norm\u001b[39m\u001b[34m(input, normalized_shape, weight, bias, eps)\u001b[39m\n\u001b[32m   2891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[32m   2892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   2893\u001b[39m         layer_norm,\n\u001b[32m   2894\u001b[39m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2899\u001b[39m         eps=eps,\n\u001b[32m   2900\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2901\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2902\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\n\u001b[32m   2903\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "from models.BaselineV2_Transformer import BaselineV2_Transformer\n",
    "\n",
    "# Inizializzazione W&B per l'intero esperimento LOO\n",
    "run = wandb.init(\n",
    "    project=\"mistake-detection\",\n",
    "    name=f\"LOO-Task2Subtask2-{DATASET_SOURCE.value}\",\n",
    "    config=config,\n",
    "    tags=[\"leave-one-out\", \"Task2Subtask2\", DATASET_SOURCE.value],\n",
    "    notes=f\"Leave-One-Out CV with {DATASET_SOURCE.value} features for mistake detection\"\n",
    ")\n",
    "\n",
    "print(f\"üöÄ W&B Run: {run.name} (ID: {run.id})\")\n",
    "\n",
    "# Statistiche per aggregare i risultati di tutti i fold\n",
    "all_fold_results = []\n",
    "\n",
    "# LOO: per ogni ricetta, usala come test set\n",
    "for fold_idx, test_recipe_id in enumerate(recipes):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FOLD {fold_idx + 1}/{len(recipes)} - Testing on Recipe {test_recipe_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Indici del test set (ricetta corrente)\n",
    "    test_indices = recipe_to_indices[test_recipe_id]\n",
    "    \n",
    "    # Indici del training set (tutte le altre ricette)\n",
    "    train_indices = []\n",
    "    for recipe_id in recipes:\n",
    "        if recipe_id != test_recipe_id:\n",
    "            train_indices.extend(recipe_to_indices[recipe_id])\n",
    "    \n",
    "    print(f\"Train videos: {len(train_indices)} | Test videos: {len(test_indices)}\")\n",
    "    \n",
    "    # Crea i subset\n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    test_dataset = Subset(full_dataset, test_indices)\n",
    "    \n",
    "    # Crea i DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    # Inizializza un nuovo modello per questo fold\n",
    "    model = BaselineV2_Transformer(DATASET_SOURCE.input_dims()).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    \n",
    "    # Loss function con pos_weight\n",
    "    train_pos_weight = torch.tensor([config[\"pos_weight\"]], device=device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=train_pos_weight)\n",
    "    \n",
    "    # Training loop per questo fold\n",
    "    best_train_loss = np.inf\n",
    "    \n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        # TRAIN\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_preds_list = []\n",
    "        train_targets_list = []\n",
    "        train_probs_list = []\n",
    "        \n",
    "        for inputs, labels, video_ids in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            \n",
    "            probs, logits = model(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred = (probs >= 0.5).long().item()\n",
    "                train_preds_list.append(pred)\n",
    "                train_targets_list.append(labels.item())\n",
    "                train_probs_list.append(probs.item())\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Metriche di training\n",
    "        train_preds = np.array(train_preds_list)\n",
    "        train_targets = np.array(train_targets_list)\n",
    "        train_probs = np.array(train_probs_list)\n",
    "        \n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_f1 = f1_score(train_targets, train_preds, zero_division=0)\n",
    "        \n",
    "        # Log su W&B per questo fold\n",
    "        wandb.log({\n",
    "            f\"fold_{fold_idx+1}/train_loss\": avg_train_loss,\n",
    "            f\"fold_{fold_idx+1}/train_accuracy\": train_acc,\n",
    "            f\"fold_{fold_idx+1}/train_f1\": train_f1,\n",
    "            f\"fold_{fold_idx+1}/epoch\": epoch + 1\n",
    "        })\n",
    "        \n",
    "        print(f\"  Epoch {epoch+1}/{config['epochs']} - Train Loss: {avg_train_loss:.4f} - Train Acc: {train_acc:.4f} - Train F1: {train_f1:.4f}\")\n",
    "        \n",
    "        # Salva il miglior modello per questo fold\n",
    "        if avg_train_loss < best_train_loss:\n",
    "            best_train_loss = avg_train_loss\n",
    "            best_model_state = model.state_dict()\n",
    "    \n",
    "    # Carica il miglior modello\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # TEST per questo fold\n",
    "    model.eval()\n",
    "    test_preds_list = []\n",
    "    test_targets_list = []\n",
    "    test_probs_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, video_ids in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            \n",
    "            probs, logits = model(inputs)\n",
    "            pred = (probs >= 0.5).long().item()\n",
    "            \n",
    "            test_preds_list.append(pred)\n",
    "            test_targets_list.append(labels.item())\n",
    "            test_probs_list.append(probs.item())\n",
    "    \n",
    "    # Metriche di test per questo fold\n",
    "    test_preds = np.array(test_preds_list)\n",
    "    test_targets = np.array(test_targets_list)\n",
    "    test_probs = np.array(test_probs_list)\n",
    "    \n",
    "    test_acc = accuracy_score(test_targets, test_preds)\n",
    "    test_f1 = f1_score(test_targets, test_preds, zero_division=0)\n",
    "    test_precision = precision_score(test_targets, test_preds, zero_division=0)\n",
    "    test_recall = recall_score(test_targets, test_preds, zero_division=0)\n",
    "    \n",
    "    try:\n",
    "        test_auc = roc_auc_score(test_targets, test_probs)\n",
    "    except ValueError:\n",
    "        test_auc = 0.0\n",
    "    \n",
    "    # Salva i risultati di questo fold\n",
    "    fold_result = {\n",
    "        'fold': fold_idx + 1,\n",
    "        'test_recipe': test_recipe_id,\n",
    "        'accuracy': test_acc,\n",
    "        'f1': test_f1,\n",
    "        'precision': test_precision,\n",
    "        'recall': test_recall,\n",
    "        'auc': test_auc,\n",
    "        'test_targets': test_targets,\n",
    "        'test_preds': test_preds\n",
    "    }\n",
    "    all_fold_results.append(fold_result)\n",
    "    \n",
    "    # Log su W&B\n",
    "    wandb.log({\n",
    "        f\"fold_{fold_idx+1}/test_accuracy\": test_acc,\n",
    "        f\"fold_{fold_idx+1}/test_f1\": test_f1,\n",
    "        f\"fold_{fold_idx+1}/test_precision\": test_precision,\n",
    "        f\"fold_{fold_idx+1}/test_recall\": test_recall,\n",
    "        f\"fold_{fold_idx+1}/test_auc\": test_auc,\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n  Test Results for Recipe {test_recipe_id}:\")\n",
    "    print(f\"    Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"    F1: {test_f1:.4f}\")\n",
    "    print(f\"    Precision: {test_precision:.4f}\")\n",
    "    print(f\"    Recall: {test_recall:.4f}\")\n",
    "    print(f\"    AUC: {test_auc:.4f}\")\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üéâ Leave-One-Out Cross-Validation completato!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4272ac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AGGREGATED RESULTS ACROSS ALL FOLDS\n",
      "================================================================================\n",
      "\n",
      "Metric            | Mean      | Std Dev\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy          | 0.4249    | 0.1469\n",
      "F1 Score          | 0.1763    | 0.3125\n",
      "Precision         | 0.1403    | 0.2560\n",
      "Recall            | 0.2500    | 0.4330\n",
      "AUC               | 0.6927    | 0.1445\n",
      "================================================================================\n",
      "\n",
      "RESULTS PER FOLD:\n",
      "--------------------------------------------------------------------------------\n",
      "Fold | Recipe | Accuracy | F1       | Precision | Recall   | AUC\n",
      "--------------------------------------------------------------------------------\n",
      "1    | 1      | 0.7222   | 0.8387   | 0.7222    | 1.0000   | 0.7846\n",
      "2    | 10     | 0.3333   | 0.0000   | 0.0000    | 0.0000   | 0.6250\n",
      "3    | 12     | 0.6111   | 0.0000   | 0.0000    | 0.0000   | 0.8961\n",
      "4    | 13     | 0.3571   | 0.0000   | 0.0000    | 0.0000   | 0.7333\n",
      "5    | 15     | 0.3333   | 0.0000   | 0.0000    | 0.0000   | 0.4600\n",
      "6    | 16     | 0.3750   | 0.0000   | 0.0000    | 0.0000   | 0.5333\n",
      "7    | 17     | 0.4000   | 0.5714   | 0.4000    | 1.0000   | 0.6458\n",
      "8    | 18     | 0.2667   | 0.0000   | 0.0000    | 0.0000   | 0.8636\n",
      "================================================================================\n",
      "\n",
      "OVERALL CONFUSION MATRIX:\n",
      "[[35 17]\n",
      " [55 21]]\n"
     ]
    }
   ],
   "source": [
    "# Calcola le statistiche aggregate su tutti i fold\n",
    "accuracies = [r['accuracy'] for r in all_fold_results]\n",
    "f1_scores = [r['f1'] for r in all_fold_results]\n",
    "precisions = [r['precision'] for r in all_fold_results]\n",
    "recalls = [r['recall'] for r in all_fold_results]\n",
    "aucs = [r['auc'] for r in all_fold_results]\n",
    "\n",
    "# Medie e deviazioni standard\n",
    "mean_acc = np.mean(accuracies)\n",
    "std_acc = np.std(accuracies)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "mean_precision = np.mean(precisions)\n",
    "std_precision = np.std(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "std_recall = np.std(recalls)\n",
    "mean_auc = np.mean(aucs)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Stampa i risultati aggregati\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AGGREGATED RESULTS ACROSS ALL FOLDS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nMetric            | Mean      | Std Dev\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"Accuracy          | {mean_acc:.4f}    | {std_acc:.4f}\")\n",
    "print(f\"F1 Score          | {mean_f1:.4f}    | {std_f1:.4f}\")\n",
    "print(f\"Precision         | {mean_precision:.4f}    | {std_precision:.4f}\")\n",
    "print(f\"Recall            | {mean_recall:.4f}    | {std_recall:.4f}\")\n",
    "print(f\"AUC               | {mean_auc:.4f}    | {std_auc:.4f}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Stampa i risultati per ogni fold\n",
    "print(f\"\\nRESULTS PER FOLD:\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"Fold | Recipe | Accuracy | F1       | Precision | Recall   | AUC\")\n",
    "print(f\"{'-'*80}\")\n",
    "for result in all_fold_results:\n",
    "    print(f\"{result['fold']:<4} | {result['test_recipe']:<6} | {result['accuracy']:.4f}   | {result['f1']:.4f}   | {result['precision']:.4f}    | {result['recall']:.4f}   | {result['auc']:.4f}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Log delle metriche aggregate su W&B\n",
    "wandb.log({\n",
    "    \"overall/mean_accuracy\": mean_acc,\n",
    "    \"overall/std_accuracy\": std_acc,\n",
    "    \"overall/mean_f1\": mean_f1,\n",
    "    \"overall/std_f1\": std_f1,\n",
    "    \"overall/mean_precision\": mean_precision,\n",
    "    \"overall/std_precision\": std_precision,\n",
    "    \"overall/mean_recall\": mean_recall,\n",
    "    \"overall/std_recall\": std_recall,\n",
    "    \"overall/mean_auc\": mean_auc,\n",
    "    \"overall/std_auc\": std_auc,\n",
    "})\n",
    "\n",
    "# Crea una tabella per W&B con i risultati per fold\n",
    "fold_table_data = []\n",
    "for result in all_fold_results:\n",
    "    fold_table_data.append([\n",
    "        result['fold'],\n",
    "        result['test_recipe'],\n",
    "        result['accuracy'],\n",
    "        result['f1'],\n",
    "        result['precision'],\n",
    "        result['recall'],\n",
    "        result['auc']\n",
    "    ])\n",
    "\n",
    "wandb.log({\n",
    "    \"fold_results_table\": wandb.Table(\n",
    "        columns=[\"Fold\", \"Test Recipe\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\", \"AUC\"],\n",
    "        data=fold_table_data\n",
    "    )\n",
    "})\n",
    "\n",
    "# Confusion Matrix aggregata (concatena tutti i target e le predizioni)\n",
    "all_targets = np.concatenate([r['test_targets'] for r in all_fold_results])\n",
    "all_preds = np.concatenate([r['test_preds'] for r in all_fold_results])\n",
    "\n",
    "cm_overall = confusion_matrix(all_targets, all_preds)\n",
    "print(f\"\\nOVERALL CONFUSION MATRIX:\")\n",
    "print(cm_overall)\n",
    "\n",
    "wandb.log({\n",
    "    \"overall/confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "        probs=None,\n",
    "        y_true=all_targets,\n",
    "        preds=all_preds,\n",
    "        class_names=[\"No Error\", \"Error\"]\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da89ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chiudi il run di W&B\n",
    "wandb.finish()\n",
    "print(\"üèÅ W&B run terminato\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
