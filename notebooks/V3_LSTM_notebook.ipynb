{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be184e4f",
   "metadata": {},
   "source": [
    "# Environement Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897b4c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente locale rilevato.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "try:\n",
    "    from google.colab import drive, userdata\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "REPO_NAME = 'MistakeDetection'\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"‚òÅÔ∏è Colab rilevato.\")\n",
    "    if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
    "\n",
    "    GITHUB_USER = 'MarcoPernoVDP'\n",
    "    try:\n",
    "        TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "        REPO_URL = f'https://{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "    except:\n",
    "        REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "\n",
    "    ROOT_DIR = f'/content/{REPO_NAME}'\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        !git clone {REPO_URL}\n",
    "    else:\n",
    "        %cd {ROOT_DIR}\n",
    "        !git pull\n",
    "        %cd /content\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Ambiente locale rilevato.\")\n",
    "    ROOT_DIR = os.getcwd()\n",
    "    while not os.path.exists(os.path.join(ROOT_DIR, '.gitignore')) and ROOT_DIR != os.path.dirname(ROOT_DIR):\n",
    "        ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
    "\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeacfa3",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e4e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Progetto in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\n",
      "source_path: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "Setup Dati da: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "Inizio setup dati...\n",
      "   Sorgente: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "   Destinazione: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n",
      "Copia cartella: annotation_json...\n",
      "Copia cartella: omnivore...\n",
      "‚úÖ Setup completato! Dati pronti in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\marco\\_netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms339450\u001b[0m (\u001b[33ms339450-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Logged in.\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from utils import setup_project\n",
    "# Ora puoi passare agli import del modello\n",
    "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
    "from models.BaselineV3_LSTM import BaselineV3_LSTM\n",
    "from dataset.utils import SplitType\n",
    "\n",
    "# Esegue: Setup Dati (unzip/copy), Login WandB, Setup Device\n",
    "device = setup_project.initialize(ROOT_DIR)\n",
    "\n",
    "# Import wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d213d",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292bb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione esperimento\n",
    "DATASET_SOURCE = DatasetSource.OMNIVORE\n",
    "SPLIT_TYPE = SplitType.STEP_ID\n",
    "\n",
    "config = {\n",
    "    \"architecture\": \"BaselineV3_LSTM_\" + DATASET_SOURCE.value + \"_\" + SPLIT_TYPE.value,\n",
    "    \"dataset\": \"CaptainCook4D\",\n",
    "    \"feature_extractor\": DATASET_SOURCE.value,\n",
    "    \"input_dim\": DATASET_SOURCE.input_dims(),\n",
    "    \"batch_size\": 1,  # DEVE essere 1 per sequenze di lunghezza variabile\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"epochs\": 1,\n",
    "    \"pos_weight\": 1.5,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
    "    \"seed\": 42,\n",
    "    \"split_type\": SPLIT_TYPE.value\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389a25d",
   "metadata": {},
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf4d783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\\omnivore...\n",
      "Dataset creato: 200 step completi da 8828 secondi\n",
      "\n",
      "=====================================================================================\n",
      "DATASET INFO [TRANSFORMER - STEP-BASED]\n",
      "   Total Steps: 200\n",
      "   Features per second: 1024\n",
      "   Step duration: min=3s, max=184s, avg=44.14s\n",
      "=====================================================================================\n",
      "FULL DATASET       | Tot: 200    | OK: 117   (58.5%) | ERR: 83    (41.5%) | Ratio: 1:1.4\n",
      "-------------------------------------------------------------------------------------\n",
      "TRAIN SET          | Tot: 140    | OK: 82    (58.6%) | ERR: 58    (41.4%) | Ratio: 1:1.4\n",
      "VALIDATION SET     | Tot: 20     | OK: 11    (55.0%) | ERR: 9     (45.0%) | Ratio: 1:1.2\n",
      "TEST SET           | Tot: 40     | OK: 24    (60.0%) | ERR: 16    (40.0%) | Ratio: 1:1.5\n",
      "=====================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataset.capitain_cook_4d_mlp_dataset import DatasetSource\n",
    "from dataset.capitain_cook_4d_transformer_dataset import CaptainCook4DTransformer_Dataset\n",
    "from dataset.utils import get_transformer_loaders\n",
    "\n",
    "try:\n",
    "    full_dataset = CaptainCook4DTransformer_Dataset(\n",
    "        dataset_source=DATASET_SOURCE,\n",
    "        root_dir=ROOT_DIR\n",
    "    )\n",
    "    train_loader, val_loader, test_loader = get_transformer_loaders(\n",
    "        full_dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        seed=config[\"seed\"],\n",
    "        split_type=SPLIT_TYPE\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec45f22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP DATASET ITEM [0]\n",
      "================================================================================\n",
      "Features shape:       torch.Size([36, 1024]) (durata_step, n_features)\n",
      "Step duration:        36 secondi\n",
      "Label:                0 (OK)\n",
      "Step ID:              3\n",
      "Video ID:             1_10\n",
      "Start time:           11.749052505026611 seconds\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# V2: quando accedi a dataset[idx], dove idx √® l'indice dello STEP\n",
    "full_dataset.print_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3ffcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\\omnivore\\1_7_360p.mp4_1s_1s.npz\n",
      "Chiavi presenti nel file: ['arr_0']\n",
      "\n",
      "Array 'arr_0' - shape: (604, 1024), dtype: float32\n",
      "[[ 0.6910985   0.09298898 -0.6608225  ... -0.75679165  1.2401273\n",
      "  -0.5683658 ]\n",
      " [ 0.40254688 -0.4466254  -0.8645446  ... -1.2709565   0.7917245\n",
      "  -0.5052321 ]\n",
      " [ 0.643613   -0.48683766 -0.88651866 ... -1.0358062   0.658605\n",
      "  -0.27201462]]\n"
     ]
    }
   ],
   "source": [
    "from utils.inspect_npz import inspect_npz_from_dataset\n",
    "\n",
    "dataset_folder = DATASET_SOURCE.value\n",
    "npz_filename = \"1_7_360p.mp4_1s_1s.npz\"\n",
    "\n",
    "# Ispezione del file .npz\n",
    "inspect_npz_from_dataset(full_dataset.features_dir(), npz_filename, n_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37a3db8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\notebooks\\wandb\\run-20251215_180915-toapz0hs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/toapz0hs' target=\"_blank\">baseline-LSTM-v3-omnivore-step_id</a></strong> to <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/toapz0hs' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/toapz0hs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ W&B Run: baseline-LSTM-v3-omnivore-step_id (ID: toapz0hs)\n"
     ]
    }
   ],
   "source": [
    "# Inizializzazione W&B\n",
    "run = wandb.init(\n",
    "    project=\"mistake-detection\",\n",
    "    name=f\"baseline-LSTM-v3-{DATASET_SOURCE.value}-{SPLIT_TYPE.value}\",\n",
    "    config=config,\n",
    "    tags=[\"baseline\", \"LSTM\", DATASET_SOURCE.value],\n",
    "    notes=f\"Baseline LSTM with {DATASET_SOURCE.value} features for mistake detection and {SPLIT_TYPE.value} split\"\n",
    ")\n",
    "\n",
    "print(f\"üöÄ W&B Run: {run.name} (ID: {run.id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0043d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = BaselineV3_LSTM(DATASET_SOURCE.input_dims()).to(device)\n",
    "\n",
    "# Watch del modello per tracciare gradienti e parametri\n",
    "wandb.watch(model, log=\"all\", log_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61f3b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso classe positiva: 1.5\n"
     ]
    }
   ],
   "source": [
    "lr = config[\"learning_rate\"]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "# Quanto pesa la classe \"positiva\" = classe \"1\" = classe \"error\":\n",
    "# - CASO 1: rapporto effettivo del dataset\n",
    "#train_pos_weight = train_cnt_0 / train_cnt_1\n",
    "\n",
    "# - CASO 2: rapporto usato nel paper\n",
    "train_pos_weight = config[\"pos_weight\"]\n",
    "\n",
    "print(f\"Peso classe positiva: {train_pos_weight}\")\n",
    "train_pos_weight = torch.tensor([train_pos_weight], device=device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=train_pos_weight)\n",
    "\n",
    "epochs = config[\"epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5de1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "error_annotations_path = os.path.join(ROOT_DIR, 'data', 'annotation_json', 'error_annotations.json')\n",
    "with open(error_annotations_path, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "def get_error_category_label(step_id, recording_id, start_time) -> list[str] | None:\n",
    "    # Apri error_annotations.json e cerca la categoria di errore corrispondente\n",
    "    # a step_id, recording_id e start_time, ritornando le labels corrette, se non trovata ritorna None\n",
    "    for annotation in annotations:\n",
    "        if(annotation['recording_id'] == recording_id):\n",
    "            for step in annotation['step_annotations']:\n",
    "                if(step['step_id'] == step_id and\n",
    "                   step['start_time'] == start_time and\n",
    "                   'errors' in step):\n",
    "                    return [error['tag'] for error in step['errors']]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91624240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Train Loss: 0.8348 - Val Loss: 0.8411 - Val Acc: 0.6500 - Val F1: 0.5333 - Val Precision: 0.6667 - Val Recall: 0.4444 - Val AUC: 0.8182\n",
      "‚úÖ Nuovo miglior modello salvato! avg_val_loss: 0.8411\n",
      "\n",
      "üéâ Training completato!\n",
      "Miglior avg_val_loss Score: 0.8411\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "best_avg_val_loss = np.inf\n",
    "final_val_acc = 0\n",
    "final_val_f1 = 0\n",
    "final_val_precision = 0\n",
    "final_val_recall = 0\n",
    "final_val_auc = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # -------------------------\n",
    "    #        TRAIN\n",
    "    # -------------------------\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_preds_list = []\n",
    "    train_targets_list = []\n",
    "    train_probs_list = []\n",
    "\n",
    "    for inputs, labels, step_ids, video_ids, start_times in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        probs, logits = model(inputs)   # probs: scalare, logits: scalare\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metriche train - ogni batch ha una sola predizione (scalare)\n",
    "        with torch.no_grad():\n",
    "            pred = (probs >= 0.5).long().item()  # converti a scalare Python\n",
    "            \n",
    "            train_preds_list.append(pred)\n",
    "            train_targets_list.append(labels.item())\n",
    "            train_probs_list.append(probs.item())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Metriche di training - converti liste a numpy\n",
    "    train_preds = np.array(train_preds_list)\n",
    "    train_targets = np.array(train_targets_list)\n",
    "    train_probs = np.array(train_probs_list)\n",
    "\n",
    "    train_acc = accuracy_score(train_targets, train_preds)\n",
    "    train_f1 = f1_score(train_targets, train_preds, zero_division=0)\n",
    "    train_precision = precision_score(train_targets, train_preds, zero_division=0)\n",
    "    train_recall = recall_score(train_targets, train_preds, zero_division=0)\n",
    "\n",
    "    # AUC train (usa probabilit√†, NON predizioni)\n",
    "    try:\n",
    "        train_auc = roc_auc_score(train_targets, train_probs)\n",
    "    except ValueError:\n",
    "        train_auc = 0.0  # Caso raro con classe mancante nel batch\n",
    "\n",
    "    # -------------------------\n",
    "    #        EVAL\n",
    "    # -------------------------\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, step_ids, video_ids, start_times in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            probs, logits = model(inputs)   # probs: scalare, logits: scalare\n",
    "\n",
    "            val_loss = criterion(logits, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "            # metriche - converti a scalari Python\n",
    "            pred = (probs >= 0.5).long().item()\n",
    "            \n",
    "            all_preds.append(pred)\n",
    "            all_targets.append(labels.item())\n",
    "            all_probs.append(probs.item())\n",
    "\n",
    "        # Converti liste a numpy\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_probs = np.array(all_probs)\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_acc = accuracy_score(all_targets, all_preds)\n",
    "        val_f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
    "        val_precision = precision_score(all_targets, all_preds, zero_division=0)\n",
    "        val_recall = recall_score(all_targets, all_preds, zero_division=0)\n",
    "\n",
    "        # AUC validation\n",
    "        try:\n",
    "            val_auc = roc_auc_score(all_targets, all_probs)\n",
    "        except ValueError:\n",
    "            val_auc = 0.0\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "        # Log su W&B\n",
    "        wandb.log({\n",
    "            # Training metrics\n",
    "            \"train/loss\": avg_train_loss,\n",
    "            \"train/accuracy\": train_acc,\n",
    "            \"train/f1\": train_f1,\n",
    "            \"train/precision\": train_precision,\n",
    "            \"train/recall\": train_recall,\n",
    "            \"train/auc\": train_auc,\n",
    "\n",
    "            # Validation metrics\n",
    "            \"val/loss\": avg_val_loss,\n",
    "            \"val/accuracy\": val_acc,\n",
    "            \"val/f1\": val_f1,\n",
    "            \"val/precision\": val_precision,\n",
    "            \"val/recall\": val_recall,\n",
    "            \"val/auc\": val_auc,\n",
    "\n",
    "            # Confusion Matrix\n",
    "            \"val/confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                probs=None,\n",
    "                y_true=all_targets,\n",
    "                preds=all_preds,\n",
    "                class_names=[\"No Error\", \"Error\"]\n",
    "            ),\n",
    "\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"epoch\": epoch + 1\n",
    "        })\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} \"\n",
    "            f\"- Train Loss: {avg_train_loss:.4f} \"\n",
    "            f\"- Val Loss: {avg_val_loss:.4f} \"\n",
    "            f\"- Val Acc: {val_acc:.4f} \"\n",
    "            f\"- Val F1: {val_f1:.4f} \"\n",
    "            f\"- Val Precision: {val_precision:.4f} \"\n",
    "            f\"- Val Recall: {val_recall:.4f} \"\n",
    "            f\"- Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "        # Salvataggio miglior modello\n",
    "        if avg_val_loss < best_avg_val_loss:\n",
    "            best_avg_val_loss = avg_val_loss\n",
    "            final_val_acc = val_acc\n",
    "            final_val_f1 = val_f1\n",
    "            final_val_precision = val_precision\n",
    "            final_val_recall = val_recall\n",
    "            final_val_auc = val_auc\n",
    "            checkpoint_path = os.path.join(ROOT_DIR, \"checkpoints\", f\"best_model_avg_val_loss_{best_avg_val_loss:.4f}.pth\")\n",
    "            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_f1': val_f1,\n",
    "                'val_acc': val_acc,\n",
    "                'val_auc': val_auc,\n",
    "            }, checkpoint_path)\n",
    "\n",
    "            if IS_COLAB:\n",
    "                artifact = wandb.Artifact(\n",
    "                    name=f\"model-{run.id}\",\n",
    "                    type=\"model\",\n",
    "                    description=f\"Best model with avg_val_loss={best_avg_val_loss:.4f}\",\n",
    "                    metadata={\n",
    "                        \"epoch\": epoch + 1,\n",
    "                        \"val_f1\": val_f1,\n",
    "                        \"val_acc\": val_acc,\n",
    "                        \"val_auc\": val_auc,\n",
    "                        \"architecture\": config[\"architecture\"]\n",
    "                    }\n",
    "                )\n",
    "                artifact.add_file(checkpoint_path)\n",
    "                wandb.log_artifact(artifact)\n",
    "\n",
    "            print(f\"‚úÖ Nuovo miglior modello salvato! avg_val_loss: {best_avg_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\nüéâ Training completato!\")\n",
    "print(f\"Miglior avg_val_loss Score: {best_avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3caf3f5",
   "metadata": {},
   "source": [
    "# Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16440fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello migliore caricato da: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\checkpoints\\best_model_avg_val_loss_0.8411.pth\n",
      "   Epoch: 1, Val F1: 0.5333, Val Acc: 0.6500\n",
      "\n",
      "üìä Test Results:\n",
      "Test Loss: 0.8247\n",
      "Test Accuracy: 0.6000\n",
      "Test F1: 0.4286\n",
      "Test Precision: 0.5000\n",
      "Test Recall: 0.3750\n",
      "Test AUC: 0.6589\n",
      "\n",
      "üìà Confusion Matrix (Dataset Labels):\n",
      "[[18  6]\n",
      " [10  6]]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "#        TEST\n",
    "# -------------------------\n",
    "# Carica il miglior modello salvato\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"‚úÖ Modello migliore caricato da: {checkpoint_path}\")\n",
    "print(f\"   Epoch: {checkpoint['epoch']}, Val F1: {checkpoint['val_f1']:.4f}, Val Acc: {checkpoint['val_acc']:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "test_preds_list = []\n",
    "test_targets_list = []\n",
    "test_probs_list = []\n",
    "test_error_categories_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, step_ids, video_ids, start_times in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        probs, logits = model(inputs)   # probs: scalare, logits: scalare\n",
    "\n",
    "        test_loss = criterion(logits, labels)\n",
    "        total_test_loss += test_loss.item()\n",
    "\n",
    "        # metriche - converti a scalari Python\n",
    "        pred = (probs >= 0.5).long().item()\n",
    "        \n",
    "        test_preds_list.append(pred)\n",
    "        test_targets_list.append(labels.item())\n",
    "        test_probs_list.append(probs.item())\n",
    "\n",
    "        for step_id, video_id, start_time in zip(step_ids, video_ids, start_times):\n",
    "            error_categories = get_error_category_label(step_id.item(), video_id, start_time.item())\n",
    "            test_error_categories_list.append(error_categories)\n",
    "\n",
    "    # Converti liste a numpy\n",
    "    test_preds = np.array(test_preds_list)\n",
    "    test_targets = np.array(test_targets_list)\n",
    "    test_probs = np.array(test_probs_list)\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_acc = accuracy_score(test_targets, test_preds)\n",
    "    test_f1 = f1_score(test_targets, test_preds, zero_division=0)\n",
    "    test_precision = precision_score(test_targets, test_preds, zero_division=0)\n",
    "    test_recall = recall_score(test_targets, test_preds, zero_division=0)\n",
    "\n",
    "    # AUC test\n",
    "    try:\n",
    "        test_auc = roc_auc_score(test_targets, test_probs)\n",
    "    except ValueError:\n",
    "        test_auc = 0.0\n",
    "\n",
    "    # Confusion Matrices\n",
    "    cm_test = confusion_matrix(test_targets, test_preds)\n",
    "\n",
    "    # Log su W&B\n",
    "    wandb.log({\n",
    "        \"test/loss\": avg_test_loss,\n",
    "        \"test/accuracy\": test_acc,\n",
    "        \"test/f1\": test_f1,\n",
    "        \"test/precision\": test_precision,\n",
    "        \"test/recall\": test_recall,\n",
    "        \"test/auc\": test_auc,\n",
    "\n",
    "        # Confusion Matrix (dataset labels)\n",
    "        \"test/confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "            probs=None,\n",
    "            y_true=test_targets,\n",
    "            preds=test_preds,\n",
    "            class_names=[\"No Error\", \"Error\"]\n",
    "        ),\n",
    "    })\n",
    "\n",
    "    print(f\"\\nüìä Test Results:\")\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Test F1: {test_f1:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Test AUC: {test_auc:.4f}\")\n",
    "    print(f\"\\nüìà Confusion Matrix (Dataset Labels):\")\n",
    "    print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80cfc397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Tabella di Contingenza: Predizioni vs Categorie di Errore Reali\n",
      "\n",
      "Prediction             Error Predicted  No Error Predicted  Total\n",
      "Actual Error Category                                            \n",
      "Measurement Error                    0                   1      1\n",
      "No Error                             6                  18     24\n",
      "Order Error                          3                   4      7\n",
      "Other                                0                   1      1\n",
      "Preparation Error                    1                   2      3\n",
      "Technique Error                      0                   1      1\n",
      "Temperature Error                    3                   2      5\n",
      "Timing Error                         3                   3      6\n",
      "Total                               16                  32     48\n",
      "\n",
      "\n",
      "üìä Tabella Percentuali (per colonna):\n",
      "\n",
      "Prediction             Error Predicted  No Error Predicted\n",
      "Actual Error Category                                     \n",
      "Measurement Error                 0.00                3.12\n",
      "No Error                         37.50               56.25\n",
      "Order Error                      18.75               12.50\n",
      "Other                             0.00                3.12\n",
      "Preparation Error                 6.25                6.25\n",
      "Technique Error                   0.00                3.12\n",
      "Temperature Error                18.75                6.25\n",
      "Timing Error                     18.75                9.38\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepara i dati per la tabella\n",
    "data_for_table = []\n",
    "for pred, error_cats in zip(test_preds_list, test_error_categories_list):\n",
    "    pred_label = \"Error Predicted\" if pred == 1 else \"No Error Predicted\"\n",
    "    \n",
    "    if error_cats is None or len(error_cats) == 0:\n",
    "        # Nessun errore reale\n",
    "        data_for_table.append({\n",
    "            'Prediction': pred_label,\n",
    "            'Actual Error Category': 'No Error'\n",
    "        })\n",
    "    else:\n",
    "        # Uno o pi√π errori - crea una riga per ogni categoria\n",
    "        for cat in error_cats:\n",
    "            data_for_table.append({\n",
    "                'Prediction': pred_label,\n",
    "                'Actual Error Category': cat\n",
    "            })\n",
    "\n",
    "# Crea DataFrame\n",
    "df = pd.DataFrame(data_for_table)\n",
    "\n",
    "# Crea tabella di contingenza\n",
    "contingency_table = pd.crosstab(\n",
    "    df['Actual Error Category'], \n",
    "    df['Prediction'],\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "print(\"üìä Tabella di Contingenza: Predizioni vs Categorie di Errore Reali\\n\")\n",
    "print(contingency_table)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Visualizza anche le percentuali\n",
    "contingency_table_pct = pd.crosstab(\n",
    "    df['Actual Error Category'], \n",
    "    df['Prediction'],\n",
    "    normalize='columns'\n",
    ") * 100\n",
    "\n",
    "print(\"üìä Tabella Percentuali (per colonna):\\n\")\n",
    "print(contingency_table_pct.round(2))\n",
    "\n",
    "# Log su W&B come tabella\n",
    "wandb.log({\n",
    "    \"test/predictions_vs_error_categories\": wandb.Table(dataframe=contingency_table.reset_index())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7759f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ</td></tr><tr><td>learning_rate</td><td>‚ñÅ</td></tr><tr><td>test/accuracy</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>test/annotation_accuracy</td><td>‚ñÅ</td></tr><tr><td>test/annotation_f1</td><td>‚ñÅ</td></tr><tr><td>test/annotation_precision</td><td>‚ñÅ</td></tr><tr><td>test/annotation_recall</td><td>‚ñÅ</td></tr><tr><td>test/auc</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>test/f1</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>test/loss</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>+14</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>test/accuracy</td><td>0.6</td></tr><tr><td>test/annotation_accuracy</td><td>0.6</td></tr><tr><td>test/annotation_f1</td><td>0.42857</td></tr><tr><td>test/annotation_precision</td><td>0.5</td></tr><tr><td>test/annotation_recall</td><td>0.375</td></tr><tr><td>test/auc</td><td>0.65885</td></tr><tr><td>test/f1</td><td>0.42857</td></tr><tr><td>test/loss</td><td>0.82469</td></tr><tr><td>+14</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">baseline-LSTM-v3-omnivore-step_id</strong> at: <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/toapz0hs' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/toapz0hs</a><br> View project at: <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection</a><br>Synced 4 W&B file(s), 5 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251215_180915-toapz0hs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ W&B run terminato\n"
     ]
    }
   ],
   "source": [
    "# Chiudi il run di W&B\n",
    "wandb.finish()\n",
    "print(\"üèÅ W&B run terminato\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
