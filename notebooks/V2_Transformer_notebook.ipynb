{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "383957ac",
   "metadata": {},
   "source": [
    "# Environement Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10db9587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente locale rilevato.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "try:\n",
    "    from google.colab import drive, userdata\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "REPO_NAME = 'MistakeDetection'\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"☁️ Colab rilevato.\")\n",
    "    if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
    "\n",
    "    GITHUB_USER = 'MarcoPernoVDP'\n",
    "    try:\n",
    "        TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "        REPO_URL = f'https://{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "    except:\n",
    "        REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "\n",
    "    ROOT_DIR = f'/content/{REPO_NAME}'\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        !git clone {REPO_URL}\n",
    "    else:\n",
    "        %cd {ROOT_DIR}\n",
    "        !git pull\n",
    "        %cd /content\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Ambiente locale rilevato.\")\n",
    "    ROOT_DIR = os.getcwd()\n",
    "    while not os.path.exists(os.path.join(ROOT_DIR, '.gitignore')) and ROOT_DIR != os.path.dirname(ROOT_DIR):\n",
    "        ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
    "\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd40e25e",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c34caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Progetto in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\n",
      "source_path: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "Setup Dati da: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "Inizio setup dati...\n",
      "   Sorgente: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "   Destinazione: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n",
      "Copia cartella: annotation_json...\n",
      "Copia cartella: omnivore...\n",
      "✅ Setup completato! Dati pronti in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\marco\\_netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms339450\u001b[0m (\u001b[33ms339450-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Logged in.\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from utils import setup_project\n",
    "# Ora puoi passare agli import del modello\n",
    "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
    "from models.BaselineV1_MLP import BaselineV1_MLP\n",
    "\n",
    "# Esegue: Setup Dati (unzip/copy), Login WandB, Setup Device\n",
    "device = setup_project.initialize(ROOT_DIR)\n",
    "DATASET_SOURCE = DatasetSource.OMNIVORE\n",
    "\n",
    "# Import wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970666a",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e56ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione esperimento\n",
    "config = {\n",
    "    \"architecture\": \"BaselineV1_Transformer_\" + DATASET_SOURCE.value,\n",
    "    \"dataset\": \"CaptainCook4D\",\n",
    "    \"feature_extractor\": DATASET_SOURCE.value,\n",
    "    \"input_dim\": DATASET_SOURCE.input_dims(),\n",
    "    \"batch_size\": 512,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"epochs\": 100,\n",
    "    \"pos_weight\": 1.5,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
    "    \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6a54d",
   "metadata": {},
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad9213c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\\omnivore...\n",
      "[V2] Numero di step univoci: 200\n",
      "\n",
      "=====================================================================================\n",
      "DATASET INFO [V2 - STEP-BASED]\n",
      "   Total Steps: 200\n",
      "   Total Sub-seconds: 8828\n",
      "   Avg seconds per step: 44.14\n",
      "FULL DATASET       | Steps: 200  | Subsecs: 8828  | OK: 4917  (55.7%) | ERR: 3911  (44.3%) | Ratio: 1:1.3\n",
      "-------------------------------------------------------------------------------------\n",
      "TRAIN SET          | Steps: 140  | Subsecs: 6252  | OK: 3281  (52.5%) | ERR: 2971  (47.5%) | Ratio: 1:1.1\n",
      "VALIDATION SET     | Steps: 20   | Subsecs: 799   | OK: 491   (61.5%) | ERR: 308   (38.5%) | Ratio: 1:1.6\n",
      "TEST SET           | Steps: 40   | Subsecs: 1777  | OK: 1145  (64.4%) | ERR: 632   (35.6%) | Ratio: 1:1.8\n",
      "=====================================================================================\n",
      "\n",
      "[V2] Batch size forzato a 1 (uno step per batch)\n",
      "[V2] Training loop itererà su 140 step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataset.capitain_cook_4d_mlp_dataset import DatasetSource\n",
    "from dataset.capitain_cook_4d_transformer_dataset import CaptainCook4DTransformer_Dataset\n",
    "from dataset.utils import get_tranformer_loaders\n",
    "\n",
    "try:\n",
    "    full_dataset = CaptainCook4DTransformer_Dataset(\n",
    "        dataset_source=DATASET_SOURCE, \n",
    "        root_dir=ROOT_DIR\n",
    "    )\n",
    "    train_loader, val_loader, test_loader = get_tranformer_loaders(\n",
    "        full_dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        seed=config[\"seed\"]\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Errore: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c26c1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "V2 DATASET ITEM [0]\n",
      "================================================================================\n",
      "Step ID:              1_10_0_11.749_46.437\n",
      "Sequence length:      36 seconds\n",
      "Features shape:       torch.Size([36, 1024]) (seconds x features)\n",
      "Labels shape:         torch.Size([36]) (seconds)\n",
      "\n",
      "Step details:\n",
      "  Video ID:             1_10\n",
      "  Step index:           0\n",
      "  Timing:               11.749s - 46.437s (34.688s)\n",
      "  Label sequence:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# V2: quando accedi a dataset[idx], dove idx è l'indice dello STEP\n",
    "\n",
    "full_dataset.print_item(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
