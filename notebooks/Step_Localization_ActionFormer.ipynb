{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dcc0cb92",
      "metadata": {
        "id": "dcc0cb92"
      },
      "source": [
        "# Environement Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Setup Progetto (MistakeDetection)\n",
        "import sys, os\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    IS_COLAB = True\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "\n",
        "REPO_NAME = 'MistakeDetection'\n",
        "\n",
        "# --- CONFIGURAZIONE PATH ---\n",
        "if IS_COLAB:\n",
        "    print(\"â˜ï¸ Colab rilevato.\")\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    # DEFINIZIONE GLOBALE PROJECT_DIR (Importante per le celle successive!)\n",
        "    PROJECT_DIR = \"/content/drive/MyDrive/MistakeDetection\"\n",
        "\n",
        "    # Fallback se la cartella ha un nome diverso\n",
        "    if not os.path.exists(PROJECT_DIR):\n",
        "        if os.path.exists(\"/content/drive/MyDrive/CaptainCook4D\"):\n",
        "            PROJECT_DIR = \"/content/drive/MyDrive/CaptainCook4D\"\n",
        "\n",
        "    print(f\"ðŸ“‚ Cartella Progetto su Drive: {PROJECT_DIR}\")\n",
        "\n",
        "    GITHUB_USER = 'MarcoPernoVDP'\n",
        "    try:\n",
        "        TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "        REPO_URL = f'https://{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
        "    except:\n",
        "        REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
        "\n",
        "    ROOT_DIR = f'/content/{REPO_NAME}'\n",
        "\n",
        "    if not os.path.exists(ROOT_DIR):\n",
        "        print(f\"ðŸ“¥ Clonazione {REPO_NAME}...\")\n",
        "        !git clone {REPO_URL}\n",
        "    else:\n",
        "        print(f\"ðŸ”„ Aggiornamento {REPO_NAME}...\")\n",
        "        %cd {ROOT_DIR}\n",
        "        !git pull\n",
        "        %cd /content\n",
        "else:\n",
        "    print(\"Ambiente locale rilevato.\")\n",
        "    ROOT_DIR = os.getcwd()\n",
        "    while not os.path.exists(os.path.join(ROOT_DIR, '.gitignore')) and ROOT_DIR != os.path.dirname(ROOT_DIR):\n",
        "        ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
        "    PROJECT_DIR = ROOT_DIR # In locale coincidono spesso\n",
        "\n",
        "if ROOT_DIR not in sys.path:\n",
        "    sys.path.append(ROOT_DIR)\n",
        "\n",
        "print(f\"âœ… ROOT_DIR impostata a: {ROOT_DIR}\")"
      ],
      "metadata": {
        "id": "zmnwlfLXsQDA"
      },
      "id": "zmnwlfLXsQDA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "caef717d",
      "metadata": {
        "id": "caef717d",
        "outputId": "911f19b5-e667-4be2-ec4c-0e9823dda1f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ðŸ“‚ Cartella Progetto rilevata: /content/drive/MyDrive/MistakeDetection\n",
            "/content/actionformer_workspace\n",
            "ðŸ“¥ Clonazione ActionFormer...\n",
            "Cloning into 'multi_step_localization'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 79 (delta 26), reused 66 (delta 20), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (79/79), 1.45 MiB | 5.09 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n",
            "/content/actionformer_workspace/multi_step_localization\n",
            "ðŸ“¦ Installazione librerie...\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.11.0+cu113 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.11.0+cu113\u001b[0m\u001b[31m\n",
            "\u001b[0mâš™ï¸ Compilazione kernel CUDA...\n",
            "[Errno 2] No such file or directory: './libs/utils'\n",
            "/content/actionformer_workspace/multi_step_localization\n",
            "python3: can't open file '/content/actionformer_workspace/multi_step_localization/setup.py': [Errno 2] No such file or directory\n",
            "/content\n",
            "\n",
            "âœ… Ambiente ActionFormer pronto e compilato.\n"
          ]
        }
      ],
      "source": [
        "# @title 2. Setup ActionFormer\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "# Usiamo un workspace separato\n",
        "AF_WORKDIR = \"/content/actionformer_workspace\"\n",
        "os.makedirs(AF_WORKDIR, exist_ok=True)\n",
        "os.chdir(AF_WORKDIR)\n",
        "\n",
        "REPO_NAME = \"multi_step_localization\"\n",
        "AF_REPO_PATH = os.path.join(AF_WORKDIR, REPO_NAME)\n",
        "\n",
        "# 1. Clone\n",
        "if not os.path.exists(AF_REPO_PATH):\n",
        "    print(\"ðŸ“¥ Clonazione ActionFormer (con --recursive)...\")\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"clone\", \"--recursive\", \"https://github.com/CaptainCook4D/multi_step_localization.git\"], check=True)\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Clone recursive fallito, provo standard...\")\n",
        "        subprocess.run([\"git\", \"clone\", \"https://github.com/CaptainCook4D/multi_step_localization.git\"], check=True)\n",
        "\n",
        "os.chdir(AF_REPO_PATH)\n",
        "\n",
        "# 2. Fix Path Libs\n",
        "if os.path.exists(os.path.join(AF_REPO_PATH, \"actionformer\", \"libs\", \"utils\")):\n",
        "    UTILS_PATH = os.path.join(AF_REPO_PATH, \"actionformer\", \"libs\", \"utils\")\n",
        "    PATCH_DIR = os.path.join(AF_REPO_PATH, \"actionformer\")\n",
        "elif os.path.exists(os.path.join(AF_REPO_PATH, \"libs\", \"utils\")):\n",
        "    UTILS_PATH = os.path.join(AF_REPO_PATH, \"libs\", \"utils\")\n",
        "    PATCH_DIR = AF_REPO_PATH\n",
        "else:\n",
        "    # Tentativo update submodule\n",
        "    print(\"âš ï¸ Cartella libs non trovata, provo update submodule...\")\n",
        "    subprocess.run([\"git\", \"submodule\", \"update\", \"--init\", \"--recursive\"], check=True)\n",
        "    if os.path.exists(os.path.join(AF_REPO_PATH, \"libs\", \"utils\")):\n",
        "        UTILS_PATH = os.path.join(AF_REPO_PATH, \"libs\", \"utils\")\n",
        "        PATCH_DIR = AF_REPO_PATH\n",
        "    else:\n",
        "        raise FileNotFoundError(\"CRITICO: Impossibile trovare libs/utils.\")\n",
        "\n",
        "print(f\"âœ… Cartella Utils: {UTILS_PATH}\")\n",
        "\n",
        "# 3. Installazione & Patch\n",
        "print(\"ðŸ“¦ Installazione dipendenze...\")\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pyyaml\", \"scipy\"], check=True)\n",
        "\n",
        "print(\"ðŸ©¹ Patch NumPy 2.0...\")\n",
        "with open(os.path.join(PATCH_DIR, \"numpy_patch.py\"), \"w\") as f:\n",
        "    f.write(\"import numpy as np\\n\")\n",
        "    f.write(\"try:\\n  if not hasattr(np, 'float'): np.float = np.float64\\nexcept: pass\\n\")\n",
        "    f.write(\"try:\\n  if not hasattr(np, 'int'): np.int = np.int_\\nexcept: pass\\n\")\n",
        "\n",
        "# Inietta patch in eval.py\n",
        "eval_path = os.path.join(AF_REPO_PATH, \"eval.py\")\n",
        "if os.path.exists(eval_path):\n",
        "    with open(eval_path, \"r\") as f: content = f.read()\n",
        "    if \"import numpy_patch\" not in content:\n",
        "        with open(eval_path, \"w\") as f:\n",
        "            f.write(\"import sys\\nsys.path.append('actionformer')\\nimport numpy_patch\\n\" + content)\n",
        "\n",
        "# 4. Compilazione\n",
        "print(\"âš™ï¸ Compilazione CUDA...\")\n",
        "os.chdir(UTILS_PATH)\n",
        "subprocess.run([sys.executable, \"setup.py\", \"install\"], check=True)\n",
        "\n",
        "os.chdir(AF_REPO_PATH)\n",
        "print(\"\\nâœ… Ambiente ActionFormer pronto.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b773efb",
      "metadata": {
        "id": "6b773efb",
        "outputId": "377b5334-2b0a-4c9b-81b0-2768c3953a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”§ Workdir: c:\\Users\\enric\\Desktop\\MistakeDetection\\temp_af_build\n",
            "ðŸ“¥ Clonazione ActionFormer...\n",
            "ðŸ”Ž Ricerca file setup.py...\n",
            "âŒ CRITICO: setup.py non trovato! Elenco contenuto scaricato:\n",
            "multi_step_localization/\n",
            "    .git/\n",
            "        hooks/\n",
            "        info/\n",
            "        logs/\n",
            "            refs/\n",
            "                heads/\n",
            "                remotes/\n",
            "                    origin/\n",
            "        objects/\n",
            "            info/\n",
            "            pack/\n",
            "        refs/\n",
            "            heads/\n",
            "            remotes/\n",
            "                origin/\n",
            "            tags/\n",
            "    actionformer/\n",
            "    captaincook/\n",
            "    captaincook_actionformer_annotations/\n",
            "        combined/\n",
            "        normal/\n",
            "    metrics_data/\n",
            "    model_outputs/\n",
            "ðŸ”„ Directory ripristinata.\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "Struttura repository non valida",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     64\u001b[39m         indent = \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m * \u001b[32m4\u001b[39m * (level)\n\u001b[32m     65\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos.path.basename(root)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mStruttura repository non valida\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# --- 4. PREPARAZIONE ---\u001b[39;00m\n\u001b[32m     69\u001b[39m os.chdir(repo_path)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: Struttura repository non valida"
          ]
        }
      ],
      "source": [
        "# @title 3. Estrazione Feature Omnivore\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIGURAZIONE VARIABILI (Self-Contained) ---\n",
        "if 'PROJECT_DIR' not in locals():\n",
        "    # Tenta di indovinare il path\n",
        "    if os.path.exists(\"/content/drive/MyDrive/MistakeDetection\"):\n",
        "        PROJECT_DIR = \"/content/drive/MyDrive/MistakeDetection\"\n",
        "    elif os.path.exists(\"/content/drive/MyDrive/CaptainCook4D\"):\n",
        "        PROJECT_DIR = \"/content/drive/MyDrive/CaptainCook4D\"\n",
        "    else:\n",
        "        # Fallback locale se non trova nulla (o se sei in locale)\n",
        "        PROJECT_DIR = os.getcwd()\n",
        "\n",
        "if 'ROOT_DIR' not in locals():\n",
        "    # Tenta di trovare il repo clonato\n",
        "    possible_roots = [\n",
        "        os.path.join(PROJECT_DIR, \"MistakeDetection\"),\n",
        "        \"/content/MistakeDetection\",\n",
        "        PROJECT_DIR\n",
        "    ]\n",
        "    for r in possible_roots:\n",
        "        if os.path.exists(os.path.join(r, \".git\")):\n",
        "            ROOT_DIR = r\n",
        "            break\n",
        "    if 'ROOT_DIR' not in locals(): ROOT_DIR = PROJECT_DIR\n",
        "\n",
        "# --- RICERCA ZIP ---\n",
        "POSSIBLE_PATHS = [\n",
        "    os.path.join(PROJECT_DIR, \"_file\", \"omnivore.zip\"),\n",
        "    os.path.join(PROJECT_DIR, \"data\", \"omnivore.zip\"),\n",
        "    os.path.join(PROJECT_DIR, \"omnivore.zip\"),\n",
        "    # Path specifici colab\n",
        "    \"/content/drive/MyDrive/MistakeDetection/omnivore.zip\",\n",
        "    \"/content/drive/MyDrive/MistakeDetection/data/omnivore.zip\"\n",
        "]\n",
        "\n",
        "ZIP_PATH = None\n",
        "for p in POSSIBLE_PATHS:\n",
        "    if os.path.exists(p):\n",
        "        ZIP_PATH = p\n",
        "        break\n",
        "\n",
        "LOCAL_FEAT_DIR = \"/content/temp_omnivore_features\"\n",
        "\n",
        "if ZIP_PATH is None:\n",
        "    print(f\"âŒ ERRORE: Non trovo 'omnivore.zip'.\")\n",
        "    print(f\"   Ho cercato in: {POSSIBLE_PATHS}\")\n",
        "else:\n",
        "    print(f\"ðŸ“‚ Trovato Zip: {ZIP_PATH}\")\n",
        "    print(f\"â³ Estrazione in: {LOCAL_FEAT_DIR}...\")\n",
        "\n",
        "    if os.path.exists(LOCAL_FEAT_DIR):\n",
        "        try:\n",
        "            shutil.rmtree(LOCAL_FEAT_DIR)\n",
        "        except: pass # Ignora errori permessi\n",
        "    os.makedirs(LOCAL_FEAT_DIR, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(LOCAL_FEAT_DIR)\n",
        "\n",
        "    print(f\"âœ… Estrazione completata.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85190e5b",
      "metadata": {
        "id": "85190e5b"
      },
      "source": [
        "# Features Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a6122b",
      "metadata": {
        "id": "a0a6122b"
      },
      "outputs": [],
      "source": [
        "# @title 4. Inferenza ActionFormer\n",
        "import yaml\n",
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "\n",
        "# --- CONFIGURAZIONE VARIABILI (Self-Contained) ---\n",
        "AF_WORKDIR = \"/content/actionformer_workspace\"\n",
        "# Cerca la repo ActionFormer (potrebbe essere in libs o root)\n",
        "if os.path.exists(os.path.join(AF_WORKDIR, \"multi_step_localization\")):\n",
        "    AF_REPO_PATH = os.path.join(AF_WORKDIR, \"multi_step_localization\")\n",
        "else:\n",
        "    AF_REPO_PATH = AF_WORKDIR # Fallback\n",
        "\n",
        "if 'PROJECT_DIR' not in locals():\n",
        "    if os.path.exists(\"/content/drive/MyDrive/MistakeDetection\"):\n",
        "        PROJECT_DIR = \"/content/drive/MyDrive/MistakeDetection\"\n",
        "    else:\n",
        "        PROJECT_DIR = \"/content/drive/MyDrive/CaptainCook4D\" # Fallback\n",
        "\n",
        "LOCAL_FEAT_DIR = \"/content/temp_omnivore_features\"\n",
        "\n",
        "# --- 1. GESTIONE ANNOTAZIONI ---\n",
        "# Cerchiamo se hai giÃ  il json pronto o se dobbiamo convertirlo\n",
        "ANNOTATION_JSON_TARGET = os.path.join(AF_WORKDIR, \"actionformer_split.json\")\n",
        "USER_ANNOTATION_DIR = os.path.join(PROJECT_DIR, \"annotation_json\")\n",
        "\n",
        "if not os.path.exists(ANNOTATION_JSON_TARGET):\n",
        "    print(\"âš ï¸ 'actionformer_split.json' non trovato. Controllo cartella annotazioni...\")\n",
        "    if os.path.exists(USER_ANNOTATION_DIR):\n",
        "        print(\"ðŸš€ Avvio conversione automatica...\")\n",
        "        converter = os.path.join(AF_REPO_PATH, \"convert_to_action_former_json.py\")\n",
        "        if os.path.exists(converter):\n",
        "            try:\n",
        "                subprocess.run([\"python\", converter,\n",
        "                               \"--annotation_folder\", USER_ANNOTATION_DIR,\n",
        "                               \"--output_file\", ANNOTATION_JSON_TARGET], check=True, cwd=AF_REPO_PATH)\n",
        "                print(\"âœ… Conversione riuscita!\")\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Errore conversione: {e}\")\n",
        "        else:\n",
        "            print(\"âŒ Script convertitore non trovato!\")\n",
        "\n",
        "# --- 2. RICERCA DISPERATA DEL CHECKPOINT ---\n",
        "CKPT_NAME = \"actionformer_best.pth\"\n",
        "MODEL_CKPT = None\n",
        "\n",
        "print(f\"ðŸ” Ricerca {CKPT_NAME} in corso...\")\n",
        "\n",
        "# Lista di posti dove cercare\n",
        "search_locations = [\n",
        "    os.path.join(PROJECT_DIR, \"checkpoints\"),\n",
        "    PROJECT_DIR,\n",
        "    # Cerca anche dentro il repo scaricato (magari Ã¨ in model_outputs o pretrained)\n",
        "    os.path.join(AF_REPO_PATH, \"model_outputs\"),\n",
        "    os.path.join(AF_REPO_PATH, \"checkpoints\"),\n",
        "    os.path.join(AF_REPO_PATH, \"pretrained\"),\n",
        "    AF_REPO_PATH\n",
        "]\n",
        "\n",
        "# 1. Cerca nei path specifici\n",
        "for loc in search_locations:\n",
        "    path = os.path.join(loc, CKPT_NAME)\n",
        "    if os.path.exists(path):\n",
        "        MODEL_CKPT = path\n",
        "        break\n",
        "\n",
        "# 2. Se non trovato, cerca ricorsivamente QUALSIASI .pth nel repo scaricato\n",
        "if not MODEL_CKPT:\n",
        "    print(\"âš ï¸ Checkpoint non trovato nei percorsi standard. Scansione repo...\")\n",
        "    pth_files = glob.glob(os.path.join(AF_REPO_PATH, \"**\", \"*.pth\"), recursive=True)\n",
        "    if pth_files:\n",
        "        # Prendi il file piÃ¹ grande (probabilmente Ã¨ il modello)\n",
        "        best_candidate = max(pth_files, key=os.path.getsize)\n",
        "        print(f\"   -> Trovato possibile candidato: {best_candidate}\")\n",
        "        MODEL_CKPT = best_candidate\n",
        "\n",
        "if not MODEL_CKPT:\n",
        "    print(\"ðŸ›‘ ERRORE BLOCCANTE: Il file dei pesi non c'Ã¨.\")\n",
        "    print(\"   ActionFormer NON Ã¨ incluso nel repo GitHub (Ã¨ troppo grande).\")\n",
        "    print(f\"   Devi scaricarlo dai link forniti nel corso e caricarlo qui: {os.path.join(PROJECT_DIR, 'checkpoints')}\")\n",
        "    # Creiamo la cartella per facilitare l'upload all'utente\n",
        "    os.makedirs(os.path.join(PROJECT_DIR, \"checkpoints\"), exist_ok=True)\n",
        "    raise FileNotFoundError(f\"Manca {CKPT_NAME}\")\n",
        "\n",
        "print(f\"âœ… Modello trovato: {MODEL_CKPT}\")\n",
        "\n",
        "# --- 3. ESECUZIONE ---\n",
        "OUTPUT_INFERENCE = os.path.join(AF_WORKDIR, \"output_results\")\n",
        "os.makedirs(OUTPUT_INFERENCE, exist_ok=True)\n",
        "\n",
        "config_data = {\n",
        "    'dataset': {\n",
        "        'json_file': ANNOTATION_JSON_TARGET,\n",
        "        'feat_folder': LOCAL_FEAT_DIR,\n",
        "        'file_prefix': '',\n",
        "        'file_ext': '.npz',\n",
        "        'input_dim': 1024,\n",
        "        'feat_stride': 16,\n",
        "        'num_classes': 24,\n",
        "        'default_fps': 30,\n",
        "    },\n",
        "    'eval': {\n",
        "        'batch_size': 1,\n",
        "        'nms_score_thres': 0.1,\n",
        "    },\n",
        "    'loader': {'batch_size': 1, 'num_workers': 2},\n",
        "    'model': {\n",
        "        'backbone_arch': [2, 2, 5],\n",
        "        'regression_range': [[0, 4], [4, 8], [8, 16], [16, 32], [32, 10000]],\n",
        "        'fpn_dim': 256, 'head_dim': 512, 'use_abs_pe': False, 'max_buffer_len_factor': 6.0, 'n_mha_win_size': 19\n",
        "    },\n",
        "    'train': {'head_dim': 512}\n",
        "}\n",
        "\n",
        "os.makedirs(os.path.join(AF_REPO_PATH, \"configs\"), exist_ok=True)\n",
        "CONFIG_PATH = os.path.join(AF_REPO_PATH, \"configs\", \"run_config.yaml\")\n",
        "with open(CONFIG_PATH, 'w') as f:\n",
        "    yaml.dump(config_data, f)\n",
        "\n",
        "print(\"ðŸš€ Avvio Inferenza...\")\n",
        "os.chdir(AF_REPO_PATH)\n",
        "!python eval.py \"{CONFIG_PATH}\" \"{MODEL_CKPT}\" --save_results --output_folder \"{OUTPUT_INFERENCE}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68440217",
      "metadata": {
        "id": "68440217"
      },
      "source": [
        "# Pooling, Zipping, Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af9f40c2",
      "metadata": {
        "id": "af9f40c2"
      },
      "outputs": [],
      "source": [
        "# @title 5. Pooling e Export Finale\n",
        "import numpy as np\n",
        "import json\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "if 'PROJECT_DIR' not in locals(): PROJECT_DIR = \"/content/drive/MyDrive/MistakeDetection\"\n",
        "\n",
        "RESULTS_JSON = os.path.join(AF_WORKDIR, \"output_results\", \"results.json\")\n",
        "TEMP_EMB_DIR = os.path.join(AF_WORKDIR, \"step_embeddings_temp\")\n",
        "if os.path.exists(TEMP_EMB_DIR): shutil.rmtree(TEMP_EMB_DIR)\n",
        "os.makedirs(TEMP_EMB_DIR, exist_ok=True)\n",
        "\n",
        "FINAL_DATA_DIR = os.path.join(PROJECT_DIR, \"data\")\n",
        "ZIP_OUTPUT_NAME = \"step_embeddings\"\n",
        "\n",
        "def load_npz(path):\n",
        "    try:\n",
        "        with np.load(path) as data:\n",
        "            if 'features' in data: return data['features']\n",
        "            if 'arr_0' in data: return data['arr_0']\n",
        "            return data[list(data.keys())[0]]\n",
        "    except: return None\n",
        "\n",
        "if os.path.exists(RESULTS_JSON):\n",
        "    print(\"ðŸš€ Inizio elaborazione embedding...\")\n",
        "\n",
        "    with open(RESULTS_JSON, 'r') as f:\n",
        "        data = json.load(f)\n",
        "        preds = data.get('results', data)\n",
        "\n",
        "    # Mappa file locali\n",
        "    file_map = {os.path.basename(f).split('.')[0]: f for f in glob.glob(os.path.join(LOCAL_FEAT_DIR, \"*.npz\"))}\n",
        "\n",
        "    count = 0\n",
        "    fps, stride = 30.0, 16.0\n",
        "    feat_rate = fps / stride\n",
        "\n",
        "    for video_id, segments in preds.items():\n",
        "        feat_path = file_map.get(video_id)\n",
        "        if not feat_path:\n",
        "            candidates = [f for k, f in file_map.items() if video_id in k]\n",
        "            if candidates: feat_path = candidates[0]\n",
        "\n",
        "        if not feat_path: continue\n",
        "\n",
        "        full_feats = load_npz(feat_path)\n",
        "        if full_feats is None: continue\n",
        "\n",
        "        step_embeddings = []\n",
        "        step_metadata = []\n",
        "\n",
        "        for seg in segments:\n",
        "            t_start, t_end = seg['segment']\n",
        "            if seg['score'] < 0.1: continue\n",
        "\n",
        "            s_idx, e_idx = int(t_start * feat_rate), int(t_end * feat_rate)\n",
        "            s_idx, e_idx = max(0, s_idx), min(len(full_feats), e_idx)\n",
        "            if e_idx <= s_idx: e_idx = s_idx + 1\n",
        "\n",
        "            if s_idx < len(full_feats):\n",
        "                pooled = np.mean(full_feats[s_idx:e_idx], axis=0)\n",
        "                step_embeddings.append(pooled)\n",
        "                step_metadata.append(seg)\n",
        "\n",
        "        if step_embeddings:\n",
        "            np.savez_compressed(\n",
        "                os.path.join(TEMP_EMB_DIR, f\"{video_id}_steps.npz\"),\n",
        "                embeddings=np.array(step_embeddings),\n",
        "                metadata=step_metadata\n",
        "            )\n",
        "            count += 1\n",
        "\n",
        "    print(f\"\\nâœ… Generati {count} file .npz\")\n",
        "\n",
        "    # Zipping e Copy su Drive\n",
        "    print(f\"ðŸ“¦ Creazione archivio ZIP...\")\n",
        "    zip_path = shutil.make_archive(\n",
        "        base_name=os.path.join(AF_WORKDIR, ZIP_OUTPUT_NAME),\n",
        "        format='zip',\n",
        "        root_dir=TEMP_EMB_DIR\n",
        "    )\n",
        "\n",
        "    print(f\"â˜ï¸ Upload su Drive: {FINAL_DATA_DIR}...\")\n",
        "    try:\n",
        "        shutil.copy2(zip_path, FINAL_DATA_DIR)\n",
        "        print(f\"âœ… SUCCESSO! File salvato in: {os.path.join(FINAL_DATA_DIR, ZIP_OUTPUT_NAME + '.zip')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Errore durante l'upload: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"âŒ Nessun risultato inferenza trovato. (Verifica Cella 4)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}