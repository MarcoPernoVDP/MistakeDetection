{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a841a958",
   "metadata": {
    "id": "a841a958"
   },
   "source": [
    "# Environement Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee1a5b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cee1a5b4",
    "outputId": "0671fdaf-5e1c-48f2-90de-09811334be38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente locale rilevato.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "try:\n",
    "    from google.colab import drive, userdata\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "REPO_NAME = 'MistakeDetection'\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"â˜ï¸ Colab rilevato.\")\n",
    "    if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
    "\n",
    "    GITHUB_USER = 'MarcoPernoVDP'\n",
    "    try:\n",
    "        TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "        REPO_URL = f'https://{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "    except:\n",
    "        REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "\n",
    "    ROOT_DIR = f'/content/{REPO_NAME}'\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        !git clone {REPO_URL}\n",
    "    else:\n",
    "        %cd {ROOT_DIR}\n",
    "        !git pull\n",
    "        %cd /content\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Ambiente locale rilevato.\")\n",
    "    ROOT_DIR = os.getcwd()\n",
    "    while not os.path.exists(os.path.join(ROOT_DIR, '.gitignore')) and ROOT_DIR != os.path.dirname(ROOT_DIR):\n",
    "        ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
    "\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UtEsNOoRtWa2",
   "metadata": {
    "id": "UtEsNOoRtWa2"
   },
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e181dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73e181dd",
    "outputId": "44928d28-9a42-4447-e9b4-9f2cdfc7b2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Progetto in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\n",
      "source_path: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "Setup Dati da: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "Inizio setup dati...\n",
      "   Sorgente: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "   Destinazione: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n",
      "Copia cartella: annotation_json...\n",
      "Copia cartella: omnivore...\n",
      "âœ… Setup completato! Dati pronti in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\marco\\_netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms339450\u001b[0m (\u001b[33ms339450-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Logged in.\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from utils import setup_project\n",
    "# Ora puoi passare agli import del modello\n",
    "from dataset.utils import SplitType\n",
    "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
    "from models.BaselineV1_MLP import BaselineV1_MLP\n",
    "\n",
    "# Esegue: Setup Dati (unzip/copy), Login WandB, Setup Device\n",
    "device = setup_project.initialize(ROOT_DIR)\n",
    "DATASET_SOURCE = DatasetSource.OMNIVORE\n",
    "SPLIT_TYPE = SplitType.VIDEO_ID\n",
    "# Import wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4728b188",
   "metadata": {
    "id": "4728b188"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ceb697",
   "metadata": {
    "id": "86ceb697"
   },
   "outputs": [],
   "source": [
    "# Configurazione esperimento\n",
    "config = {\n",
    "    \"architecture\": \"BaselineV1_MLP_\" + DATASET_SOURCE.value + \"_\" + SPLIT_TYPE.value,\n",
    "    \"dataset\": \"CaptainCook4D\",\n",
    "    \"feature_extractor\": DATASET_SOURCE.value,\n",
    "    \"input_dim\": DATASET_SOURCE.input_dims(),\n",
    "    \"batch_size\": 512,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 50,\n",
    "    \"pos_weight\": 1.5,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
    "    \"seed\": 42,\n",
    "    \"split_type\": SPLIT_TYPE.value\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c480212",
   "metadata": {
    "id": "1c480212"
   },
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a3a690",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75a3a690",
    "outputId": "5a89f451-08b6-4ba4-b707-e97fa1653865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\\omnivore...\n",
      "\n",
      "=====================================================================================\n",
      "DATASET INFO [V1 - SUBSECOND-BASED]\n",
      "   Shape: torch.Size([8828, 1024]) -> 8828 Campioni, 1024 Features\n",
      "=====================================================================================\n",
      "FULL DATASET       | Tot: 8828   | OK: 4917  (55.7%) | ERR: 3911  (44.3%) | Ratio: 1:1.3\n",
      "-------------------------------------------------------------------------------------\n",
      "TRAIN SET          | Tot: 6104   | OK: 3630  (59.5%) | ERR: 2474  (40.5%) | Ratio: 1:1.5\n",
      "VALIDATION SET     | Tot: 517    | OK: 122   (23.6%) | ERR: 395   (76.4%) | Ratio: 1:0.3\n",
      "TEST SET           | Tot: 2207   | OK: 1165  (52.8%) | ERR: 1042  (47.2%) | Ratio: 1:1.1\n",
      "=====================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
    "from dataset.utils import get_mlp_loaders\n",
    "\n",
    "try:\n",
    "    full_dataset = CaptainCook4DMLP_Dataset(dataset_source=DATASET_SOURCE, root_dir=ROOT_DIR)\n",
    "    train_loader, val_loader, test_loader = get_mlp_loaders(\n",
    "        full_dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        seed=config[\"seed\"],\n",
    "        split_type=SPLIT_TYPE\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Errore: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1485378d",
   "metadata": {
    "id": "1485378d",
    "outputId": "36d729eb-35d2-4917-dd3e-b5cb51107580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "V1 DATASET ITEM [0]\n",
      "================================================================================\n",
      "Features shape:       torch.Size([1024]) (features)\n",
      "Label:                0 (OK)\n",
      "Step id:             3\n",
      "Video id:             1_10\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "full_dataset.print_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a5eed01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a5eed01",
    "outputId": "a226d55a-7b06-409a-a821-31ad91586783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\\omnivore\\1_7_360p.mp4_1s_1s.npz\n",
      "Chiavi presenti nel file: ['arr_0']\n",
      "\n",
      "Array 'arr_0' - shape: (604, 1024), dtype: float32\n",
      "[[ 0.6910985   0.09298898 -0.6608225  ... -0.75679165  1.2401273\n",
      "  -0.5683658 ]\n",
      " [ 0.40254688 -0.4466254  -0.8645446  ... -1.2709565   0.7917245\n",
      "  -0.5052321 ]\n",
      " [ 0.643613   -0.48683766 -0.88651866 ... -1.0358062   0.658605\n",
      "  -0.27201462]]\n"
     ]
    }
   ],
   "source": [
    "from utils.inspect_npz import inspect_npz_from_dataset\n",
    "\n",
    "dataset_folder = DATASET_SOURCE.value\n",
    "npz_filename = \"1_7_360p.mp4_1s_1s.npz\"\n",
    "\n",
    "# Ispezione del file .npz\n",
    "inspect_npz_from_dataset(full_dataset.features_dir(), npz_filename, n_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd232444",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "fd232444",
    "outputId": "87c44967-c514-4b1c-baa9-21f6e615ad72"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251207_210217-nqbm3zzo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/nqbm3zzo' target=\"_blank\">baseline-mlp-v1-omnivore</a></strong> to <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/nqbm3zzo' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/nqbm3zzo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ W&B Run: baseline-mlp-v1-omnivore (ID: nqbm3zzo)\n"
     ]
    }
   ],
   "source": [
    "# Inizializzazione W&B\n",
    "run = wandb.init(\n",
    "    project=\"mistake-detection\",\n",
    "    name=f\"baseline-mlp-v1-{DATASET_SOURCE.value}-{SPLIT_TYPE.value}\",\n",
    "    config=config,\n",
    "    tags=[\"baseline\", \"mlp\", DATASET_SOURCE.value],\n",
    "    notes=f\"Baseline MLP with {DATASET_SOURCE.value} features for mistake detection and {SPLIT_TYPE.value} split\"\n",
    ")\n",
    "\n",
    "print(f\"ğŸš€ W&B Run: {run.name} (ID: {run.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89edd5e",
   "metadata": {
    "id": "d89edd5e"
   },
   "source": [
    "# W&B Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SigNHU8ctaWJ",
   "metadata": {
    "id": "SigNHU8ctaWJ"
   },
   "source": [
    "# MLP (Version 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "O74QGf1Qo2sK",
   "metadata": {
    "id": "O74QGf1Qo2sK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = BaselineV1_MLP(DATASET_SOURCE.input_dims()).to(device)\n",
    "\n",
    "# Watch del modello per tracciare gradienti e parametri\n",
    "wandb.watch(model, log=\"all\", log_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6FdOuKJopr3m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FdOuKJopr3m",
    "outputId": "5c67ccd7-ae70-41b9-9602-297c3ffe5588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso classe positiva: 1.5\n"
     ]
    }
   ],
   "source": [
    "lr = config[\"learning_rate\"]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "# Quanto pesa la classe \"positiva\" = classe \"1\" = classe \"error\":\n",
    "# - CASO 1: rapporto effettivo del dataset\n",
    "#train_pos_weight = train_cnt_0 / train_cnt_1\n",
    "\n",
    "# - CASO 2: rapporto usato nel paper\n",
    "train_pos_weight = config[\"pos_weight\"]\n",
    "\n",
    "print(f\"Peso classe positiva: {train_pos_weight}\")\n",
    "train_pos_weight = torch.tensor([train_pos_weight], device=device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=train_pos_weight)\n",
    "\n",
    "epochs = config[\"epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4u_a6jPgq7OI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4u_a6jPgq7OI",
    "outputId": "b1791b1d-a287-4e0f-feb1-15c26ce79a02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.5426 - Val Loss: 0.7254 - Val Acc: 0.6942 - Val F1: 0.4469 - Val Precision: 0.4791 - Val Recall: 0.4187\n",
      "âœ… Nuovo miglior modello salvato! F1: 0.4469\n",
      "Epoch 2/50 - Train Loss: 0.4897 - Val Loss: 0.7428 - Val Acc: 0.7001 - Val F1: 0.4530 - Val Precision: 0.4903 - Val Recall: 0.4210\n",
      "âœ… Nuovo miglior modello salvato! F1: 0.4530\n",
      "Epoch 3/50 - Train Loss: 0.4520 - Val Loss: 0.7534 - Val Acc: 0.7036 - Val F1: 0.4678 - Val Precision: 0.4974 - Val Recall: 0.4415\n",
      "âœ… Nuovo miglior modello salvato! F1: 0.4678\n",
      "Epoch 4/50 - Train Loss: 0.4243 - Val Loss: 0.7735 - Val Acc: 0.6872 - Val F1: 0.4874 - Val Precision: 0.4718 - Val Recall: 0.5040\n",
      "âœ… Nuovo miglior modello salvato! F1: 0.4874\n",
      "Epoch 5/50 - Train Loss: 0.4042 - Val Loss: 0.7703 - Val Acc: 0.6987 - Val F1: 0.4887 - Val Precision: 0.4894 - Val Recall: 0.4881\n",
      "âœ… Nuovo miglior modello salvato! F1: 0.4887\n",
      "Epoch 6/50 - Train Loss: 0.3856 - Val Loss: 0.7997 - Val Acc: 0.7048 - Val F1: 0.4804 - Val Precision: 0.4996 - Val Recall: 0.4625\n",
      "Epoch 7/50 - Train Loss: 0.3701 - Val Loss: 0.8003 - Val Acc: 0.7041 - Val F1: 0.4983 - Val Precision: 0.4985 - Val Recall: 0.4981\n",
      "âœ… Nuovo miglior modello salvato! F1: 0.4983\n",
      "Epoch 8/50 - Train Loss: 0.3575 - Val Loss: 0.8228 - Val Acc: 0.7111 - Val F1: 0.4810 - Val Precision: 0.5117 - Val Recall: 0.4537\n",
      "Epoch 9/50 - Train Loss: 0.3445 - Val Loss: 0.8266 - Val Acc: 0.7025 - Val F1: 0.4969 - Val Precision: 0.4958 - Val Recall: 0.4980\n",
      "Epoch 10/50 - Train Loss: 0.3349 - Val Loss: 0.8525 - Val Acc: 0.7058 - Val F1: 0.4878 - Val Precision: 0.5015 - Val Recall: 0.4748\n",
      "Epoch 11/50 - Train Loss: 0.3251 - Val Loss: 0.8541 - Val Acc: 0.7065 - Val F1: 0.4972 - Val Precision: 0.5027 - Val Recall: 0.4918\n",
      "Epoch 12/50 - Train Loss: 0.3167 - Val Loss: 0.8652 - Val Acc: 0.7024 - Val F1: 0.4947 - Val Precision: 0.4956 - Val Recall: 0.4938\n",
      "Epoch 13/50 - Train Loss: 0.3091 - Val Loss: 0.8817 - Val Acc: 0.7033 - Val F1: 0.4917 - Val Precision: 0.4972 - Val Recall: 0.4864\n",
      "Epoch 14/50 - Train Loss: 0.3037 - Val Loss: 0.8943 - Val Acc: 0.7065 - Val F1: 0.4940 - Val Precision: 0.5027 - Val Recall: 0.4855\n",
      "Epoch 15/50 - Train Loss: 0.2952 - Val Loss: 0.9480 - Val Acc: 0.7089 - Val F1: 0.4695 - Val Precision: 0.5077 - Val Recall: 0.4367\n",
      "Epoch 16/50 - Train Loss: 0.2910 - Val Loss: 0.9021 - Val Acc: 0.7090 - Val F1: 0.4923 - Val Precision: 0.5073 - Val Recall: 0.4782\n",
      "Epoch 17/50 - Train Loss: 0.2838 - Val Loss: 0.9279 - Val Acc: 0.7057 - Val F1: 0.4983 - Val Precision: 0.5013 - Val Recall: 0.4953\n",
      "Epoch 18/50 - Train Loss: 0.2805 - Val Loss: 0.9355 - Val Acc: 0.7104 - Val F1: 0.4922 - Val Precision: 0.5098 - Val Recall: 0.4758\n",
      "Epoch 19/50 - Train Loss: 0.2741 - Val Loss: 0.9450 - Val Acc: 0.7104 - Val F1: 0.5040 - Val Precision: 0.5093 - Val Recall: 0.4987\n",
      "âœ… Nuovo miglior modello salvato! F1: 0.5040\n",
      "Epoch 20/50 - Train Loss: 0.2690 - Val Loss: 0.9595 - Val Acc: 0.7132 - Val F1: 0.5009 - Val Precision: 0.5147 - Val Recall: 0.4878\n",
      "Epoch 21/50 - Train Loss: 0.2664 - Val Loss: 0.9571 - Val Acc: 0.7131 - Val F1: 0.4970 - Val Precision: 0.5147 - Val Recall: 0.4805\n",
      "Epoch 22/50 - Train Loss: 0.2614 - Val Loss: 1.0167 - Val Acc: 0.7097 - Val F1: 0.4804 - Val Precision: 0.5090 - Val Recall: 0.4548\n",
      "Epoch 23/50 - Train Loss: 0.2552 - Val Loss: 0.9594 - Val Acc: 0.7152 - Val F1: 0.5097 - Val Precision: 0.5178 - Val Recall: 0.5018\n",
      "âœ… Nuovo miglior modello salvato! F1: 0.5097\n",
      "Epoch 24/50 - Train Loss: 0.2554 - Val Loss: 0.9796 - Val Acc: 0.7083 - Val F1: 0.5127 - Val Precision: 0.5055 - Val Recall: 0.5202\n",
      "âœ… Nuovo miglior modello salvato! F1: 0.5127\n",
      "Epoch 25/50 - Train Loss: 0.2516 - Val Loss: 1.0063 - Val Acc: 0.7069 - Val F1: 0.5014 - Val Precision: 0.5033 - Val Recall: 0.4995\n",
      "Epoch 26/50 - Train Loss: 0.2453 - Val Loss: 1.0421 - Val Acc: 0.7119 - Val F1: 0.4912 - Val Precision: 0.5129 - Val Recall: 0.4713\n",
      "Epoch 27/50 - Train Loss: 0.2462 - Val Loss: 1.0309 - Val Acc: 0.7115 - Val F1: 0.5018 - Val Precision: 0.5115 - Val Recall: 0.4925\n",
      "Epoch 28/50 - Train Loss: 0.2405 - Val Loss: 1.0693 - Val Acc: 0.7075 - Val F1: 0.4890 - Val Precision: 0.5045 - Val Recall: 0.4744\n",
      "Epoch 29/50 - Train Loss: 0.2385 - Val Loss: 1.0441 - Val Acc: 0.7114 - Val F1: 0.4936 - Val Precision: 0.5116 - Val Recall: 0.4768\n",
      "Epoch 30/50 - Train Loss: 0.2333 - Val Loss: 1.0741 - Val Acc: 0.7106 - Val F1: 0.4982 - Val Precision: 0.5101 - Val Recall: 0.4869\n",
      "Epoch 31/50 - Train Loss: 0.2322 - Val Loss: 1.0595 - Val Acc: 0.7132 - Val F1: 0.5029 - Val Precision: 0.5147 - Val Recall: 0.4917\n",
      "Epoch 32/50 - Train Loss: 0.2266 - Val Loss: 1.0664 - Val Acc: 0.7140 - Val F1: 0.4996 - Val Precision: 0.5164 - Val Recall: 0.4839\n",
      "Epoch 33/50 - Train Loss: 0.2287 - Val Loss: 1.0769 - Val Acc: 0.7100 - Val F1: 0.5015 - Val Precision: 0.5087 - Val Recall: 0.4944\n",
      "Epoch 34/50 - Train Loss: 0.2245 - Val Loss: 1.1036 - Val Acc: 0.7135 - Val F1: 0.4985 - Val Precision: 0.5154 - Val Recall: 0.4828\n",
      "Epoch 35/50 - Train Loss: 0.2216 - Val Loss: 1.1214 - Val Acc: 0.7134 - Val F1: 0.4921 - Val Precision: 0.5156 - Val Recall: 0.4707\n",
      "Epoch 36/50 - Train Loss: 0.2200 - Val Loss: 1.1212 - Val Acc: 0.7163 - Val F1: 0.4959 - Val Precision: 0.5212 - Val Recall: 0.4729\n",
      "Epoch 37/50 - Train Loss: 0.2165 - Val Loss: 1.1260 - Val Acc: 0.7154 - Val F1: 0.4982 - Val Precision: 0.5192 - Val Recall: 0.4788\n",
      "Epoch 38/50 - Train Loss: 0.2151 - Val Loss: 1.1478 - Val Acc: 0.7136 - Val F1: 0.4930 - Val Precision: 0.5160 - Val Recall: 0.4721\n",
      "Epoch 39/50 - Train Loss: 0.2141 - Val Loss: 1.1590 - Val Acc: 0.7118 - Val F1: 0.4918 - Val Precision: 0.5125 - Val Recall: 0.4727\n",
      "Epoch 40/50 - Train Loss: 0.2110 - Val Loss: 1.1652 - Val Acc: 0.7138 - Val F1: 0.4936 - Val Precision: 0.5164 - Val Recall: 0.4727\n",
      "Epoch 41/50 - Train Loss: 0.2089 - Val Loss: 1.1684 - Val Acc: 0.7182 - Val F1: 0.4943 - Val Precision: 0.5253 - Val Recall: 0.4667\n",
      "Epoch 42/50 - Train Loss: 0.2065 - Val Loss: 1.1822 - Val Acc: 0.7150 - Val F1: 0.4922 - Val Precision: 0.5188 - Val Recall: 0.4681\n",
      "Epoch 43/50 - Train Loss: 0.2072 - Val Loss: 1.1586 - Val Acc: 0.7100 - Val F1: 0.4956 - Val Precision: 0.5090 - Val Recall: 0.4830\n",
      "Epoch 44/50 - Train Loss: 0.2055 - Val Loss: 1.1828 - Val Acc: 0.7131 - Val F1: 0.4989 - Val Precision: 0.5146 - Val Recall: 0.4841\n",
      "Epoch 45/50 - Train Loss: 0.2008 - Val Loss: 1.1922 - Val Acc: 0.7150 - Val F1: 0.4980 - Val Precision: 0.5184 - Val Recall: 0.4792\n",
      "Epoch 46/50 - Train Loss: 0.2001 - Val Loss: 1.2109 - Val Acc: 0.7176 - Val F1: 0.4922 - Val Precision: 0.5241 - Val Recall: 0.4640\n",
      "Epoch 47/50 - Train Loss: 0.2001 - Val Loss: 1.1713 - Val Acc: 0.7132 - Val F1: 0.5020 - Val Precision: 0.5147 - Val Recall: 0.4900\n",
      "Epoch 48/50 - Train Loss: 0.1966 - Val Loss: 1.2025 - Val Acc: 0.7149 - Val F1: 0.4968 - Val Precision: 0.5182 - Val Recall: 0.4771\n",
      "Epoch 49/50 - Train Loss: 0.1969 - Val Loss: 1.2226 - Val Acc: 0.7170 - Val F1: 0.4969 - Val Precision: 0.5224 - Val Recall: 0.4737\n",
      "Epoch 50/50 - Train Loss: 0.1966 - Val Loss: 1.2617 - Val Acc: 0.7162 - Val F1: 0.4878 - Val Precision: 0.5216 - Val Recall: 0.4581\n",
      "\n",
      "ğŸ‰ Training completato!\n",
      "Miglior F1 Score: 0.5127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # -------------------------\n",
    "    #        TRAIN\n",
    "    # -------------------------\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_preds_list = []\n",
    "    train_targets_list = []\n",
    "    train_probs_list = []\n",
    "\n",
    "    for inputs, labels, _, _ in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        outputs = model(inputs)            # [B, 1]\n",
    "        outputs = outputs.squeeze(1)       # [B]\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metriche train\n",
    "        with torch.no_grad():\n",
    "            probs = torch.sigmoid(outputs).cpu()\n",
    "            preds = (probs >= 0.5).long()\n",
    "\n",
    "            train_preds_list.append(preds)\n",
    "            train_targets_list.append(labels.cpu())\n",
    "            train_probs_list.append(probs)\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Metriche di training\n",
    "    train_preds = torch.cat(train_preds_list).numpy()\n",
    "    train_targets = torch.cat(train_targets_list).numpy()\n",
    "    train_probs = torch.cat(train_probs_list).numpy()\n",
    "\n",
    "    train_acc = accuracy_score(train_targets, train_preds)\n",
    "    train_f1 = f1_score(train_targets, train_preds, zero_division=0)\n",
    "    train_precision = precision_score(train_targets, train_preds, zero_division=0)\n",
    "    train_recall = recall_score(train_targets, train_preds, zero_division=0)\n",
    "\n",
    "    # AUC train (usa probabilitÃ , NON predizioni)\n",
    "    try:\n",
    "        train_auc = roc_auc_score(train_targets, train_probs)\n",
    "    except ValueError:\n",
    "        train_auc = 0.0  # Caso raro con classe mancante nel batch\n",
    "\n",
    "    # -------------------------\n",
    "    #        EVAL\n",
    "    # -------------------------\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            outputs = model(inputs).squeeze(1)  # logits\n",
    "\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(outputs).cpu()\n",
    "            preds = (probs >= 0.5).long()\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(labels.cpu())\n",
    "            all_probs.append(probs)\n",
    "\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(test_loader)\n",
    "    val_acc = accuracy_score(all_targets, all_preds)\n",
    "    val_f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
    "    val_precision = precision_score(all_targets, all_preds, zero_division=0)\n",
    "    val_recall = recall_score(all_targets, all_preds, zero_division=0)\n",
    "\n",
    "    # AUC validation\n",
    "    try:\n",
    "        val_auc = roc_auc_score(all_targets, all_probs)\n",
    "    except ValueError:\n",
    "        val_auc = 0.0\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "    # Log su W&B\n",
    "    wandb.log({\n",
    "        # Training metrics\n",
    "        \"train/loss\": avg_train_loss,\n",
    "        \"train/accuracy\": train_acc,\n",
    "        \"train/f1\": train_f1,\n",
    "        \"train/precision\": train_precision,\n",
    "        \"train/recall\": train_recall,\n",
    "        \"train/auc\": train_auc,\n",
    "\n",
    "        # Validation metrics\n",
    "        \"val/loss\": avg_val_loss,\n",
    "        \"val/accuracy\": val_acc,\n",
    "        \"val/f1\": val_f1,\n",
    "        \"val/precision\": val_precision,\n",
    "        \"val/recall\": val_recall,\n",
    "        \"val/auc\": val_auc,\n",
    "\n",
    "        # Confusion Matrix\n",
    "        \"val/confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "            probs=None,\n",
    "            y_true=all_targets,\n",
    "            preds=all_preds,\n",
    "            class_names=[\"No Error\", \"Error\"]\n",
    "        ),\n",
    "\n",
    "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "        \"epoch\": epoch + 1\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} \"\n",
    "          f\"- Train Loss: {avg_train_loss:.4f} \"\n",
    "          f\"- Val Loss: {avg_val_loss:.4f} \"\n",
    "          f\"- Val Acc: {val_acc:.4f} \"\n",
    "          f\"- Val F1: {val_f1:.4f} \"\n",
    "          f\"- Val Precision: {val_precision:.4f} \"\n",
    "          f\"- Val Recall: {val_recall:.4f} \"\n",
    "          f\"- Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # Salvataggio miglior modello\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        checkpoint_path = os.path.join(ROOT_DIR, \"checkpoints\", f\"best_model_f1_{best_f1:.4f}.pth\")\n",
    "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_f1': val_f1,\n",
    "            'val_acc': val_acc,\n",
    "            'val_auc': val_auc,\n",
    "        }, checkpoint_path)\n",
    "\n",
    "        artifact = wandb.Artifact(\n",
    "            name=f\"model-{run.id}\",\n",
    "            type=\"model\",\n",
    "            description=f\"Best model with F1={best_f1:.4f}\",\n",
    "            metadata={\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"val_f1\": val_f1,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"val_auc\": val_auc,\n",
    "                \"architecture\": config[\"architecture\"]\n",
    "            }\n",
    "        )\n",
    "        artifact.add_file(checkpoint_path)\n",
    "        wandb.log_artifact(artifact)\n",
    "\n",
    "        print(f\"âœ… Nuovo miglior modello salvato! F1: {best_f1:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ‰ Training completato!\")\n",
    "print(f\"Miglior F1 Score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f70e8",
   "metadata": {
    "id": "673f70e8"
   },
   "source": [
    "# Results & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf287b55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf287b55",
    "outputId": "b6322ca3-a893-48ed-b9e4-e34153b664ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tabella predizioni e summary caricati su W&B\n"
     ]
    }
   ],
   "source": [
    "# Log della tabella con esempi di predizioni\n",
    "model.eval()\n",
    "predictions_table = wandb.Table(\n",
    "    columns=[\"ID\", \"True Label\", \"Predicted\", \"Probability\", \"Correct\"]\n",
    ")\n",
    "\n",
    "global_id = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, _, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        outputs = model(inputs).squeeze(1)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs >= 0.5).long()\n",
    "\n",
    "        for i in range(min(50, len(labels))):\n",
    "            predictions_table.add_data(\n",
    "                global_id,\n",
    "                labels[i].item(),\n",
    "                preds[i].item(),\n",
    "                probs[i].item(),\n",
    "                preds[i].item() == labels[i].item()\n",
    "            )\n",
    "            global_id += 1\n",
    "\n",
    "        break  # solo un batch\n",
    "\n",
    "wandb.log({\"predictions/sample_table\": predictions_table})\n",
    "\n",
    "# Summary\n",
    "wandb.run.summary[\"best_f1\"] = best_f1\n",
    "wandb.run.summary[\"final_val_acc\"] = val_acc\n",
    "wandb.run.summary[\"final_val_precision\"] = val_precision\n",
    "wandb.run.summary[\"final_val_recall\"] = val_recall\n",
    "\n",
    "print(\"âœ… Tabella predizioni e summary caricati su W&B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68310055",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "id": "68310055",
    "outputId": "57045af9-6fc9-499f-bcbe-3983be3e1031"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/accuracy</td><td>â–â–‚â–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/f1</td><td>â–â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/loss</td><td>â–ˆâ–‡â–†â–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/precision</td><td>â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/recall</td><td>â–â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val/accuracy</td><td>â–ƒâ–„â–…â–â–„â–…â–†â–„â–…â–…â–…â–…â–†â–†â–…â–‡â–‡â–†â–‡â–†â–‡â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–ˆâ–‡â–‡â–ˆ</td></tr><tr><td>val/f1</td><td>â–â–‚â–…â–…â–…â–…â–†â–…â–†â–†â–ƒâ–†â–†â–†â–‡â–†â–…â–ˆâ–ˆâ–‡â–‡â–…â–†â–†â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–…</td></tr><tr><td>val/loss</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–„â–„â–„â–…â–„â–…â–…â–…â–…â–†â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_f1</td><td>0.51274</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>final_val_acc</td><td>0.71616</td></tr><tr><td>final_val_precision</td><td>0.5216</td></tr><tr><td>final_val_recall</td><td>0.45811</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train/accuracy</td><td>0.92597</td></tr><tr><td>train/f1</td><td>0.8799</td></tr><tr><td>train/loss</td><td>0.19655</td></tr><tr><td>train/precision</td><td>0.85301</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">baseline-mlp-v1-omnivore</strong> at: <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/nqbm3zzo' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/nqbm3zzo</a><br> View project at: <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection</a><br>Synced 5 W&B file(s), 51 media file(s), 120 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251207_210217-nqbm3zzo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ W&B run terminato\n"
     ]
    }
   ],
   "source": [
    "# Chiudi il run di W&B\n",
    "wandb.finish()\n",
    "print(\"ğŸ W&B run terminato\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
