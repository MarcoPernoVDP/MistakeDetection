{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a841a958",
      "metadata": {
        "id": "a841a958"
      },
      "source": [
        "# Environement Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cee1a5b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cee1a5b4",
        "outputId": "373a6bda-e57c-4a07-e8b2-425672adba1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚òÅÔ∏è Colab rilevato.\n",
            "Mounted at /content/drive\n",
            "Cloning into 'MistakeDetection'...\n",
            "remote: Enumerating objects: 412, done.\u001b[K\n",
            "remote: Counting objects: 100% (197/197), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 412 (delta 100), reused 137 (delta 50), pack-reused 215 (from 1)\u001b[K\n",
            "Receiving objects: 100% (412/412), 50.03 MiB | 15.51 MiB/s, done.\n",
            "Resolving deltas: 100% (181/181), done.\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    IS_COLAB = True\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "\n",
        "REPO_NAME = 'MistakeDetection'\n",
        "\n",
        "if IS_COLAB:\n",
        "    print(\"‚òÅÔ∏è Colab rilevato.\")\n",
        "    if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
        "\n",
        "    GITHUB_USER = 'MarcoPernoVDP'\n",
        "    try:\n",
        "        TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "        REPO_URL = f'https://{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
        "    except:\n",
        "        REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
        "\n",
        "    ROOT_DIR = f'/content/{REPO_NAME}'\n",
        "    if not os.path.exists(ROOT_DIR):\n",
        "        !git clone {REPO_URL}\n",
        "    else:\n",
        "        %cd {ROOT_DIR}\n",
        "        !git pull\n",
        "        %cd /content\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"Ambiente locale rilevato.\")\n",
        "    ROOT_DIR = os.getcwd()\n",
        "    while not os.path.exists(os.path.join(ROOT_DIR, '.gitignore')) and ROOT_DIR != os.path.dirname(ROOT_DIR):\n",
        "        ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
        "\n",
        "if ROOT_DIR not in sys.path:\n",
        "    sys.path.append(ROOT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UtEsNOoRtWa2",
      "metadata": {
        "id": "UtEsNOoRtWa2"
      },
      "source": [
        "# Dataset Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "73e181dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73e181dd",
        "outputId": "35fb7bdb-4237-486a-a7ee-d6e9d763d745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup Progetto in: /content/MistakeDetection\n",
            "source_path: /content/drive/MyDrive/MistakeDetection\n",
            "Setup Dati da: /content/drive/MyDrive/MistakeDetection\n",
            "Inizio setup dati...\n",
            "   Sorgente: /content/drive/MyDrive/MistakeDetection\n",
            "   Destinazione: /content/MistakeDetection/data\n",
            "Estrazione ZIP: omnivore.zip...\n",
            "Copia cartella: annotation_json...\n",
            "Estrazione ZIP: slowfast.zip...\n",
            "Estrazione ZIP: 3dresnet.zip...\n",
            "Estrazione ZIP: x3d.zip...\n",
            "Estrazione ZIP: omnivore_test.zip...\n",
            "‚úÖ Setup completato! Dati pronti in: /content/MistakeDetection/data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms339450\u001b[0m (\u001b[33ms339450-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WandB Logged in.\n",
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "from utils import setup_project\n",
        "# Ora puoi passare agli import del modello\n",
        "from dataset.utils import SplitType\n",
        "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
        "from models.BaselineV1_MLP import BaselineV1_MLP\n",
        "\n",
        "# Esegue: Setup Dati (unzip/copy), Login WandB, Setup Device\n",
        "device = setup_project.initialize(ROOT_DIR)\n",
        "# Import wandb\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4728b188",
      "metadata": {
        "id": "4728b188"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "86ceb697",
      "metadata": {
        "id": "86ceb697"
      },
      "outputs": [],
      "source": [
        "# Configurazione esperimento\n",
        "DATASET_SOURCE = DatasetSource.OMNIVORE\n",
        "SPLIT_TYPE = SplitType.VIDEO_ID\n",
        "\n",
        "config = {\n",
        "    \"architecture\": \"BaselineV1_MLP_\" + DATASET_SOURCE.value + \"_\" + SPLIT_TYPE.value,\n",
        "    \"dataset\": \"CaptainCook4D\",\n",
        "    \"feature_extractor\": DATASET_SOURCE.value,\n",
        "    \"input_dim\": DATASET_SOURCE.input_dims(),\n",
        "    \"batch_size\": 512,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 50,\n",
        "    \"pos_weight\": 1.5,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
        "    \"seed\": 42,\n",
        "    \"split_type\": SPLIT_TYPE.value\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c480212",
      "metadata": {
        "id": "1c480212"
      },
      "source": [
        "# Dataset Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "75a3a690",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75a3a690",
        "outputId": "c63cb91c-cebf-4e5d-f599-95a7747cb5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading from: /content/MistakeDetection/data/omnivore...\n",
            "\n",
            "=====================================================================================\n",
            "DATASET INFO [V1 - SUBSECOND-BASED]\n",
            "   Shape: torch.Size([283228, 1024]) -> 283228 Campioni, 1024 Features\n",
            "=====================================================================================\n",
            "FULL DATASET       | Tot: 283228 | OK: 198834 (70.2%) | ERR: 84394 (29.8%) | Ratio: 1:2.4\n",
            "-------------------------------------------------------------------------------------\n",
            "TRAIN SET          | Tot: 198102 | OK: 140235 (70.8%) | ERR: 57867 (29.2%) | Ratio: 1:2.4\n",
            "VALIDATION SET     | Tot: 28120  | OK: 21600 (76.8%) | ERR: 6520  (23.2%) | Ratio: 1:3.3\n",
            "TEST SET           | Tot: 57006  | OK: 36999 (64.9%) | ERR: 20007 (35.1%) | Ratio: 1:1.8\n",
            "=====================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
        "from dataset.utils import get_mlp_loaders\n",
        "\n",
        "try:\n",
        "    full_dataset = CaptainCook4DMLP_Dataset(dataset_source=DATASET_SOURCE, root_dir=ROOT_DIR)\n",
        "    train_loader, val_loader, test_loader = get_mlp_loaders(\n",
        "        full_dataset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        seed=config[\"seed\"],\n",
        "        split_type=SPLIT_TYPE\n",
        "    )\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Errore: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1485378d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1485378d",
        "outputId": "1335eea9-86d0-44c7-9ac2-6002ff914263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "V1 DATASET ITEM [0]\n",
            "================================================================================\n",
            "Features shape:       torch.Size([1024]) (features)\n",
            "Label:                0 (OK)\n",
            "Step id:              115\n",
            "Video id:             10_16\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "full_dataset.print_item(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6a5eed01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a5eed01",
        "outputId": "891090a0-e15c-441f-96dc-45485f2c2ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: /content/MistakeDetection/data/omnivore/1_7_360p.mp4_1s_1s.npz\n",
            "Chiavi presenti nel file: ['arr_0']\n",
            "\n",
            "Array 'arr_0' - shape: (604, 1024), dtype: float32\n",
            "[[ 0.6910985   0.09298898 -0.6608225  ... -0.75679165  1.2401273\n",
            "  -0.5683658 ]\n",
            " [ 0.40254688 -0.4466254  -0.8645446  ... -1.2709565   0.7917245\n",
            "  -0.5052321 ]\n",
            " [ 0.643613   -0.48683766 -0.88651866 ... -1.0358062   0.658605\n",
            "  -0.27201462]]\n"
          ]
        }
      ],
      "source": [
        "from utils.inspect_npz import inspect_npz_from_dataset\n",
        "\n",
        "dataset_folder = DATASET_SOURCE.value\n",
        "npz_filename = \"1_7_360p.mp4_1s_1s.npz\"\n",
        "\n",
        "# Ispezione del file .npz\n",
        "inspect_npz_from_dataset(full_dataset.features_dir(), npz_filename, n_rows=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "fd232444",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "fd232444",
        "outputId": "5d05d4c9-1dfd-4440-f1b8-bc6b9c4d01a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251208_121314-mk733ify</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/mk733ify' target=\"_blank\">baseline-mlp-v1-omnivore-video_id</a></strong> to <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/mk733ify' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/mk733ify</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ W&B Run: baseline-mlp-v1-omnivore-video_id (ID: mk733ify)\n"
          ]
        }
      ],
      "source": [
        "# Inizializzazione W&B\n",
        "run = wandb.init(\n",
        "    project=\"mistake-detection\",\n",
        "    name=f\"baseline-mlp-v1-{DATASET_SOURCE.value}-{SPLIT_TYPE.value}\",\n",
        "    config=config,\n",
        "    tags=[\"baseline\", \"mlp\", DATASET_SOURCE.value],\n",
        "    notes=f\"Baseline MLP with {DATASET_SOURCE.value} features for mistake detection and {SPLIT_TYPE.value} split\"\n",
        ")\n",
        "\n",
        "print(f\"üöÄ W&B Run: {run.name} (ID: {run.id})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d89edd5e",
      "metadata": {
        "id": "d89edd5e"
      },
      "source": [
        "# W&B Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SigNHU8ctaWJ",
      "metadata": {
        "id": "SigNHU8ctaWJ"
      },
      "source": [
        "# MLP (Version 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "O74QGf1Qo2sK",
      "metadata": {
        "id": "O74QGf1Qo2sK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = BaselineV1_MLP(DATASET_SOURCE.input_dims()).to(device)\n",
        "\n",
        "# Watch del modello per tracciare gradienti e parametri\n",
        "wandb.watch(model, log=\"all\", log_freq=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6FdOuKJopr3m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FdOuKJopr3m",
        "outputId": "52475b93-e6fc-4507-ecb5-129a459ecb8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peso classe positiva: 1.5\n"
          ]
        }
      ],
      "source": [
        "lr = config[\"learning_rate\"]\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "\n",
        "# Quanto pesa la classe \"positiva\" = classe \"1\" = classe \"error\":\n",
        "# - CASO 1: rapporto effettivo del dataset\n",
        "#train_pos_weight = train_cnt_0 / train_cnt_1\n",
        "\n",
        "# - CASO 2: rapporto usato nel paper\n",
        "train_pos_weight = config[\"pos_weight\"]\n",
        "\n",
        "print(f\"Peso classe positiva: {train_pos_weight}\")\n",
        "train_pos_weight = torch.tensor([train_pos_weight], device=device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=train_pos_weight)\n",
        "\n",
        "epochs = config[\"epochs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "4u_a6jPgq7OI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "4u_a6jPgq7OI",
        "outputId": "cedc1a69-e003-4385-d9d5-d38bd4e92517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Train Loss: 0.6389 - Val Loss: 0.7660 - Val Acc: 0.6882 - Val F1: 0.3073 - Val Precision: 0.3169 - Val Recall: 0.2983 - Val AUC: 0.5846\n",
            "‚úÖ Nuovo miglior modello salvato! avg_val_loss: 0.7660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50 - Train Loss: 0.5112 - Val Loss: 0.7963 - Val Acc: 0.6821 - Val F1: 0.3365 - Val Precision: 0.3260 - Val Recall: 0.3475 - Val AUC: 0.6125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50 - Train Loss: 0.4523 - Val Loss: 0.8009 - Val Acc: 0.6828 - Val F1: 0.3512 - Val Precision: 0.3340 - Val Recall: 0.3704 - Val AUC: 0.6268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50 - Train Loss: 0.4138 - Val Loss: 0.8656 - Val Acc: 0.6784 - Val F1: 0.3371 - Val Precision: 0.3229 - Val Recall: 0.3526 - Val AUC: 0.6103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50 - Train Loss: 0.3844 - Val Loss: 0.9459 - Val Acc: 0.7037 - Val F1: 0.3232 - Val Precision: 0.3436 - Val Recall: 0.3051 - Val AUC: 0.6147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50 - Train Loss: 0.3614 - Val Loss: 0.9366 - Val Acc: 0.6629 - Val F1: 0.3431 - Val Precision: 0.3129 - Val Recall: 0.3796 - Val AUC: 0.6002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3854731771.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# [B, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# [B]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m             \u001b[0;31m# run always called hooks if they have not already been run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1827\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1830\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m                 for hook_id, hook in (\n",
            "\u001b[0;32m/content/MistakeDetection/models/BaselineV1_MLP.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# stabilizza feature Omnivore/SlowFast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1416\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     return (\n\u001b[0;32m-> 1418\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m     )\n\u001b[1;32m   1420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "best_avg_val_loss = np.inf\n",
        "final_val_acc = 0\n",
        "final_val_f1 = 0\n",
        "final_val_precision = 0\n",
        "final_val_recall = 0\n",
        "final_val_auc = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # -------------------------\n",
        "    #        TRAIN\n",
        "    # -------------------------\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds_list = []\n",
        "    train_targets_list = []\n",
        "    train_probs_list = []\n",
        "\n",
        "    for inputs, labels, _, _ in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).float()\n",
        "\n",
        "        outputs = model(inputs)            # [B, 1]\n",
        "        outputs = outputs.squeeze(1)       # [B]\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Metriche train\n",
        "        with torch.no_grad():\n",
        "            probs = torch.sigmoid(outputs).cpu()\n",
        "            preds = (probs >= 0.5).long()\n",
        "\n",
        "            train_preds_list.append(preds)\n",
        "            train_targets_list.append(labels.cpu())\n",
        "            train_probs_list.append(probs)\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Metriche di training\n",
        "    train_preds = torch.cat(train_preds_list).numpy()\n",
        "    train_targets = torch.cat(train_targets_list).numpy()\n",
        "    train_probs = torch.cat(train_probs_list).numpy()\n",
        "\n",
        "    train_acc = accuracy_score(train_targets, train_preds)\n",
        "    train_f1 = f1_score(train_targets, train_preds, zero_division=0)\n",
        "    train_precision = precision_score(train_targets, train_preds, zero_division=0)\n",
        "    train_recall = recall_score(train_targets, train_preds, zero_division=0)\n",
        "\n",
        "    # AUC train (usa probabilit√†, NON predizioni)\n",
        "    try:\n",
        "        train_auc = roc_auc_score(train_targets, train_probs)\n",
        "    except ValueError:\n",
        "        train_auc = 0.0  # Caso raro con classe mancante nel batch\n",
        "\n",
        "    # -------------------------\n",
        "    #        EVAL\n",
        "    # -------------------------\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, _, _ in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device).float()\n",
        "\n",
        "            outputs = model(inputs).squeeze(1)  # logits\n",
        "\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(outputs).cpu()\n",
        "            preds = (probs >= 0.5).long()\n",
        "\n",
        "            all_preds.append(preds)\n",
        "            all_targets.append(labels.cpu())\n",
        "            all_probs.append(probs)\n",
        "\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "    all_probs = torch.cat(all_probs).numpy()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_acc = accuracy_score(all_targets, all_preds)\n",
        "    val_f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
        "    val_precision = precision_score(all_targets, all_preds, zero_division=0)\n",
        "    val_recall = recall_score(all_targets, all_preds, zero_division=0)\n",
        "\n",
        "    # AUC validation\n",
        "    try:\n",
        "        val_auc = roc_auc_score(all_targets, all_probs)\n",
        "    except ValueError:\n",
        "        val_auc = 0.0\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "\n",
        "    # Log su W&B\n",
        "    wandb.log({\n",
        "        # Training metrics\n",
        "        \"train/loss\": avg_train_loss,\n",
        "        \"train/accuracy\": train_acc,\n",
        "        \"train/f1\": train_f1,\n",
        "        \"train/precision\": train_precision,\n",
        "        \"train/recall\": train_recall,\n",
        "        \"train/auc\": train_auc,\n",
        "\n",
        "        # Validation metrics\n",
        "        \"val/loss\": avg_val_loss,\n",
        "        \"val/accuracy\": val_acc,\n",
        "        \"val/f1\": val_f1,\n",
        "        \"val/precision\": val_precision,\n",
        "        \"val/recall\": val_recall,\n",
        "        \"val/auc\": val_auc,\n",
        "\n",
        "        # Confusion Matrix\n",
        "        \"val/confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "            probs=None,\n",
        "            y_true=all_targets,\n",
        "            preds=all_preds,\n",
        "            class_names=[\"No Error\", \"Error\"]\n",
        "        ),\n",
        "\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"epoch\": epoch + 1\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} \"\n",
        "          f\"- Train Loss: {avg_train_loss:.4f} \"\n",
        "          f\"- Val Loss: {avg_val_loss:.4f} \"\n",
        "          f\"- Val Acc: {val_acc:.4f} \"\n",
        "          f\"- Val F1: {val_f1:.4f} \"\n",
        "          f\"- Val Precision: {val_precision:.4f} \"\n",
        "          f\"- Val Recall: {val_recall:.4f} \"\n",
        "          f\"- Val AUC: {val_auc:.4f}\")\n",
        "\n",
        "    # Salvataggio miglior modello\n",
        "    if avg_val_loss < best_avg_val_loss:\n",
        "        best_avg_val_loss = avg_val_loss\n",
        "        final_val_acc = 0\n",
        "        final_val_f1 = val_f1\n",
        "        final_val_precision = val_precision\n",
        "        final_val_recall = val_recall\n",
        "        final_val_auc = val_acc\n",
        "        best_model = model\n",
        "        checkpoint_path = os.path.join(ROOT_DIR, \"checkpoints\", f\"best_model_avg_val_loss_{best_avg_val_loss:.4f}.pth\")\n",
        "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_f1': val_f1,\n",
        "            'val_acc': val_acc,\n",
        "            'val_auc': val_auc,\n",
        "        }, checkpoint_path)\n",
        "\n",
        "        artifact = wandb.Artifact(\n",
        "            name=f\"model-{run.id}\",\n",
        "            type=\"model\",\n",
        "            description=f\"Best model with avg_val_loss={best_avg_val_loss:.4f}\",\n",
        "            metadata={\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"val_f1\": val_f1,\n",
        "                \"val_acc\": val_acc,\n",
        "                \"val_auc\": val_auc,\n",
        "                \"architecture\": config[\"architecture\"]\n",
        "            }\n",
        "        )\n",
        "        artifact.add_file(checkpoint_path)\n",
        "        wandb.log_artifact(artifact)\n",
        "\n",
        "        print(f\"‚úÖ Nuovo miglior modello salvato! avg_val_loss: {best_avg_val_loss:.4f}\")\n",
        "\n",
        "print(\"\\nüéâ Training completato!\")\n",
        "print(f\"Miglior avg_val_loss Score: {best_avg_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "673f70e8",
      "metadata": {
        "id": "673f70e8"
      },
      "source": [
        "# Results & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "cf287b55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf287b55",
        "outputId": "281b551f-d408-4e90-f59c-84ac1e0b5ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Tabella predizioni + metriche complete caricate su W&B\n"
          ]
        }
      ],
      "source": [
        "# Log della tabella con esempi di predizioni\n",
        "best_model.eval()\n",
        "predictions_table = wandb.Table(\n",
        "    columns=[\"ID\", \"True Label\", \"Predicted\", \"Probability\", \"Correct\"]\n",
        ")\n",
        "\n",
        "global_id = 0\n",
        "\n",
        "all_targets = []\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels, _, _ in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).float()\n",
        "\n",
        "        outputs = best_model(inputs).squeeze(1)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs >= 0.5).long()\n",
        "\n",
        "        # Salviamo tutte le metriche del batch\n",
        "        all_targets.append(labels.cpu())\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_probs.append(probs.cpu())\n",
        "\n",
        "        # Campioni per tabella W&B (max 50)\n",
        "        \"\"\"\n",
        "        for i in range(min(50, len(labels))):\n",
        "            predictions_table.add_data(\n",
        "                global_id,\n",
        "                labels[i].item(),\n",
        "                preds[i].item(),\n",
        "                probs[i].item(),\n",
        "                preds[i].item() == labels[i].item()\n",
        "            )\n",
        "            global_id += 1\n",
        "\n",
        "        break  # SOLO un batch, come facevi gi√†\n",
        "        \"\"\"\n",
        "\n",
        "# -------------------------\n",
        "# CALCOLO METRICHE COMPLETO\n",
        "# -------------------------\n",
        "\n",
        "all_targets = torch.cat(all_targets).numpy()\n",
        "all_preds = torch.cat(all_preds).numpy()\n",
        "all_probs = torch.cat(all_probs).numpy()\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "sample_acc = accuracy_score(all_targets, all_preds)\n",
        "sample_precision = precision_score(all_targets, all_preds, zero_division=0)\n",
        "sample_recall = recall_score(all_targets, all_preds, zero_division=0)\n",
        "sample_f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
        "\n",
        "try:\n",
        "    sample_auc = roc_auc_score(all_targets, all_probs)\n",
        "except ValueError:\n",
        "    sample_auc = 0.0\n",
        "\n",
        "sample_cm = confusion_matrix(all_targets, all_preds)\n",
        "\n",
        "# -------------------------\n",
        "# LOG SU W&B\n",
        "# -------------------------\n",
        "\n",
        "wandb.log({\n",
        "    \"predictions/sample_table\": predictions_table,\n",
        "\n",
        "    # Metriche calcolate sul batch del sample table\n",
        "    \"sample/accuracy\": sample_acc,\n",
        "    \"sample/precision\": sample_precision,\n",
        "    \"sample/recall\": sample_recall,\n",
        "    \"sample/f1\": sample_f1,\n",
        "    \"sample/auc\": sample_auc,\n",
        "\n",
        "    # Confusion matrix per il batch\n",
        "    \"sample/confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "        y_true=all_targets,\n",
        "        preds=all_preds,\n",
        "        class_names=[\"No Error\", \"Error\"]\n",
        "    )\n",
        "})\n",
        "\n",
        "# Summary\n",
        "wandb.run.summary[\"best_avg_val_loss\"] = best_avg_val_loss\n",
        "wandb.run.summary[\"final_val_acc\"] = final_val_acc\n",
        "wandb.run.summary[\"final_val_precision\"] = final_val_precision\n",
        "wandb.run.summary[\"final_val_recall\"] = final_val_recall\n",
        "wandb.run.summary[\"final_val_auc\"] = final_val_auc\n",
        "\n",
        "print(\"‚úÖ Tabella predizioni + metriche complete caricate su W&B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "68310055",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "68310055",
        "outputId": "1dfc8e22-d958-4557-87e6-1c4f15a6e3dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ</td></tr><tr><td>learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/accuracy</td><td>‚ñÅ</td></tr><tr><td>train/auc</td><td>‚ñÅ</td></tr><tr><td>train/f1</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>train/precision</td><td>‚ñÅ</td></tr><tr><td>train/recall</td><td>‚ñÅ</td></tr><tr><td>val/accuracy</td><td>‚ñÅ</td></tr><tr><td>val/auc</td><td>‚ñÅ</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train/accuracy</td><td>0.733</td></tr><tr><td>train/auc</td><td>0.75723</td></tr><tr><td>train/f1</td><td>0.50163</td></tr><tr><td>train/loss</td><td>0.63547</td></tr><tr><td>train/precision</td><td>0.55153</td></tr><tr><td>train/recall</td><td>0.46002</td></tr><tr><td>val/accuracy</td><td>0.708</td></tr><tr><td>val/auc</td><td>0.59795</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">baseline-mlp-v1-omnivore-video_id</strong> at: <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/wwk2hv00' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/wwk2hv00</a><br> View project at: <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251208_121022-wwk2hv00/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÅ W&B run terminato\n"
          ]
        }
      ],
      "source": [
        "# Chiudi il run di W&B\n",
        "wandb.finish()\n",
        "print(\"üèÅ W&B run terminato\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.12.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}