{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a841a958",
      "metadata": {
        "id": "a841a958"
      },
      "source": [
        "# Environement Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cee1a5b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cee1a5b4",
        "outputId": "8a58b80c-cb65-49eb-c61e-ec38f11a339a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ambiente locale rilevato.\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    IS_COLAB = True\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "\n",
        "REPO_NAME = 'MistakeDetection'\n",
        "\n",
        "if IS_COLAB:\n",
        "    print(\"‚òÅÔ∏è Colab rilevato.\")\n",
        "    if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
        "\n",
        "    GITHUB_USER = 'MarcoPernoVDP'\n",
        "    try:\n",
        "        TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "        REPO_URL = f'https://{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
        "    except:\n",
        "        REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
        "\n",
        "    ROOT_DIR = f'/content/{REPO_NAME}'\n",
        "    if not os.path.exists(ROOT_DIR):\n",
        "        !git clone {REPO_URL}\n",
        "    else:\n",
        "        %cd {ROOT_DIR}\n",
        "        !git pull\n",
        "        %cd /content\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"Ambiente locale rilevato.\")\n",
        "    ROOT_DIR = os.getcwd()\n",
        "    while not os.path.exists(os.path.join(ROOT_DIR, '.gitignore')) and ROOT_DIR != os.path.dirname(ROOT_DIR):\n",
        "        ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
        "\n",
        "if ROOT_DIR not in sys.path:\n",
        "    sys.path.append(ROOT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UtEsNOoRtWa2",
      "metadata": {
        "id": "UtEsNOoRtWa2"
      },
      "source": [
        "# Dataset Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "73e181dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73e181dd",
        "outputId": "d4cb32b4-8cf6-4a21-f43a-7775028498fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup Progetto in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\n",
            "source_path: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
            "Setup Dati da: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
            "Inizio setup dati...\n",
            "   Sorgente: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
            "   Destinazione: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n",
            "Copia cartella: annotation_json...\n",
            "Copia cartella: omnivore...\n",
            "‚úÖ Setup completato! Dati pronti in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\marco\\_netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms339450\u001b[0m (\u001b[33ms339450-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WandB Logged in.\n",
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "from utils import setup_project\n",
        "# Ora puoi passare agli import del modello\n",
        "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
        "from models.BaselineV1_MLP import BaselineV1_MLP\n",
        "\n",
        "# Esegue: Setup Dati (unzip/copy), Login WandB, Setup Device\n",
        "device = setup_project.initialize(ROOT_DIR)\n",
        "DATASET_SOURCE = DatasetSource.OMNIVORE\n",
        "# Import wandb\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4728b188",
      "metadata": {},
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "86ceb697",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurazione esperimento\n",
        "config = {\n",
        "    \"architecture\": \"BaselineV1_MLP_\" + DATASET_SOURCE.value,\n",
        "    \"dataset\": \"CaptainCook4D\",\n",
        "    \"feature_extractor\": DATASET_SOURCE.value,\n",
        "    \"input_dim\": DATASET_SOURCE.input_dims(),\n",
        "    \"batch_size\": 512,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"epochs\": 100,\n",
        "    \"pos_weight\": 1.5,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
        "    \"seed\": 42\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c480212",
      "metadata": {
        "id": "1c480212"
      },
      "source": [
        "# Dataset Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "75a3a690",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75a3a690",
        "outputId": "33fd56c6-e0be-4083-e4b6-063d490e2fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading from: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\\omnivore...\n",
            "\n",
            "=====================================================================================\n",
            "DATASET INFO [V1 - SUBSECOND-BASED]\n",
            "   Shape: torch.Size([8828, 1024]) -> 8828 Campioni, 1024 Features\n",
            "=====================================================================================\n",
            "FULL DATASET       | Tot: 8828   | OK: 4917  (55.7%) | ERR: 3911  (44.3%) | Ratio: 1:1.3\n",
            "-------------------------------------------------------------------------------------\n",
            "TRAIN SET          | Tot: 6181   | OK: 3383  (54.7%) | ERR: 2798  (45.3%) | Ratio: 1:1.2\n",
            "VALIDATION SET     | Tot: 882    | OK: 516   (58.5%) | ERR: 366   (41.5%) | Ratio: 1:1.4\n",
            "TEST SET           | Tot: 1765   | OK: 1018  (57.7%) | ERR: 747   (42.3%) | Ratio: 1:1.4\n",
            "=====================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
        "from dataset.utils import get_mlp_loaders\n",
        "\n",
        "try:\n",
        "    full_dataset = CaptainCook4DMLP_Dataset(dataset_source=DATASET_SOURCE, root_dir=ROOT_DIR)\n",
        "    train_loader, val_loader, test_loader = get_mlp_loaders(\n",
        "        full_dataset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        seed=config[\"seed\"]\n",
        "    )\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Errore: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1485378d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "V1 DATASET ITEM [0]\n",
            "================================================================================\n",
            "Features shape:       torch.Size([1024]) (features)\n",
            "Label:                0 (OK)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "full_dataset.print_item(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6a5eed01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a5eed01",
        "outputId": "4b0d06be-6ecd-4979-b00c-4e63c94217f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\\omnivore\\1_7_360p.mp4_1s_1s.npz\n",
            "Chiavi presenti nel file: ['arr_0']\n",
            "\n",
            "Array 'arr_0' - shape: (604, 1024), dtype: float32\n",
            "[[ 0.6910985   0.09298898 -0.6608225  ... -0.75679165  1.2401273\n",
            "  -0.5683658 ]\n",
            " [ 0.40254688 -0.4466254  -0.8645446  ... -1.2709565   0.7917245\n",
            "  -0.5052321 ]\n",
            " [ 0.643613   -0.48683766 -0.88651866 ... -1.0358062   0.658605\n",
            "  -0.27201462]]\n"
          ]
        }
      ],
      "source": [
        "from utils.inspect_npz import inspect_npz_from_dataset\n",
        "\n",
        "dataset_folder = DATASET_SOURCE.value\n",
        "npz_filename = \"1_7_360p.mp4_1s_1s.npz\"\n",
        "\n",
        "# Ispezione del file .npz\n",
        "inspect_npz_from_dataset(full_dataset.features_dir(), npz_filename, n_rows=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fd232444",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "fd232444",
        "outputId": "a5214869-46e3-48f5-f017-bcd62ea4bdda"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Inizializzazione W&B\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m run = \u001b[43mwandb\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmistake-detection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbaseline-mlp-v1-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATASET_SOURCE\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbaseline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmlp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASET_SOURCE\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnotes\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBaseline MLP with \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATASET_SOURCE\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m features for mistake detection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müöÄ W&B Run: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:1586\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[39m\n\u001b[32m   1583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_settings.x_server_side_derived_summary:\n\u001b[32m   1584\u001b[39m     init_telemetry.feature.server_side_derived_summary = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1586\u001b[39m run = \u001b[43mwi\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_printer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1588\u001b[39m \u001b[38;5;66;03m# Set up automatic Weave integration if Weave is installed\u001b[39;00m\n\u001b[32m   1589\u001b[39m weave.setup(run_settings.entity, run_settings.project)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:893\u001b[39m, in \u001b[36m_WandbInit.init\u001b[39m\u001b[34m(self, settings, config, run_printer)\u001b[39m\n\u001b[32m    890\u001b[39m service = \u001b[38;5;28mself\u001b[39m._wl.ensure_service()\n\u001b[32m    891\u001b[39m \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33msending inform_init request\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    892\u001b[39m service.inform_init(\n\u001b[32m--> \u001b[39m\u001b[32m893\u001b[39m     settings=\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    894\u001b[39m     run_id=settings.run_id,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    895\u001b[39m )\n\u001b[32m    897\u001b[39m backend = Backend(settings=settings, service=service)\n\u001b[32m    898\u001b[39m backend.ensure_launched()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\wandb\\sdk\\wandb_settings.py:2005\u001b[39m, in \u001b[36mSettings.to_proto\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2000\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate a protobuf representation of the settings.\u001b[39;00m\n\u001b[32m   2001\u001b[39m \n\u001b[32m   2002\u001b[39m \u001b[33;03m<!-- lazydoc-ignore: internal -->\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2004\u001b[39m settings_proto = wandb_settings_pb2.Settings()\n\u001b[32m-> \u001b[39m\u001b[32m2005\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.items():\n\u001b[32m   2006\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m CLIENT_ONLY_SETTINGS:\n\u001b[32m   2007\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\pydantic\\main.py:464\u001b[39m, in \u001b[36mBaseModel.model_dump\u001b[39m\u001b[34m(self, mode, include, exclude, context, by_alias, exclude_unset, exclude_defaults, exclude_none, exclude_computed_fields, round_trip, warnings, fallback, serialize_as_any)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_dump\u001b[39m(\n\u001b[32m    419\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    420\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    433\u001b[39m     serialize_as_any: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    434\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    435\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"!!! abstract \"Usage Documentation\"\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[33;03m        [`model_dump`](../concepts/serialization.md#python-mode)\u001b[39;00m\n\u001b[32m    437\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    462\u001b[39m \u001b[33;03m        A dictionary representation of the model.\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_serializer__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_computed_fields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_computed_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mround_trip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mround_trip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialize_as_any\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialize_as_any\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\wandb\\sdk\\wandb_settings.py:1651\u001b[39m, in \u001b[36mSettings._os\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1647\u001b[39m \u001b[38;5;129m@computed_field\u001b[39m  \u001b[38;5;66;03m# type: ignore[prop-decorator]\u001b[39;00m\n\u001b[32m   1648\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   1649\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_os\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m   1650\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The operating system of the machine running the script.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1651\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplatform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplatform\u001b[49m\u001b[43m(\u001b[49m\u001b[43maliased\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\platform.py:1259\u001b[39m, in \u001b[36mplatform\u001b[39m\u001b[34m(aliased, terse)\u001b[39m\n\u001b[32m   1255\u001b[39m         release = macos_release\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m system == \u001b[33m'\u001b[39m\u001b[33mWindows\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1258\u001b[39m     \u001b[38;5;66;03m# MS platforms\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     rel, vers, csd, ptype = \u001b[43mwin32_ver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m terse:\n\u001b[32m   1261\u001b[39m         platform = _platform(system, release)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\platform.py:449\u001b[39m, in \u001b[36mwin32_ver\u001b[39m\u001b[34m(release, version, csd, ptype)\u001b[39m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwin32_ver\u001b[39m(release=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, version=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, csd=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, ptype=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    447\u001b[39m     is_client = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     version, csd, ptype, is_client = \u001b[43m_win32_ver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m version:\n\u001b[32m    452\u001b[39m         intversion = \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, version.split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\platform.py:387\u001b[39m, in \u001b[36m_win32_ver\u001b[39m\u001b[34m(version, csd, ptype)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_win32_ver\u001b[39m(version, csd, ptype):\n\u001b[32m    385\u001b[39m     \u001b[38;5;66;03m# Try using WMI first, as this is the canonical source of data\u001b[39;00m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m         (version, product_type, ptype, spmajor, spminor)  = \u001b[43m_wmi_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mOS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mVersion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mProductType\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBuildType\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mServicePackMajorVersion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mServicePackMinorVersion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m         is_client = (\u001b[38;5;28mint\u001b[39m(product_type) == \u001b[32m1\u001b[39m)\n\u001b[32m    396\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m spminor \u001b[38;5;129;01mand\u001b[39;00m spminor != \u001b[33m'\u001b[39m\u001b[33m0\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\platform.py:327\u001b[39m, in \u001b[36m_wmi_query\u001b[39m\u001b[34m(table, *keys)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wmi_query\u001b[39m(table, *keys):\n\u001b[32m    323\u001b[39m     table = {\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOS\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWin32_OperatingSystem\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    325\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCPU\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWin32_Processor\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    326\u001b[39m     }[table]\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     data = \u001b[43m_wmi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_query\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSELECT \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m FROM \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.split(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\0\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    331\u001b[39m     split_data = (i.partition(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[32m    332\u001b[39m     dict_data = {i[\u001b[32m0\u001b[39m]: i[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m split_data}\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Inizializzazione W&B\n",
        "run = wandb.init(\n",
        "    project=\"mistake-detection\",\n",
        "    name=f\"baseline-mlp-v1-{DATASET_SOURCE.value}\",\n",
        "    config=config,\n",
        "    tags=[\"baseline\", \"mlp\", DATASET_SOURCE.value],\n",
        "    notes=f\"Baseline MLP with {DATASET_SOURCE.value} features for mistake detection\"\n",
        ")\n",
        "\n",
        "print(f\"üöÄ W&B Run: {run.name} (ID: {run.id})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d89edd5e",
      "metadata": {
        "id": "d89edd5e"
      },
      "source": [
        "# W&B Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SigNHU8ctaWJ",
      "metadata": {
        "id": "SigNHU8ctaWJ"
      },
      "source": [
        "# MLP (Version 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O74QGf1Qo2sK",
      "metadata": {
        "id": "O74QGf1Qo2sK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = BaselineV1_MLP(DATASET_SOURCE.input_dims()).to(device)\n",
        "\n",
        "# Watch del modello per tracciare gradienti e parametri\n",
        "wandb.watch(model, log=\"all\", log_freq=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6FdOuKJopr3m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FdOuKJopr3m",
        "outputId": "57233821-2e98-4535-c1d4-591e8947b408"
      },
      "outputs": [],
      "source": [
        "lr = config[\"learning_rate\"]\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "\n",
        "# Quanto pesa la classe \"positiva\" = classe \"1\" = classe \"error\":\n",
        "# - CASO 1: rapporto effettivo del dataset\n",
        "#train_pos_weight = train_cnt_0 / train_cnt_1\n",
        "\n",
        "# - CASO 2: rapporto usato nel paper\n",
        "train_pos_weight = config[\"pos_weight\"]\n",
        "\n",
        "print(f\"Peso classe positiva: {train_pos_weight}\")\n",
        "train_pos_weight = torch.tensor([train_pos_weight], device=device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=train_pos_weight)\n",
        "\n",
        "epochs = config[\"epochs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4u_a6jPgq7OI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u_a6jPgq7OI",
        "outputId": "13345508-7fdf-4fa8-8e38-eb9ce91f13b1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "best_f1 = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # -------------------------\n",
        "    #        TRAIN\n",
        "    # -------------------------\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds_list = []\n",
        "    train_targets_list = []\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).float()\n",
        "\n",
        "        outputs = model(inputs)            # [B, 1]\n",
        "        outputs = outputs.squeeze(1)       # [B]\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Raccolta predizioni per metriche di train\n",
        "        with torch.no_grad():\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (probs >= 0.5).long()\n",
        "            train_preds_list.append(preds.cpu())\n",
        "            train_targets_list.append(labels.cpu())\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Metriche di training\n",
        "    train_preds = torch.cat(train_preds_list).numpy()\n",
        "    train_targets = torch.cat(train_targets_list).numpy()\n",
        "    train_acc = accuracy_score(train_targets, train_preds)\n",
        "    train_f1 = f1_score(train_targets, train_preds, zero_division=0)\n",
        "    train_precision = precision_score(train_targets, train_preds, zero_division=0)\n",
        "    train_recall = recall_score(train_targets, train_preds, zero_division=0)\n",
        "\n",
        "    # -------------------------\n",
        "    #        EVAL\n",
        "    # -------------------------\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device).float()\n",
        "\n",
        "            outputs = model(inputs).squeeze(1)  # logits\n",
        "\n",
        "            # same loss as train\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "            # convert logits ‚Üí probabilities ‚Üí binary predictions\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (probs >= 0.5).long()\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_targets.append(labels.cpu())\n",
        "            all_probs.append(probs.cpu())\n",
        "\n",
        "    # concat\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "    all_probs = torch.cat(all_probs).numpy()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(test_loader)\n",
        "    val_acc = accuracy_score(all_targets, all_preds)\n",
        "    val_f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
        "    val_precision = precision_score(all_targets, all_preds, zero_division=0)\n",
        "    val_recall = recall_score(all_targets, all_preds, zero_division=0)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "\n",
        "    # Log su W&B\n",
        "    wandb.log({\n",
        "        # Training metrics\n",
        "        \"train/loss\": avg_train_loss,\n",
        "        \"train/accuracy\": train_acc,\n",
        "        \"train/f1\": train_f1,\n",
        "        \"train/precision\": train_precision,\n",
        "        \"train/recall\": train_recall,\n",
        "\n",
        "        # Validation metrics\n",
        "        \"val/loss\": avg_val_loss,\n",
        "        \"val/accuracy\": val_acc,\n",
        "        \"val/f1\": val_f1,\n",
        "        \"val/precision\": val_precision,\n",
        "        \"val/recall\": val_recall,\n",
        "\n",
        "        # Confusion Matrix\n",
        "        \"val/confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "            probs=None,\n",
        "            y_true=all_targets,\n",
        "            preds=all_preds,\n",
        "            class_names=[\"No Error\", \"Error\"]\n",
        "        ),\n",
        "\n",
        "        # Learning\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"epoch\": epoch + 1\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} \"\n",
        "          f\"- Train Loss: {avg_train_loss:.4f} \"\n",
        "          f\"- Val Loss: {avg_val_loss:.4f} \"\n",
        "          f\"- Val Acc: {val_acc:.4f} \"\n",
        "          f\"- Val F1: {val_f1:.4f} \"\n",
        "          f\"- Val Precision: {val_precision:.4f} \"\n",
        "          f\"- Val Recall: {val_recall:.4f}\")\n",
        "\n",
        "    # Salva il miglior modello\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        checkpoint_path = os.path.join(ROOT_DIR, \"checkpoints\", f\"best_model_f1_{best_f1:.4f}.pth\")\n",
        "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_f1': val_f1,\n",
        "            'val_acc': val_acc,\n",
        "        }, checkpoint_path)\n",
        "\n",
        "        # Salva come artifact su W&B\n",
        "        artifact = wandb.Artifact(\n",
        "            name=f\"model-{run.id}\",\n",
        "            type=\"model\",\n",
        "            description=f\"Best model with F1={best_f1:.4f}\",\n",
        "            metadata={\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"val_f1\": val_f1,\n",
        "                \"val_acc\": val_acc,\n",
        "                \"architecture\": config[\"architecture\"]\n",
        "            }\n",
        "        )\n",
        "        artifact.add_file(checkpoint_path)\n",
        "        wandb.log_artifact(artifact)\n",
        "\n",
        "        print(f\"‚úÖ Nuovo miglior modello salvato! F1: {best_f1:.4f}\")\n",
        "\n",
        "print(\"\\nüéâ Training completato!\")\n",
        "print(f\"Miglior F1 Score: {best_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "673f70e8",
      "metadata": {
        "id": "673f70e8"
      },
      "source": [
        "# Results & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf287b55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf287b55",
        "outputId": "555886e6-4b62-4a49-d37d-94c46f44657f"
      },
      "outputs": [],
      "source": [
        "# Log della tabella con esempi di predizioni\n",
        "model.eval()\n",
        "predictions_table = wandb.Table(\n",
        "    columns=[\"ID\", \"True Label\", \"Predicted\", \"Probability\", \"Correct\"]\n",
        ")\n",
        "\n",
        "global_id = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).float()\n",
        "\n",
        "        outputs = model(inputs).squeeze(1)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs >= 0.5).long()\n",
        "\n",
        "        for i in range(min(50, len(labels))):\n",
        "            predictions_table.add_data(\n",
        "                global_id,\n",
        "                labels[i].item(),\n",
        "                preds[i].item(),\n",
        "                probs[i].item(),\n",
        "                preds[i].item() == labels[i].item()\n",
        "            )\n",
        "            global_id += 1\n",
        "\n",
        "        break  # solo un batch\n",
        "\n",
        "wandb.log({\"predictions/sample_table\": predictions_table})\n",
        "\n",
        "# Summary\n",
        "wandb.run.summary[\"best_f1\"] = best_f1\n",
        "wandb.run.summary[\"final_val_acc\"] = val_acc\n",
        "wandb.run.summary[\"final_val_precision\"] = val_precision\n",
        "wandb.run.summary[\"final_val_recall\"] = val_recall\n",
        "\n",
        "print(\"‚úÖ Tabella predizioni e summary caricati su W&B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68310055",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "68310055",
        "outputId": "344af75f-3aea-49c2-e9de-77de00022ff5"
      },
      "outputs": [],
      "source": [
        "# Chiudi il run di W&B\n",
        "wandb.finish()\n",
        "print(\"üèÅ W&B run terminato\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.12.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
