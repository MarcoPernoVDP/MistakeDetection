{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00db5f23",
      "metadata": {
        "id": "00db5f23"
      },
      "source": [
        "# Environement Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d301206b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d301206b",
        "outputId": "51428ffb-28ee-413d-b34f-1d0fe4fffd55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚òÅÔ∏è Colab rilevato.\n",
            "Mounted at /content/drive\n",
            "Cloning into 'MistakeDetection'...\n",
            "remote: Enumerating objects: 746, done.\u001b[K\n",
            "remote: Counting objects: 100% (213/213), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 746 (delta 131), reused 100 (delta 47), pack-reused 533 (from 1)\u001b[K\n",
            "Receiving objects: 100% (746/746), 86.52 MiB | 16.01 MiB/s, done.\n",
            "Resolving deltas: 100% (403/403), done.\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    IS_COLAB = True\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "\n",
        "REPO_NAME = 'MistakeDetection'\n",
        "\n",
        "if IS_COLAB:\n",
        "    print(\"‚òÅÔ∏è Colab rilevato.\")\n",
        "    if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
        "\n",
        "    GITHUB_USER = 'MarcoPernoVDP'\n",
        "    try:\n",
        "        TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "        REPO_URL = f'https://{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
        "    except:\n",
        "        REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
        "\n",
        "    ROOT_DIR = f'/content/{REPO_NAME}'\n",
        "    if not os.path.exists(ROOT_DIR):\n",
        "        !git clone {REPO_URL}\n",
        "    else:\n",
        "        %cd {ROOT_DIR}\n",
        "        !git pull\n",
        "        %cd /content\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"Ambiente locale rilevato.\")\n",
        "    ROOT_DIR = os.getcwd()\n",
        "    while not os.path.exists(os.path.join(ROOT_DIR, '.gitignore')) and ROOT_DIR != os.path.dirname(ROOT_DIR):\n",
        "        ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
        "\n",
        "if ROOT_DIR not in sys.path:\n",
        "    sys.path.append(ROOT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf787bb",
      "metadata": {
        "id": "edf787bb"
      },
      "source": [
        "# Dataset Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b5150539",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5150539",
        "outputId": "1acdb4f1-9ef1-4733-a289-7d63b0aa004f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup Progetto in: /content/MistakeDetection\n",
            "source_path: /content/drive/MyDrive/MistakeDetection\n",
            "Setup Dati da: /content/drive/MyDrive/MistakeDetection\n",
            "Inizio setup dati...\n",
            "   Sorgente: /content/drive/MyDrive/MistakeDetection\n",
            "   Destinazione: /content/MistakeDetection/data\n",
            "Estrazione ZIP: omnivore.zip...\n",
            "Copia cartella: annotation_json...\n",
            "Estrazione ZIP: slowfast.zip...\n",
            "Estrazione ZIP: 3dresnet.zip...\n",
            "Estrazione ZIP: x3d.zip...\n",
            "Estrazione ZIP: omnivore_test.zip...\n",
            "Estrazione ZIP: error_recognition_best.zip...\n",
            "Estrazione ZIP: features.zip...\n",
            "Estrazione ZIP: perceptionencoder.zip...\n",
            "Estrazione ZIP: egovlp.zip...\n",
            "Copia cartella: hungarian_results...\n",
            "Copia cartella: task_graphs...\n",
            "Copia cartella: recipe_text_step_embeddings...\n",
            "‚úÖ Setup completato! Dati pronti in: /content/MistakeDetection/data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms338793\u001b[0m (\u001b[33ms339450-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WandB Logged in.\n",
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "from utils import setup_project\n",
        "# Ora puoi passare agli import del modello\n",
        "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
        "from models.BaselineV2_Transformer import BaselineV2_Transformer\n",
        "from dataset.utils import SplitType\n",
        "\n",
        "# Esegue: Setup Dati (unzip/copy), Login WandB, Setup Device\n",
        "device = setup_project.initialize(ROOT_DIR)\n",
        "\n",
        "# Import wandb\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e42308",
      "metadata": {
        "id": "a3e42308"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "a5a7e990",
      "metadata": {
        "id": "a5a7e990"
      },
      "outputs": [],
      "source": [
        "# Configurazione esperimento\n",
        "DATASET_SOURCE = DatasetSource.HIERO\n",
        "\n",
        "config = {\n",
        "    \"dataset\": \"CaptainCook4D\",\n",
        "    \"feature_extractor\": DATASET_SOURCE.value,\n",
        "    \"input_dim\": DATASET_SOURCE.input_dims(),\n",
        "    \"batch_size\": 16,\n",
        "    \"learning_rate\": 8e-4,\n",
        "    \"epochs\": 10,\n",
        "    \"pos_weight\": 0.75,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
        "    \"seed\": 42,\n",
        "    \"weight_decay\": 1e-5,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a88f766",
      "metadata": {
        "id": "4a88f766"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a2f0f9e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2f0f9e2",
        "outputId": "d6f678f0-d9e1-4cb4-e932-729279061e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading video embeddings...\n",
            "Loading Hungarian matching results...\n",
            "Loading error annotations...\n",
            "Dataset initialized with 384 samples\n"
          ]
        }
      ],
      "source": [
        "from dataset.dagnn_dataset import DAGNNDataset\n",
        "\n",
        "if IS_COLAB:\n",
        "  dataset = DAGNNDataset(\n",
        "      video_embeddings_path=os.path.join(\"/content/drive/MyDrive/MistakeDetection\", \"hiero_all_video_steps.npz\"),\n",
        "      recipe_embeddings_dir=os.path.join(\"/content/drive/MyDrive/MistakeDetection\", \"recipe_text_step_embeddings\"),\n",
        "      hungarian_results_path=os.path.join(\"/content/drive/MyDrive/MistakeDetection\", \"hungarian_results\", \"hungarian_matching_results.json\"),\n",
        "      annotation_path=os.path.join(\"/content/drive/MyDrive/MistakeDetection\", \"annotation_json\", \"video_level_annotations.json\"),\n",
        "  )\n",
        "else:\n",
        "  dataset = DAGNNDataset(\n",
        "      video_embeddings_path=os.path.join(ROOT_DIR, \"data\", \"hiero_all_video_steps.npz\"),\n",
        "      recipe_embeddings_dir=os.path.join(ROOT_DIR, \"data\", \"recipe_text_step_embeddings\"),\n",
        "      hungarian_results_path=os.path.join(ROOT_DIR, \"hungarian_results\", \"hungarian_matching_results.json\"),\n",
        "      annotation_path=os.path.join(ROOT_DIR, \"data\", \"annotation_json\", \"video_level_annotations.json\"),\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c017fcea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c017fcea",
        "outputId": "f603ff37-5ee0-4658-95a3-f787c83427cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([21, 1536])\n",
            "tensor([[14, 15,  1,  7, 18,  2, 11,  5,  3, 17, 19, 13, 16,  8, 10,  4,  6, 12,\n",
            "          0,  9, 15],\n",
            "        [ 1,  2,  3,  4,  5, 20,  7,  8,  9, 10, 11, 12, 13, 14, 15, 17, 18, 19,\n",
            "         16, 20,  6]])\n"
          ]
        }
      ],
      "source": [
        "print(dataset[1]['node_features'].shape)  # Esempio di accesso ai dati\n",
        "print(dataset[1]['edge_index'])  # Esempio di accesso agli indici degli edge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "898401a7",
      "metadata": {
        "id": "898401a7"
      },
      "source": [
        "# Leave-One-Out Cross-Validation Setup\n",
        "\n",
        "Raggruppiamo i video per ricetta per fare LOO CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "291b839f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "291b839f",
        "outputId": "28faf793-25b6-4ec5-9853-1d51832b0773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "LEAVE-ONE-OUT CROSS-VALIDATION SETUP\n",
            "================================================================================\n",
            "Total videos: 384\n",
            "Total recipes: 24\n",
            "\n",
            "Videos per recipe:\n",
            "  blenderbananapancakes         : 19 videos\n",
            "  breakfastburritos             : 16 videos\n",
            "  broccolistirfry               : 16 videos\n",
            "  buttercorncup                 : 14 videos\n",
            "  capresebruschetta             : 18 videos\n",
            "  cheesepimiento                : 15 videos\n",
            "  coffee                        : 15 videos\n",
            "  cucumberraita                 : 20 videos\n",
            "  dressedupmeatballs            : 16 videos\n",
            "  herbomeletwithfriedtomatoes   : 17 videos\n",
            "  microwaveeggsandwich          : 18 videos\n",
            "  microwavefrenchtoast          : 14 videos\n",
            "  microwavemugpizza             : 13 videos\n",
            "  mugcake                       : 17 videos\n",
            "  panfriedtofu                  : 15 videos\n",
            "  pinwheels                     : 12 videos\n",
            "  ramen                         : 17 videos\n",
            "  sautedmushrooms               : 14 videos\n",
            "  scrambledeggs                 : 16 videos\n",
            "  spicedhotchocolate            : 16 videos\n",
            "  spicytunaavocadowraps         : 18 videos\n",
            "  tomatochutney                 : 15 videos\n",
            "  tomatomozzarellasalad         : 18 videos\n",
            "  zoodles                       : 15 videos\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Raggruppa i video per ricetta\n",
        "recipe_to_indices = defaultdict(list)\n",
        "for idx in range(len(dataset)):\n",
        "    sample = dataset.samples[idx]\n",
        "    recipe_name = sample['recipe_name']\n",
        "    recipe_to_indices[recipe_name].append(idx)\n",
        "\n",
        "# Ordina le ricette per avere un ordine consistente\n",
        "recipes = sorted(recipe_to_indices.keys())\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"LEAVE-ONE-OUT CROSS-VALIDATION SETUP\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Total videos: {len(dataset)}\")\n",
        "print(f\"Total recipes: {len(recipes)}\")\n",
        "print(f\"\\nVideos per recipe:\")\n",
        "for recipe_name in recipes:\n",
        "    print(f\"  {recipe_name:<30}: {len(recipe_to_indices[recipe_name])} videos\")\n",
        "print(f\"{'='*80}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b96e646",
      "metadata": {
        "id": "6b96e646"
      },
      "source": [
        "# DAGNN Model\n",
        "\n",
        "Implementiamo la DAGNN per error detection con:\n",
        "- ProjectionLayer per ridurre dimensioni (1536 ‚Üí 256)\n",
        "- Graph Convolutional layers\n",
        "- Global pooling\n",
        "- Binary classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "P08LwiQCC_2u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P08LwiQCC_2u",
        "outputId": "64eef62a-978b-4d26-fabd-be4b265c0c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "84ebf70e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ebf70e",
        "outputId": "67528b0c-c98e-4ed5-dc7b-e1f5184d3916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ DAGNN model implementato con regolarizzazione aumentata\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "\n",
        "class DAGNN(nn.Module):\n",
        "    \"\"\"\n",
        "    DAGNN model for cooking mistake detection.\n",
        "\n",
        "    Architecture:\n",
        "    1. ProjectionLayer: [1536] ‚Üí [128] (ridotto da 256)\n",
        "    2. 2 GCN layers (ridotto da 3)\n",
        "    3. Global pooling over nodes\n",
        "    4. Binary classifier (error/no error)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int = 1536,\n",
        "        hidden_dim: int = 128,  # Ridotto da 256\n",
        "        num_gnn_layers: int = 1,  # Ridotto da 3\n",
        "        dropout: float = 0.4,  # Bilanciato\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Feature projection (learnable combination of text + visual)\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "        )\n",
        "\n",
        "        # GNN layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.norms = nn.ModuleList()  # Aggiunto Layer Norm per ogni GNN layer\n",
        "        for i in range(num_gnn_layers):\n",
        "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
        "            self.norms.append(nn.LayerNorm(hidden_dim))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Binary classifier - pi√π semplice\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1),  # Binary output\n",
        "        )\n",
        "\n",
        "    def forward(self, batch_data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            batch_data: Batched PyG Data object with:\n",
        "                - x: [total_nodes, 1536] node features\n",
        "                - edge_index: [2, total_edges] edges\n",
        "                - batch: [total_nodes] batch assignment\n",
        "\n",
        "        Returns:\n",
        "            logits: [batch_size, 1] - logits for binary classification\n",
        "            probs: [batch_size, 1] - probabilities after sigmoid\n",
        "        \"\"\"\n",
        "        x = batch_data.x\n",
        "        edge_index = batch_data.edge_index\n",
        "        batch = batch_data.batch\n",
        "\n",
        "        # 1. Project features [total_nodes, 1536] ‚Üí [total_nodes, 128]\n",
        "        x = self.projection(x)\n",
        "\n",
        "        # 2. GNN layers with normalization\n",
        "        for conv, norm in zip(self.convs, self.norms):\n",
        "            x = conv(x, edge_index)\n",
        "            x = norm(x)  # Layer norm per stabilit√†\n",
        "            x = F.relu(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        # 3. Global pooling (one embedding per graph)\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, 128]\n",
        "\n",
        "        # 4. Classification\n",
        "        logits = self.classifier(x)  # [batch_size, 1]\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        return probs, logits\n",
        "\n",
        "print(\"‚úÖ DAGNN model implementato con regolarizzazione aumentata\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "760e60d9",
      "metadata": {
        "id": "760e60d9"
      },
      "source": [
        "# Helper Functions\n",
        "\n",
        "Funzioni per convertire batch in formato PyTorch Geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "e8a809b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a809b4",
        "outputId": "f7a58a4a-74cc-46e4-aab5-50d398eba089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Helper functions aggiornate con validazione edge_index\n"
          ]
        }
      ],
      "source": [
        "from dataset.dagnn_dataset import collate_fn\n",
        "\n",
        "def collate_to_pyg(batch_dict):\n",
        "    \"\"\"\n",
        "    Convert batch from DAGNNDataset to PyTorch Geometric format.\n",
        "\n",
        "    Args:\n",
        "        batch_dict: Dictionary from DAGNN collate_fn\n",
        "\n",
        "    Returns:\n",
        "        Batched PyG Data object\n",
        "    \"\"\"\n",
        "    graphs = []\n",
        "\n",
        "    for i in range(len(batch_dict['node_features'])):\n",
        "        # Verifica che edge_index sia nel formato corretto\n",
        "        edge_index = batch_dict['edge_index'][i]\n",
        "        num_nodes = batch_dict['node_features'][i].shape[0]\n",
        "\n",
        "        # Debug: controlla che gli indici siano validi\n",
        "        if edge_index.numel() > 0:\n",
        "            max_idx = edge_index.max().item()\n",
        "            if max_idx >= num_nodes:\n",
        "                print(f\"‚ö†Ô∏è Warning: edge_index contiene indice {max_idx} ma ci sono solo {num_nodes} nodi\")\n",
        "                # Filtra edge invalidi\n",
        "                valid_edges = (edge_index[0] < num_nodes) & (edge_index[1] < num_nodes)\n",
        "                edge_index = edge_index[:, valid_edges]\n",
        "\n",
        "        graph = Data(\n",
        "            x=batch_dict['node_features'][i],        # [N_i, 1536]\n",
        "            edge_index=edge_index,                    # [2, E_i]\n",
        "            y=batch_dict['labels'][i],               # Scalar\n",
        "        )\n",
        "        graphs.append(graph)\n",
        "\n",
        "    # Batch graphs\n",
        "    batched = Batch.from_data_list(graphs)\n",
        "\n",
        "    return batched\n",
        "\n",
        "print(\"‚úÖ Helper functions aggiornate con validazione edge_index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fba74f92",
      "metadata": {
        "id": "fba74f92"
      },
      "source": [
        "# Leave-One-Out Cross-Validation Training\n",
        "\n",
        "Training con LOO CV: ogni ricetta usata come test set una volta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "ce621a33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ce621a33",
        "outputId": "6ab7c245-2b51-4ce3-9480-b9c659f7a1a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold_1/epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>fold_1/test_accuracy</td><td>‚ñÅ</td></tr><tr><td>fold_1/test_auc</td><td>‚ñÅ</td></tr><tr><td>fold_1/test_f1</td><td>‚ñÅ</td></tr><tr><td>fold_1/test_precision</td><td>‚ñÅ</td></tr><tr><td>fold_1/test_recall</td><td>‚ñÅ</td></tr><tr><td>fold_1/train_accuracy</td><td>‚ñÖ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>fold_1/train_f1</td><td>‚ñá‚ñÉ‚ñà‚ñÜ‚ñÅ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>fold_1/train_loss</td><td>‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>fold_2/epoch</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñà</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold_1/epoch</td><td>10</td></tr><tr><td>fold_1/test_accuracy</td><td>0.36842</td></tr><tr><td>fold_1/test_auc</td><td>0.5</td></tr><tr><td>fold_1/test_f1</td><td>0</td></tr><tr><td>fold_1/test_precision</td><td>0</td></tr><tr><td>fold_1/test_recall</td><td>0</td></tr><tr><td>fold_1/train_accuracy</td><td>0.43014</td></tr><tr><td>fold_1/train_f1</td><td>0</td></tr><tr><td>fold_1/train_loss</td><td>0.59479</td></tr><tr><td>fold_2/epoch</td><td>4</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">LOO-Task2Subtask4-DAGNN-hiero-balanced</strong> at: <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/8yns11y3' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/8yns11y3</a><br> View project at: <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251222_143237-8yns11y3/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251222_143322-u2tm02bl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/u2tm02bl' target=\"_blank\">LOO-Task2Subtask4-DAGNN-hiero-balanced</a></strong> to <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/u2tm02bl' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/u2tm02bl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ W&B Run: LOO-Task2Subtask4-DAGNN-hiero-balanced (ID: u2tm02bl)\n",
            "\n",
            "================================================================================\n",
            "FOLD 1/24 - Testing on Recipe: blenderbananapancakes\n",
            "================================================================================\n",
            "Train videos: 365 | Test videos: 19\n",
            "  Epoch 1/10 - Loss: 0.6015 - Acc: 0.5123 - F1: 0.4765\n",
            "  Epoch 2/10 - Loss: 0.5971 - Acc: 0.5260 - F1: 0.6059\n",
            "  Epoch 3/10 - Loss: 0.5955 - Acc: 0.4986 - F1: 0.4986\n",
            "  Epoch 4/10 - Loss: 0.5912 - Acc: 0.5041 - F1: 0.4180\n",
            "  Epoch 5/10 - Loss: 0.5847 - Acc: 0.5781 - F1: 0.6709\n",
            "  Epoch 6/10 - Loss: 0.5634 - Acc: 0.6164 - F1: 0.6552\n",
            "  Epoch 7/10 - Loss: 0.5619 - Acc: 0.6329 - F1: 0.6716\n",
            "  Epoch 8/10 - Loss: 0.5526 - Acc: 0.6247 - F1: 0.6327\n",
            "  Epoch 9/10 - Loss: 0.5087 - Acc: 0.7068 - F1: 0.7235\n",
            "  Epoch 10/10 - Loss: 0.4534 - Acc: 0.7452 - F1: 0.7669\n",
            "\n",
            "  Test Results for Recipe blenderbananapancakes:\n",
            "    Accuracy: 0.7895\n",
            "    F1: 0.8571\n",
            "    Precision: 0.7500\n",
            "    Recall: 1.0000\n",
            "    AUC: 0.6667\n",
            "\n",
            "================================================================================\n",
            "FOLD 2/24 - Testing on Recipe: breakfastburritos\n",
            "================================================================================\n",
            "Train videos: 368 | Test videos: 16\n",
            "  Epoch 1/10 - Loss: 0.5931 - Acc: 0.5516 - F1: 0.6062\n",
            "  Epoch 2/10 - Loss: 0.5935 - Acc: 0.5245 - F1: 0.5700\n",
            "  Epoch 3/10 - Loss: 0.5952 - Acc: 0.5054 - F1: 0.5625\n",
            "  Epoch 4/10 - Loss: 0.5744 - Acc: 0.5707 - F1: 0.5460\n",
            "  Epoch 5/10 - Loss: 0.5534 - Acc: 0.6359 - F1: 0.6650\n",
            "  Epoch 6/10 - Loss: 0.5234 - Acc: 0.6929 - F1: 0.7196\n",
            "  Epoch 7/10 - Loss: 0.4683 - Acc: 0.7228 - F1: 0.7650\n",
            "  Epoch 8/10 - Loss: 0.4146 - Acc: 0.7772 - F1: 0.8029\n",
            "  Epoch 9/10 - Loss: 0.3480 - Acc: 0.8261 - F1: 0.8469\n",
            "  Epoch 10/10 - Loss: 0.2352 - Acc: 0.9049 - F1: 0.9157\n",
            "\n",
            "  Test Results for Recipe breakfastburritos:\n",
            "    Accuracy: 0.4375\n",
            "    F1: 0.3077\n",
            "    Precision: 0.6667\n",
            "    Recall: 0.2000\n",
            "    AUC: 0.6167\n",
            "\n",
            "================================================================================\n",
            "FOLD 3/24 - Testing on Recipe: broccolistirfry\n",
            "================================================================================\n",
            "Train videos: 368 | Test videos: 16\n",
            "  Epoch 1/10 - Loss: 0.6047 - Acc: 0.4701 - F1: 0.4855\n",
            "  Epoch 2/10 - Loss: 0.5933 - Acc: 0.5245 - F1: 0.5843\n",
            "  Epoch 3/10 - Loss: 0.5795 - Acc: 0.5951 - F1: 0.6682\n",
            "  Epoch 4/10 - Loss: 0.5749 - Acc: 0.5842 - F1: 0.6400\n",
            "  Epoch 5/10 - Loss: 0.5591 - Acc: 0.6359 - F1: 0.6884\n",
            "  Epoch 6/10 - Loss: 0.5240 - Acc: 0.6957 - F1: 0.7443\n",
            "  Epoch 7/10 - Loss: 0.5024 - Acc: 0.7065 - F1: 0.7465\n",
            "  Epoch 8/10 - Loss: 0.4644 - Acc: 0.7446 - F1: 0.7740\n",
            "  Epoch 9/10 - Loss: 0.4295 - Acc: 0.7799 - F1: 0.8121\n",
            "  Epoch 10/10 - Loss: 0.3713 - Acc: 0.8016 - F1: 0.8189\n",
            "\n",
            "  Test Results for Recipe broccolistirfry:\n",
            "    Accuracy: 0.3125\n",
            "    F1: 0.4762\n",
            "    Precision: 0.3333\n",
            "    Recall: 0.8333\n",
            "    AUC: 0.2667\n",
            "\n",
            "================================================================================\n",
            "FOLD 4/24 - Testing on Recipe: buttercorncup\n",
            "================================================================================\n",
            "Train videos: 370 | Test videos: 14\n",
            "  Epoch 1/10 - Loss: 0.6025 - Acc: 0.4973 - F1: 0.5131\n",
            "  Epoch 2/10 - Loss: 0.5840 - Acc: 0.5243 - F1: 0.5028\n",
            "  Epoch 3/10 - Loss: 0.5949 - Acc: 0.5568 - F1: 0.5773\n",
            "  Epoch 4/10 - Loss: 0.5895 - Acc: 0.5703 - F1: 0.6074\n",
            "  Epoch 5/10 - Loss: 0.5604 - Acc: 0.6189 - F1: 0.6635\n",
            "  Epoch 6/10 - Loss: 0.5638 - Acc: 0.6378 - F1: 0.6599\n",
            "  Epoch 7/10 - Loss: 0.5134 - Acc: 0.7189 - F1: 0.7387\n",
            "  Epoch 8/10 - Loss: 0.4751 - Acc: 0.7378 - F1: 0.7640\n",
            "  Epoch 9/10 - Loss: 0.4079 - Acc: 0.7838 - F1: 0.8113\n",
            "  Epoch 10/10 - Loss: 0.3021 - Acc: 0.8892 - F1: 0.9002\n",
            "\n",
            "  Test Results for Recipe buttercorncup:\n",
            "    Accuracy: 0.6429\n",
            "    F1: 0.7826\n",
            "    Precision: 0.6429\n",
            "    Recall: 1.0000\n",
            "    AUC: 0.5111\n",
            "\n",
            "================================================================================\n",
            "FOLD 5/24 - Testing on Recipe: capresebruschetta\n",
            "================================================================================\n",
            "Train videos: 366 | Test videos: 18\n",
            "  Epoch 1/10 - Loss: 0.6023 - Acc: 0.4945 - F1: 0.4411\n",
            "  Epoch 2/10 - Loss: 0.5955 - Acc: 0.5273 - F1: 0.5728\n",
            "  Epoch 3/10 - Loss: 0.5882 - Acc: 0.5464 - F1: 0.5489\n",
            "  Epoch 4/10 - Loss: 0.5803 - Acc: 0.5956 - F1: 0.6652\n",
            "  Epoch 5/10 - Loss: 0.5681 - Acc: 0.5984 - F1: 0.6278\n",
            "  Epoch 6/10 - Loss: 0.5505 - Acc: 0.6421 - F1: 0.6749\n",
            "  Epoch 7/10 - Loss: 0.4941 - Acc: 0.7377 - F1: 0.7788\n",
            "  Epoch 8/10 - Loss: 0.4408 - Acc: 0.7541 - F1: 0.7644\n",
            "  Epoch 9/10 - Loss: 0.3764 - Acc: 0.8197 - F1: 0.8443\n",
            "  Epoch 10/10 - Loss: 0.3381 - Acc: 0.8224 - F1: 0.8338\n",
            "\n",
            "  Test Results for Recipe capresebruschetta:\n",
            "    Accuracy: 0.6667\n",
            "    F1: 0.7500\n",
            "    Precision: 0.7500\n",
            "    Recall: 0.7500\n",
            "    AUC: 0.7500\n",
            "\n",
            "================================================================================\n",
            "FOLD 6/24 - Testing on Recipe: cheesepimiento\n",
            "================================================================================\n",
            "Train videos: 369 | Test videos: 15\n",
            "  Epoch 1/10 - Loss: 0.6099 - Acc: 0.4715 - F1: 0.4855\n",
            "  Epoch 2/10 - Loss: 0.5924 - Acc: 0.5366 - F1: 0.6369\n",
            "  Epoch 3/10 - Loss: 0.5899 - Acc: 0.5393 - F1: 0.6154\n",
            "  Epoch 4/10 - Loss: 0.5847 - Acc: 0.5935 - F1: 0.5924\n",
            "  Epoch 5/10 - Loss: 0.5674 - Acc: 0.6016 - F1: 0.6316\n",
            "  Epoch 6/10 - Loss: 0.5504 - Acc: 0.6369 - F1: 0.6884\n",
            "  Epoch 7/10 - Loss: 0.5305 - Acc: 0.6667 - F1: 0.7106\n",
            "  Epoch 8/10 - Loss: 0.4973 - Acc: 0.7100 - F1: 0.7563\n",
            "  Epoch 9/10 - Loss: 0.4312 - Acc: 0.7778 - F1: 0.8057\n",
            "  Epoch 10/10 - Loss: 0.3645 - Acc: 0.8049 - F1: 0.8269\n",
            "\n",
            "  Test Results for Recipe cheesepimiento:\n",
            "    Accuracy: 0.5333\n",
            "    F1: 0.5333\n",
            "    Precision: 0.6667\n",
            "    Recall: 0.4444\n",
            "    AUC: 0.5556\n",
            "\n",
            "================================================================================\n",
            "FOLD 7/24 - Testing on Recipe: coffee\n",
            "================================================================================\n",
            "Train videos: 369 | Test videos: 15\n",
            "  Epoch 1/10 - Loss: 0.6086 - Acc: 0.4770 - F1: 0.4961\n",
            "  Epoch 2/10 - Loss: 0.5959 - Acc: 0.5501 - F1: 0.6584\n",
            "  Epoch 3/10 - Loss: 0.6036 - Acc: 0.5122 - F1: 0.4675\n",
            "  Epoch 4/10 - Loss: 0.5922 - Acc: 0.5393 - F1: 0.6009\n",
            "  Epoch 5/10 - Loss: 0.5849 - Acc: 0.5881 - F1: 0.6984\n",
            "  Epoch 6/10 - Loss: 0.5712 - Acc: 0.5799 - F1: 0.6210\n",
            "  Epoch 7/10 - Loss: 0.5527 - Acc: 0.6341 - F1: 0.6793\n",
            "  Epoch 8/10 - Loss: 0.5524 - Acc: 0.6802 - F1: 0.7243\n",
            "  Epoch 9/10 - Loss: 0.5177 - Acc: 0.6856 - F1: 0.7171\n",
            "  Epoch 10/10 - Loss: 0.4297 - Acc: 0.7859 - F1: 0.8115\n",
            "\n",
            "  Test Results for Recipe coffee:\n",
            "    Accuracy: 0.6000\n",
            "    F1: 0.6250\n",
            "    Precision: 0.5556\n",
            "    Recall: 0.7143\n",
            "    AUC: 0.5893\n",
            "\n",
            "================================================================================\n",
            "FOLD 8/24 - Testing on Recipe: cucumberraita\n",
            "================================================================================\n",
            "Train videos: 364 | Test videos: 20\n",
            "  Epoch 1/10 - Loss: 0.5914 - Acc: 0.5192 - F1: 0.5431\n",
            "  Epoch 2/10 - Loss: 0.5973 - Acc: 0.5440 - F1: 0.6327\n",
            "  Epoch 3/10 - Loss: 0.5946 - Acc: 0.5027 - F1: 0.5014\n",
            "  Epoch 4/10 - Loss: 0.5846 - Acc: 0.5824 - F1: 0.6766\n",
            "  Epoch 5/10 - Loss: 0.5768 - Acc: 0.5989 - F1: 0.6490\n",
            "  Epoch 6/10 - Loss: 0.5624 - Acc: 0.6401 - F1: 0.7056\n",
            "  Epoch 7/10 - Loss: 0.5404 - Acc: 0.6291 - F1: 0.6565\n",
            "  Epoch 8/10 - Loss: 0.5318 - Acc: 0.6648 - F1: 0.7336\n",
            "  Epoch 9/10 - Loss: 0.4761 - Acc: 0.7198 - F1: 0.7424\n",
            "  Epoch 10/10 - Loss: 0.4057 - Acc: 0.8159 - F1: 0.8474\n",
            "\n",
            "  Test Results for Recipe cucumberraita:\n",
            "    Accuracy: 0.5000\n",
            "    F1: 0.4444\n",
            "    Precision: 0.4000\n",
            "    Recall: 0.5000\n",
            "    AUC: 0.4583\n",
            "\n",
            "================================================================================\n",
            "FOLD 9/24 - Testing on Recipe: dressedupmeatballs\n",
            "================================================================================\n",
            "Train videos: 368 | Test videos: 16\n",
            "  Epoch 1/10 - Loss: 0.5993 - Acc: 0.4755 - F1: 0.4563\n",
            "  Epoch 2/10 - Loss: 0.5942 - Acc: 0.5136 - F1: 0.5748\n",
            "  Epoch 3/10 - Loss: 0.5794 - Acc: 0.5978 - F1: 0.6652\n",
            "  Epoch 4/10 - Loss: 0.5693 - Acc: 0.5543 - F1: 0.5419\n",
            "  Epoch 5/10 - Loss: 0.5638 - Acc: 0.6332 - F1: 0.7033\n",
            "  Epoch 6/10 - Loss: 0.5573 - Acc: 0.6250 - F1: 0.6270\n",
            "  Epoch 7/10 - Loss: 0.4988 - Acc: 0.7418 - F1: 0.7775\n",
            "  Epoch 8/10 - Loss: 0.4279 - Acc: 0.7853 - F1: 0.8124\n",
            "  Epoch 9/10 - Loss: 0.3620 - Acc: 0.8125 - F1: 0.8384\n",
            "  Epoch 10/10 - Loss: 0.2571 - Acc: 0.9022 - F1: 0.9130\n",
            "\n",
            "  Test Results for Recipe dressedupmeatballs:\n",
            "    Accuracy: 0.5625\n",
            "    F1: 0.6316\n",
            "    Precision: 0.6667\n",
            "    Recall: 0.6000\n",
            "    AUC: 0.6167\n",
            "\n",
            "================================================================================\n",
            "FOLD 10/24 - Testing on Recipe: herbomeletwithfriedtomatoes\n",
            "================================================================================\n",
            "Train videos: 367 | Test videos: 17\n",
            "  Epoch 1/10 - Loss: 0.6058 - Acc: 0.4578 - F1: 0.4749\n",
            "  Epoch 2/10 - Loss: 0.5946 - Acc: 0.5095 - F1: 0.5522\n",
            "  Epoch 3/10 - Loss: 0.5992 - Acc: 0.5477 - F1: 0.6140\n",
            "  Epoch 4/10 - Loss: 0.5868 - Acc: 0.5504 - F1: 0.5429\n",
            "  Epoch 5/10 - Loss: 0.5738 - Acc: 0.5913 - F1: 0.6094\n",
            "  Epoch 6/10 - Loss: 0.5585 - Acc: 0.6240 - F1: 0.6634\n",
            "  Epoch 7/10 - Loss: 0.5341 - Acc: 0.6676 - F1: 0.6806\n",
            "  Epoch 8/10 - Loss: 0.4758 - Acc: 0.7466 - F1: 0.7715\n",
            "  Epoch 9/10 - Loss: 0.3891 - Acc: 0.8038 - F1: 0.8235\n",
            "  Epoch 10/10 - Loss: 0.3254 - Acc: 0.8311 - F1: 0.8524\n",
            "\n",
            "  Test Results for Recipe herbomeletwithfriedtomatoes:\n",
            "    Accuracy: 0.7647\n",
            "    F1: 0.8182\n",
            "    Precision: 0.8182\n",
            "    Recall: 0.8182\n",
            "    AUC: 0.8030\n",
            "\n",
            "================================================================================\n",
            "FOLD 11/24 - Testing on Recipe: microwaveeggsandwich\n",
            "================================================================================\n",
            "Train videos: 366 | Test videos: 18\n",
            "  Epoch 1/10 - Loss: 0.5999 - Acc: 0.5000 - F1: 0.4816\n",
            "  Epoch 2/10 - Loss: 0.5970 - Acc: 0.5219 - F1: 0.5863\n",
            "  Epoch 3/10 - Loss: 0.5874 - Acc: 0.5656 - F1: 0.5668\n",
            "  Epoch 4/10 - Loss: 0.5797 - Acc: 0.5683 - F1: 0.5885\n",
            "  Epoch 5/10 - Loss: 0.5818 - Acc: 0.5683 - F1: 0.5990\n",
            "  Epoch 6/10 - Loss: 0.5412 - Acc: 0.6448 - F1: 0.6561\n",
            "  Epoch 7/10 - Loss: 0.5205 - Acc: 0.6639 - F1: 0.6772\n",
            "  Epoch 8/10 - Loss: 0.4529 - Acc: 0.7514 - F1: 0.7708\n",
            "  Epoch 9/10 - Loss: 0.4025 - Acc: 0.7978 - F1: 0.8263\n",
            "  Epoch 10/10 - Loss: 0.3183 - Acc: 0.8552 - F1: 0.8723\n",
            "\n",
            "  Test Results for Recipe microwaveeggsandwich:\n",
            "    Accuracy: 0.4444\n",
            "    F1: 0.3750\n",
            "    Precision: 1.0000\n",
            "    Recall: 0.2308\n",
            "    AUC: 0.6462\n",
            "\n",
            "================================================================================\n",
            "FOLD 12/24 - Testing on Recipe: microwavefrenchtoast\n",
            "================================================================================\n",
            "Train videos: 370 | Test videos: 14\n",
            "  Epoch 1/10 - Loss: 0.5980 - Acc: 0.4838 - F1: 0.5115\n",
            "  Epoch 2/10 - Loss: 0.6114 - Acc: 0.4541 - F1: 0.5000\n",
            "  Epoch 3/10 - Loss: 0.5817 - Acc: 0.5405 - F1: 0.6009\n",
            "  Epoch 4/10 - Loss: 0.5916 - Acc: 0.5811 - F1: 0.6843\n",
            "  Epoch 5/10 - Loss: 0.5691 - Acc: 0.6351 - F1: 0.6809\n",
            "  Epoch 6/10 - Loss: 0.5849 - Acc: 0.5892 - F1: 0.6329\n",
            "  Epoch 7/10 - Loss: 0.5506 - Acc: 0.6919 - F1: 0.7444\n",
            "  Epoch 8/10 - Loss: 0.4761 - Acc: 0.7243 - F1: 0.7371\n",
            "  Epoch 9/10 - Loss: 0.4307 - Acc: 0.7703 - F1: 0.7962\n",
            "  Epoch 10/10 - Loss: 0.3660 - Acc: 0.8081 - F1: 0.8305\n",
            "\n",
            "  Test Results for Recipe microwavefrenchtoast:\n",
            "    Accuracy: 0.6429\n",
            "    F1: 0.6154\n",
            "    Precision: 0.5000\n",
            "    Recall: 0.8000\n",
            "    AUC: 0.8000\n",
            "\n",
            "================================================================================\n",
            "FOLD 13/24 - Testing on Recipe: microwavemugpizza\n",
            "================================================================================\n",
            "Train videos: 371 | Test videos: 13\n",
            "  Epoch 1/10 - Loss: 0.6086 - Acc: 0.4636 - F1: 0.3914\n",
            "  Epoch 2/10 - Loss: 0.5948 - Acc: 0.5499 - F1: 0.6362\n",
            "  Epoch 3/10 - Loss: 0.5893 - Acc: 0.5013 - F1: 0.4377\n",
            "  Epoch 4/10 - Loss: 0.5851 - Acc: 0.5175 - F1: 0.5227\n",
            "  Epoch 5/10 - Loss: 0.5864 - Acc: 0.5580 - F1: 0.5795\n",
            "  Epoch 6/10 - Loss: 0.5658 - Acc: 0.5957 - F1: 0.6305\n",
            "  Epoch 7/10 - Loss: 0.5405 - Acc: 0.6604 - F1: 0.7014\n",
            "  Epoch 8/10 - Loss: 0.5123 - Acc: 0.6846 - F1: 0.7208\n",
            "  Epoch 9/10 - Loss: 0.4470 - Acc: 0.7655 - F1: 0.7972\n",
            "  Epoch 10/10 - Loss: 0.4518 - Acc: 0.7358 - F1: 0.7656\n",
            "\n",
            "  Test Results for Recipe microwavemugpizza:\n",
            "    Accuracy: 0.3846\n",
            "    F1: 0.3333\n",
            "    Precision: 0.5000\n",
            "    Recall: 0.2500\n",
            "    AUC: 0.4500\n",
            "\n",
            "================================================================================\n",
            "FOLD 14/24 - Testing on Recipe: mugcake\n",
            "================================================================================\n",
            "Train videos: 367 | Test videos: 17\n",
            "  Epoch 1/10 - Loss: 0.6011 - Acc: 0.5123 - F1: 0.5866\n",
            "  Epoch 2/10 - Loss: 0.5964 - Acc: 0.4741 - F1: 0.4239\n",
            "  Epoch 3/10 - Loss: 0.5945 - Acc: 0.5041 - F1: 0.4859\n",
            "  Epoch 4/10 - Loss: 0.5849 - Acc: 0.5777 - F1: 0.6336\n",
            "  Epoch 5/10 - Loss: 0.5754 - Acc: 0.6185 - F1: 0.6875\n",
            "  Epoch 6/10 - Loss: 0.5514 - Acc: 0.6458 - F1: 0.6905\n",
            "  Epoch 7/10 - Loss: 0.5250 - Acc: 0.6649 - F1: 0.6886\n",
            "  Epoch 8/10 - Loss: 0.4802 - Acc: 0.7357 - F1: 0.7749\n",
            "  Epoch 9/10 - Loss: 0.4227 - Acc: 0.7875 - F1: 0.8030\n",
            "  Epoch 10/10 - Loss: 0.3323 - Acc: 0.8392 - F1: 0.8557\n",
            "\n",
            "  Test Results for Recipe mugcake:\n",
            "    Accuracy: 0.7059\n",
            "    F1: 0.7619\n",
            "    Precision: 0.7273\n",
            "    Recall: 0.8000\n",
            "    AUC: 0.7000\n",
            "\n",
            "================================================================================\n",
            "FOLD 15/24 - Testing on Recipe: panfriedtofu\n",
            "================================================================================\n",
            "Train videos: 369 | Test videos: 15\n",
            "  Epoch 1/10 - Loss: 0.5877 - Acc: 0.4715 - F1: 0.4828\n",
            "  Epoch 2/10 - Loss: 0.5920 - Acc: 0.5556 - F1: 0.6598\n",
            "  Epoch 3/10 - Loss: 0.5822 - Acc: 0.5556 - F1: 0.6058\n",
            "  Epoch 4/10 - Loss: 0.5680 - Acc: 0.6016 - F1: 0.6316\n",
            "  Epoch 5/10 - Loss: 0.5617 - Acc: 0.5745 - F1: 0.6323\n",
            "  Epoch 6/10 - Loss: 0.5404 - Acc: 0.6341 - F1: 0.6897\n",
            "  Epoch 7/10 - Loss: 0.5085 - Acc: 0.6992 - F1: 0.7351\n",
            "  Epoch 8/10 - Loss: 0.5090 - Acc: 0.6802 - F1: 0.7318\n",
            "  Epoch 9/10 - Loss: 0.4834 - Acc: 0.7182 - F1: 0.7699\n",
            "  Epoch 10/10 - Loss: 0.4707 - Acc: 0.7805 - F1: 0.8029\n",
            "\n",
            "  Test Results for Recipe panfriedtofu:\n",
            "    Accuracy: 0.4667\n",
            "    F1: 0.6364\n",
            "    Precision: 0.5000\n",
            "    Recall: 0.8750\n",
            "    AUC: 0.5714\n",
            "\n",
            "================================================================================\n",
            "FOLD 16/24 - Testing on Recipe: pinwheels\n",
            "================================================================================\n",
            "Train videos: 372 | Test videos: 12\n",
            "  Epoch 1/10 - Loss: 0.6027 - Acc: 0.4382 - F1: 0.3569\n",
            "  Epoch 2/10 - Loss: 0.5996 - Acc: 0.4812 - F1: 0.5089\n",
            "  Epoch 3/10 - Loss: 0.5946 - Acc: 0.5457 - F1: 0.6442\n",
            "  Epoch 4/10 - Loss: 0.5830 - Acc: 0.5269 - F1: 0.4568\n",
            "  Epoch 5/10 - Loss: 0.5699 - Acc: 0.6263 - F1: 0.6745\n",
            "  Epoch 6/10 - Loss: 0.5613 - Acc: 0.6263 - F1: 0.6805\n",
            "  Epoch 7/10 - Loss: 0.5333 - Acc: 0.6559 - F1: 0.6878\n",
            "  Epoch 8/10 - Loss: 0.4783 - Acc: 0.7312 - F1: 0.7630\n",
            "  Epoch 9/10 - Loss: 0.4173 - Acc: 0.7957 - F1: 0.8199\n",
            "  Epoch 10/10 - Loss: 0.3525 - Acc: 0.8091 - F1: 0.8229\n",
            "\n",
            "  Test Results for Recipe pinwheels:\n",
            "    Accuracy: 0.5833\n",
            "    F1: 0.7368\n",
            "    Precision: 0.6364\n",
            "    Recall: 0.8750\n",
            "    AUC: 0.6875\n",
            "\n",
            "================================================================================\n",
            "FOLD 17/24 - Testing on Recipe: ramen\n",
            "================================================================================\n",
            "Train videos: 367 | Test videos: 17\n",
            "  Epoch 1/10 - Loss: 0.5978 - Acc: 0.4905 - F1: 0.5217\n",
            "  Epoch 2/10 - Loss: 0.5967 - Acc: 0.4850 - F1: 0.5424\n",
            "  Epoch 3/10 - Loss: 0.5913 - Acc: 0.5504 - F1: 0.6099\n",
            "  Epoch 4/10 - Loss: 0.5895 - Acc: 0.5422 - F1: 0.6267\n",
            "  Epoch 5/10 - Loss: 0.5821 - Acc: 0.5804 - F1: 0.6532\n",
            "  Epoch 6/10 - Loss: 0.5654 - Acc: 0.6322 - F1: 0.6809\n",
            "  Epoch 7/10 - Loss: 0.5525 - Acc: 0.6131 - F1: 0.6667\n",
            "  Epoch 8/10 - Loss: 0.5073 - Acc: 0.7166 - F1: 0.7604\n",
            "  Epoch 9/10 - Loss: 0.4641 - Acc: 0.7384 - F1: 0.7736\n",
            "  Epoch 10/10 - Loss: 0.3786 - Acc: 0.8011 - F1: 0.8258\n",
            "\n",
            "  Test Results for Recipe ramen:\n",
            "    Accuracy: 0.4706\n",
            "    F1: 0.5263\n",
            "    Precision: 0.4167\n",
            "    Recall: 0.7143\n",
            "    AUC: 0.6000\n",
            "\n",
            "================================================================================\n",
            "FOLD 18/24 - Testing on Recipe: sautedmushrooms\n",
            "================================================================================\n",
            "Train videos: 370 | Test videos: 14\n",
            "  Epoch 1/10 - Loss: 0.6022 - Acc: 0.5297 - F1: 0.6250\n",
            "  Epoch 2/10 - Loss: 0.5934 - Acc: 0.5000 - F1: 0.4699\n",
            "  Epoch 3/10 - Loss: 0.5938 - Acc: 0.5541 - F1: 0.6172\n",
            "  Epoch 4/10 - Loss: 0.5892 - Acc: 0.5649 - F1: 0.5387\n",
            "  Epoch 5/10 - Loss: 0.5854 - Acc: 0.6027 - F1: 0.6508\n",
            "  Epoch 6/10 - Loss: 0.5638 - Acc: 0.6216 - F1: 0.6552\n",
            "  Epoch 7/10 - Loss: 0.5454 - Acc: 0.6541 - F1: 0.6952\n",
            "  Epoch 8/10 - Loss: 0.5367 - Acc: 0.6973 - F1: 0.7268\n",
            "  Epoch 9/10 - Loss: 0.4467 - Acc: 0.7649 - F1: 0.7943\n",
            "  Epoch 10/10 - Loss: 0.3693 - Acc: 0.8108 - F1: 0.8309\n",
            "\n",
            "  Test Results for Recipe sautedmushrooms:\n",
            "    Accuracy: 0.6429\n",
            "    F1: 0.6154\n",
            "    Precision: 0.8000\n",
            "    Recall: 0.5000\n",
            "    AUC: 0.7083\n",
            "\n",
            "================================================================================\n",
            "FOLD 19/24 - Testing on Recipe: scrambledeggs\n",
            "================================================================================\n",
            "Train videos: 368 | Test videos: 16\n",
            "  Epoch 1/10 - Loss: 0.6032 - Acc: 0.4918 - F1: 0.5701\n",
            "  Epoch 2/10 - Loss: 0.5937 - Acc: 0.4565 - F1: 0.2126\n",
            "  Epoch 3/10 - Loss: 0.5972 - Acc: 0.5163 - F1: 0.5291\n",
            "  Epoch 4/10 - Loss: 0.5846 - Acc: 0.5815 - F1: 0.6468\n",
            "  Epoch 5/10 - Loss: 0.5770 - Acc: 0.5924 - F1: 0.6359\n",
            "  Epoch 6/10 - Loss: 0.5604 - Acc: 0.6250 - F1: 0.6368\n",
            "  Epoch 7/10 - Loss: 0.5328 - Acc: 0.6603 - F1: 0.7002\n",
            "  Epoch 8/10 - Loss: 0.4670 - Acc: 0.7636 - F1: 0.7914\n",
            "  Epoch 9/10 - Loss: 0.4322 - Acc: 0.7527 - F1: 0.7828\n",
            "  Epoch 10/10 - Loss: 0.3693 - Acc: 0.7880 - F1: 0.8134\n",
            "\n",
            "  Test Results for Recipe scrambledeggs:\n",
            "    Accuracy: 0.6875\n",
            "    F1: 0.8000\n",
            "    Precision: 0.6667\n",
            "    Recall: 1.0000\n",
            "    AUC: 0.5333\n",
            "\n",
            "================================================================================\n",
            "FOLD 20/24 - Testing on Recipe: spicedhotchocolate\n",
            "================================================================================\n",
            "Train videos: 368 | Test videos: 16\n",
            "  Epoch 1/10 - Loss: 0.5998 - Acc: 0.5027 - F1: 0.5390\n",
            "  Epoch 2/10 - Loss: 0.5970 - Acc: 0.5000 - F1: 0.5534\n",
            "  Epoch 3/10 - Loss: 0.5970 - Acc: 0.5272 - F1: 0.6116\n",
            "  Epoch 4/10 - Loss: 0.5885 - Acc: 0.5353 - F1: 0.5757\n",
            "  Epoch 5/10 - Loss: 0.5692 - Acc: 0.5951 - F1: 0.6209\n",
            "  Epoch 6/10 - Loss: 0.5636 - Acc: 0.5978 - F1: 0.6337\n",
            "  Epoch 7/10 - Loss: 0.5535 - Acc: 0.6332 - F1: 0.6731\n",
            "  Epoch 8/10 - Loss: 0.5101 - Acc: 0.7255 - F1: 0.7430\n",
            "  Epoch 9/10 - Loss: 0.4611 - Acc: 0.7473 - F1: 0.7780\n",
            "  Epoch 10/10 - Loss: 0.4081 - Acc: 0.8016 - F1: 0.8274\n",
            "\n",
            "  Test Results for Recipe spicedhotchocolate:\n",
            "    Accuracy: 0.6250\n",
            "    F1: 0.7500\n",
            "    Precision: 0.6429\n",
            "    Recall: 0.9000\n",
            "    AUC: 0.5333\n",
            "\n",
            "================================================================================\n",
            "FOLD 21/24 - Testing on Recipe: spicytunaavocadowraps\n",
            "================================================================================\n",
            "Train videos: 366 | Test videos: 18\n",
            "  Epoch 1/10 - Loss: 0.6095 - Acc: 0.4781 - F1: 0.5039\n",
            "  Epoch 2/10 - Loss: 0.6019 - Acc: 0.4918 - F1: 0.5592\n",
            "  Epoch 3/10 - Loss: 0.5918 - Acc: 0.5164 - F1: 0.4899\n",
            "  Epoch 4/10 - Loss: 0.5904 - Acc: 0.5246 - F1: 0.5140\n",
            "  Epoch 5/10 - Loss: 0.5690 - Acc: 0.6311 - F1: 0.6809\n",
            "  Epoch 6/10 - Loss: 0.5408 - Acc: 0.6366 - F1: 0.6545\n",
            "  Epoch 7/10 - Loss: 0.5220 - Acc: 0.6749 - F1: 0.7105\n",
            "  Epoch 8/10 - Loss: 0.4806 - Acc: 0.7104 - F1: 0.7415\n",
            "  Epoch 9/10 - Loss: 0.4008 - Acc: 0.8060 - F1: 0.8264\n",
            "  Epoch 10/10 - Loss: 0.3285 - Acc: 0.8552 - F1: 0.8765\n",
            "\n",
            "  Test Results for Recipe spicytunaavocadowraps:\n",
            "    Accuracy: 0.4444\n",
            "    F1: 0.3750\n",
            "    Precision: 0.6000\n",
            "    Recall: 0.2727\n",
            "    AUC: 0.5455\n",
            "\n",
            "================================================================================\n",
            "FOLD 22/24 - Testing on Recipe: tomatochutney\n",
            "================================================================================\n",
            "Train videos: 369 | Test videos: 15\n",
            "  Epoch 1/10 - Loss: 0.5882 - Acc: 0.5095 - F1: 0.4532\n",
            "  Epoch 2/10 - Loss: 0.6097 - Acc: 0.5312 - F1: 0.6588\n",
            "  Epoch 3/10 - Loss: 0.5899 - Acc: 0.4417 - F1: 0.4012\n",
            "  Epoch 4/10 - Loss: 0.5877 - Acc: 0.5528 - F1: 0.6259\n",
            "  Epoch 5/10 - Loss: 0.5816 - Acc: 0.5501 - F1: 0.5514\n",
            "  Epoch 6/10 - Loss: 0.5782 - Acc: 0.5827 - F1: 0.6150\n",
            "  Epoch 7/10 - Loss: 0.5458 - Acc: 0.6450 - F1: 0.6684\n",
            "  Epoch 8/10 - Loss: 0.5133 - Acc: 0.6965 - F1: 0.7308\n",
            "  Epoch 9/10 - Loss: 0.5235 - Acc: 0.7019 - F1: 0.7442\n",
            "  Epoch 10/10 - Loss: 0.4323 - Acc: 0.7696 - F1: 0.7971\n",
            "\n",
            "  Test Results for Recipe tomatochutney:\n",
            "    Accuracy: 0.8000\n",
            "    F1: 0.8696\n",
            "    Precision: 0.7692\n",
            "    Recall: 1.0000\n",
            "    AUC: 0.6000\n",
            "\n",
            "================================================================================\n",
            "FOLD 23/24 - Testing on Recipe: tomatomozzarellasalad\n",
            "================================================================================\n",
            "Train videos: 366 | Test videos: 18\n",
            "  Epoch 1/10 - Loss: 0.6079 - Acc: 0.4891 - F1: 0.4932\n",
            "  Epoch 2/10 - Loss: 0.5987 - Acc: 0.4863 - F1: 0.5437\n",
            "  Epoch 3/10 - Loss: 0.5892 - Acc: 0.5191 - F1: 0.6106\n",
            "  Epoch 4/10 - Loss: 0.5923 - Acc: 0.5738 - F1: 0.7011\n",
            "  Epoch 5/10 - Loss: 0.5855 - Acc: 0.5738 - F1: 0.6303\n",
            "  Epoch 6/10 - Loss: 0.5736 - Acc: 0.6011 - F1: 0.6667\n",
            "  Epoch 7/10 - Loss: 0.5591 - Acc: 0.6257 - F1: 0.6478\n",
            "  Epoch 8/10 - Loss: 0.5275 - Acc: 0.7158 - F1: 0.7500\n",
            "  Epoch 9/10 - Loss: 0.5270 - Acc: 0.6257 - F1: 0.6514\n",
            "  Epoch 10/10 - Loss: 0.4862 - Acc: 0.7186 - F1: 0.7506\n",
            "\n",
            "  Test Results for Recipe tomatomozzarellasalad:\n",
            "    Accuracy: 0.3889\n",
            "    F1: 0.5600\n",
            "    Precision: 0.3889\n",
            "    Recall: 1.0000\n",
            "    AUC: 0.4935\n",
            "\n",
            "================================================================================\n",
            "FOLD 24/24 - Testing on Recipe: zoodles\n",
            "================================================================================\n",
            "Train videos: 369 | Test videos: 15\n",
            "  Epoch 1/10 - Loss: 0.5898 - Acc: 0.5447 - F1: 0.6233\n",
            "  Epoch 2/10 - Loss: 0.6008 - Acc: 0.5068 - F1: 0.5211\n",
            "  Epoch 3/10 - Loss: 0.6060 - Acc: 0.4580 - F1: 0.4152\n",
            "  Epoch 4/10 - Loss: 0.5844 - Acc: 0.5745 - F1: 0.6143\n",
            "  Epoch 5/10 - Loss: 0.5714 - Acc: 0.6396 - F1: 0.6780\n",
            "  Epoch 6/10 - Loss: 0.5336 - Acc: 0.6721 - F1: 0.6889\n",
            "  Epoch 7/10 - Loss: 0.5234 - Acc: 0.6612 - F1: 0.6835\n",
            "  Epoch 8/10 - Loss: 0.5104 - Acc: 0.6558 - F1: 0.7171\n",
            "  Epoch 9/10 - Loss: 0.4948 - Acc: 0.8022 - F1: 0.8170\n",
            "  Epoch 10/10 - Loss: 0.3535 - Acc: 0.8374 - F1: 0.8537\n",
            "\n",
            "  Test Results for Recipe zoodles:\n",
            "    Accuracy: 0.4667\n",
            "    F1: 0.5556\n",
            "    Precision: 0.7143\n",
            "    Recall: 0.4545\n",
            "    AUC: 0.5000\n",
            "\n",
            "================================================================================\n",
            "üéâ Leave-One-Out Cross-Validation completato!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Inizializzazione W&B per l'intero esperimento LOO\n",
        "run = wandb.init(\n",
        "    project=\"mistake-detection\",\n",
        "    name=f\"LOO-Task2Subtask4-DAGNN-{DATASET_SOURCE.value}-balanced\",\n",
        "    config={\n",
        "        **config,\n",
        "        \"model\": \"DAGNN\",\n",
        "        \"hidden_dim\": 128,\n",
        "        \"num_gnn_layers\": 1,\n",
        "        \"dropout\": 0.4,\n",
        "    },\n",
        "    tags=[\"leave-one-out\", \"Task2Subtask4\", \"DAGNN\", DATASET_SOURCE.value, \"balanced\"],\n",
        "    notes=f\"Leave-One-Out CV with DAGNN (balanced regularization) for mistake detection using {DATASET_SOURCE.value} features\"\n",
        ")\n",
        "\n",
        "print(f\"üöÄ W&B Run: {run.name} (ID: {run.id})\")\n",
        "\n",
        "# Aggiorna config\n",
        "config.update({\n",
        "    \"model\": \"DAGNN\",\n",
        "    \"hidden_dim\": 128,\n",
        "    \"num_gnn_layers\": 1,\n",
        "    \"dropout\": 0.4,\n",
        "})\n",
        "\n",
        "# Statistiche per aggregare i risultati di tutti i fold\n",
        "all_fold_results = []\n",
        "\n",
        "# LOO: per ogni ricetta, usala come test set\n",
        "for fold_idx, test_recipe_name in enumerate(recipes):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"FOLD {fold_idx + 1}/{len(recipes)} - Testing on Recipe: {test_recipe_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Indici del test set (ricetta corrente)\n",
        "    test_indices = recipe_to_indices[test_recipe_name]\n",
        "\n",
        "    # Indici del training set (tutte le altre ricette)\n",
        "    train_indices = []\n",
        "    for recipe_name in recipes:\n",
        "        if recipe_name != test_recipe_name:\n",
        "            train_indices.extend(recipe_to_indices[recipe_name])\n",
        "\n",
        "    print(f\"Train videos: {len(train_indices)} | Test videos: {len(test_indices)}\")\n",
        "\n",
        "    # Crea i subset\n",
        "    train_dataset = Subset(dataset, train_indices)\n",
        "    test_dataset = Subset(dataset, test_indices)\n",
        "\n",
        "    # Crea i DataLoader con collate_fn custom\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    # Inizializza un nuovo modello per questo fold\n",
        "    model = DAGNN(\n",
        "        input_dim=1536,\n",
        "        hidden_dim=config[\"hidden_dim\"],\n",
        "        num_gnn_layers=config[\"num_gnn_layers\"],\n",
        "        dropout=config[\"dropout\"]\n",
        "    ).to(device)\n",
        "\n",
        "    # Optimizer con weight decay\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=config[\"learning_rate\"],\n",
        "        weight_decay=config.get(\"weight_decay\", 1e-4)  # L2 regularization leggera\n",
        "    )\n",
        "\n",
        "    # Loss function con pos_weight\n",
        "    train_pos_weight = torch.tensor([config[\"pos_weight\"]], device=device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=train_pos_weight)\n",
        "\n",
        "    # Training loop per questo fold\n",
        "    best_train_loss = np.inf\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        # TRAIN\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        train_preds_list = []\n",
        "        train_targets_list = []\n",
        "        train_probs_list = []\n",
        "\n",
        "        for batch_dict in train_loader:\n",
        "            # Converti a PyG format\n",
        "            pyg_batch = collate_to_pyg(batch_dict).to(device)\n",
        "\n",
        "            # Forward\n",
        "            probs, logits = model(pyg_batch)\n",
        "\n",
        "            # Loss\n",
        "            labels = pyg_batch.y.float().unsqueeze(1)  # [batch_size, 1]\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            # Backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping per stabilit√†\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Metriche\n",
        "            total_loss += loss.item()\n",
        "            preds = (probs >= 0.5).long().cpu().numpy().flatten()\n",
        "            targets = labels.long().cpu().numpy().flatten()\n",
        "            probs_np = probs.detach().cpu().numpy().flatten()\n",
        "\n",
        "            train_preds_list.extend(preds)\n",
        "            train_targets_list.extend(targets)\n",
        "            train_probs_list.extend(probs_np)\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Metriche di training\n",
        "        train_preds = np.array(train_preds_list)\n",
        "        train_targets = np.array(train_targets_list)\n",
        "        train_probs = np.array(train_probs_list)\n",
        "\n",
        "        train_acc = accuracy_score(train_targets, train_preds)\n",
        "        train_f1 = f1_score(train_targets, train_preds, zero_division=0)\n",
        "\n",
        "        # Log su W&B per questo fold\n",
        "        wandb.log({\n",
        "            f\"fold_{fold_idx+1}/train_loss\": avg_train_loss,\n",
        "            f\"fold_{fold_idx+1}/train_accuracy\": train_acc,\n",
        "            f\"fold_{fold_idx+1}/train_f1\": train_f1,\n",
        "            f\"fold_{fold_idx+1}/epoch\": epoch + 1\n",
        "        })\n",
        "\n",
        "        print(f\"  Epoch {epoch+1}/{config['epochs']} - Loss: {avg_train_loss:.4f} - Acc: {train_acc:.4f} - F1: {train_f1:.4f}\")\n",
        "\n",
        "        # Salva il miglior modello per questo fold\n",
        "        if avg_train_loss < best_train_loss:\n",
        "            best_train_loss = avg_train_loss\n",
        "            best_model_state = model.state_dict().copy()\n",
        "\n",
        "    # Carica il miglior modello\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    # TEST per questo fold\n",
        "    model.eval()\n",
        "    test_preds_list = []\n",
        "    test_targets_list = []\n",
        "    test_probs_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_dict in test_loader:\n",
        "            # Converti a PyG format\n",
        "            pyg_batch = collate_to_pyg(batch_dict).to(device)\n",
        "\n",
        "            # Forward\n",
        "            probs, logits = model(pyg_batch)\n",
        "\n",
        "            # Predictions\n",
        "            labels = pyg_batch.y.long().cpu().numpy()\n",
        "            preds = (probs >= 0.5).long().cpu().numpy().flatten()\n",
        "            probs_np = probs.cpu().numpy().flatten()\n",
        "\n",
        "            test_preds_list.extend(preds)\n",
        "            test_targets_list.extend(labels)\n",
        "            test_probs_list.extend(probs_np)\n",
        "\n",
        "    # Metriche di test per questo fold\n",
        "    test_preds = np.array(test_preds_list)\n",
        "    test_targets = np.array(test_targets_list)\n",
        "    test_probs = np.array(test_probs_list)\n",
        "\n",
        "    test_acc = accuracy_score(test_targets, test_preds)\n",
        "    test_f1 = f1_score(test_targets, test_preds, zero_division=0)\n",
        "    test_precision = precision_score(test_targets, test_preds, zero_division=0)\n",
        "    test_recall = recall_score(test_targets, test_preds, zero_division=0)\n",
        "\n",
        "    try:\n",
        "        test_auc = roc_auc_score(test_targets, test_probs)\n",
        "    except ValueError:\n",
        "        test_auc = 0.0\n",
        "\n",
        "    # Salva i risultati di questo fold\n",
        "    fold_result = {\n",
        "        'fold': fold_idx + 1,\n",
        "        'test_recipe': test_recipe_name,\n",
        "        'accuracy': test_acc,\n",
        "        'f1': test_f1,\n",
        "        'precision': test_precision,\n",
        "        'recall': test_recall,\n",
        "        'auc': test_auc,\n",
        "        'test_targets': test_targets,\n",
        "        'test_preds': test_preds\n",
        "    }\n",
        "    all_fold_results.append(fold_result)\n",
        "\n",
        "    # Log su W&B\n",
        "    wandb.log({\n",
        "        f\"fold_{fold_idx+1}/test_accuracy\": test_acc,\n",
        "        f\"fold_{fold_idx+1}/test_f1\": test_f1,\n",
        "        f\"fold_{fold_idx+1}/test_precision\": test_precision,\n",
        "        f\"fold_{fold_idx+1}/test_recall\": test_recall,\n",
        "        f\"fold_{fold_idx+1}/test_auc\": test_auc,\n",
        "    })\n",
        "\n",
        "    print(f\"\\n  Test Results for Recipe {test_recipe_name}:\")\n",
        "    print(f\"    Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"    F1: {test_f1:.4f}\")\n",
        "    print(f\"    Precision: {test_precision:.4f}\")\n",
        "    print(f\"    Recall: {test_recall:.4f}\")\n",
        "    print(f\"    AUC: {test_auc:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"üéâ Leave-One-Out Cross-Validation completato!\")\n",
        "print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e8bd58",
      "metadata": {
        "id": "56e8bd58"
      },
      "source": [
        "# Results Analysis\n",
        "\n",
        "Analisi dei risultati aggregati su tutti i fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "aa915363",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa915363",
        "outputId": "9bab7cd1-5d85-4f5d-d835-5ccf3fd86189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "AGGREGATED RESULTS ACROSS ALL FOLDS\n",
            "================================================================================\n",
            "\n",
            "Metric            | Mean      | Std Dev\n",
            "--------------------------------------------------------------------------------\n",
            "Accuracy          | 0.5651    | 0.1323\n",
            "F1 Score          | 0.6140    | 0.1657\n",
            "Precision         | 0.6297    | 0.1546\n",
            "Recall            | 0.6889    | 0.2641\n",
            "AUC               | 0.5918    | 0.1184\n",
            "================================================================================\n",
            "\n",
            "RESULTS PER FOLD:\n",
            "--------------------------------------------------------------------------------\n",
            "Fold | Recipe                         | Accuracy | F1       | Precision | Recall   | AUC\n",
            "--------------------------------------------------------------------------------\n",
            "1    | blenderbananapancakes          | 0.7895   | 0.8571   | 0.7500    | 1.0000   | 0.6667\n",
            "2    | breakfastburritos              | 0.4375   | 0.3077   | 0.6667    | 0.2000   | 0.6167\n",
            "3    | broccolistirfry                | 0.3125   | 0.4762   | 0.3333    | 0.8333   | 0.2667\n",
            "4    | buttercorncup                  | 0.6429   | 0.7826   | 0.6429    | 1.0000   | 0.5111\n",
            "5    | capresebruschetta              | 0.6667   | 0.7500   | 0.7500    | 0.7500   | 0.7500\n",
            "6    | cheesepimiento                 | 0.5333   | 0.5333   | 0.6667    | 0.4444   | 0.5556\n",
            "7    | coffee                         | 0.6000   | 0.6250   | 0.5556    | 0.7143   | 0.5893\n",
            "8    | cucumberraita                  | 0.5000   | 0.4444   | 0.4000    | 0.5000   | 0.4583\n",
            "9    | dressedupmeatballs             | 0.5625   | 0.6316   | 0.6667    | 0.6000   | 0.6167\n",
            "10   | herbomeletwithfriedtomatoes    | 0.7647   | 0.8182   | 0.8182    | 0.8182   | 0.8030\n",
            "11   | microwaveeggsandwich           | 0.4444   | 0.3750   | 1.0000    | 0.2308   | 0.6462\n",
            "12   | microwavefrenchtoast           | 0.6429   | 0.6154   | 0.5000    | 0.8000   | 0.8000\n",
            "13   | microwavemugpizza              | 0.3846   | 0.3333   | 0.5000    | 0.2500   | 0.4500\n",
            "14   | mugcake                        | 0.7059   | 0.7619   | 0.7273    | 0.8000   | 0.7000\n",
            "15   | panfriedtofu                   | 0.4667   | 0.6364   | 0.5000    | 0.8750   | 0.5714\n",
            "16   | pinwheels                      | 0.5833   | 0.7368   | 0.6364    | 0.8750   | 0.6875\n",
            "17   | ramen                          | 0.4706   | 0.5263   | 0.4167    | 0.7143   | 0.6000\n",
            "18   | sautedmushrooms                | 0.6429   | 0.6154   | 0.8000    | 0.5000   | 0.7083\n",
            "19   | scrambledeggs                  | 0.6875   | 0.8000   | 0.6667    | 1.0000   | 0.5333\n",
            "20   | spicedhotchocolate             | 0.6250   | 0.7500   | 0.6429    | 0.9000   | 0.5333\n",
            "21   | spicytunaavocadowraps          | 0.4444   | 0.3750   | 0.6000    | 0.2727   | 0.5455\n",
            "22   | tomatochutney                  | 0.8000   | 0.8696   | 0.7692    | 1.0000   | 0.6000\n",
            "23   | tomatomozzarellasalad          | 0.3889   | 0.5600   | 0.3889    | 1.0000   | 0.4935\n",
            "24   | zoodles                        | 0.4667   | 0.5556   | 0.7143    | 0.4545   | 0.5000\n",
            "================================================================================\n",
            "\n",
            "OVERALL CONFUSION MATRIX:\n",
            "[[ 68  96]\n",
            " [ 71 149]]\n"
          ]
        }
      ],
      "source": [
        "# Calcola le statistiche aggregate su tutti i fold\n",
        "accuracies = [r['accuracy'] for r in all_fold_results]\n",
        "f1_scores = [r['f1'] for r in all_fold_results]\n",
        "precisions = [r['precision'] for r in all_fold_results]\n",
        "recalls = [r['recall'] for r in all_fold_results]\n",
        "aucs = [r['auc'] for r in all_fold_results]\n",
        "\n",
        "# Medie e deviazioni standard\n",
        "mean_acc = np.mean(accuracies)\n",
        "std_acc = np.std(accuracies)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_auc = np.mean(aucs)\n",
        "std_auc = np.std(aucs)\n",
        "\n",
        "# Stampa i risultati aggregati\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"AGGREGATED RESULTS ACROSS ALL FOLDS\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\nMetric            | Mean      | Std Dev\")\n",
        "print(f\"{'-'*80}\")\n",
        "print(f\"Accuracy          | {mean_acc:.4f}    | {std_acc:.4f}\")\n",
        "print(f\"F1 Score          | {mean_f1:.4f}    | {std_f1:.4f}\")\n",
        "print(f\"Precision         | {mean_precision:.4f}    | {std_precision:.4f}\")\n",
        "print(f\"Recall            | {mean_recall:.4f}    | {std_recall:.4f}\")\n",
        "print(f\"AUC               | {mean_auc:.4f}    | {std_auc:.4f}\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Stampa i risultati per ogni fold\n",
        "print(f\"\\nRESULTS PER FOLD:\")\n",
        "print(f\"{'-'*80}\")\n",
        "print(f\"Fold | Recipe                         | Accuracy | F1       | Precision | Recall   | AUC\")\n",
        "print(f\"{'-'*80}\")\n",
        "for result in all_fold_results:\n",
        "    print(f\"{result['fold']:<4} | {result['test_recipe']:<30} | {result['accuracy']:.4f}   | {result['f1']:.4f}   | {result['precision']:.4f}    | {result['recall']:.4f}   | {result['auc']:.4f}\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Log delle metriche aggregate su W&B\n",
        "wandb.log({\n",
        "    \"overall/mean_accuracy\": mean_acc,\n",
        "    \"overall/std_accuracy\": std_acc,\n",
        "    \"overall/mean_f1\": mean_f1,\n",
        "    \"overall/std_f1\": std_f1,\n",
        "    \"overall/mean_precision\": mean_precision,\n",
        "    \"overall/std_precision\": std_precision,\n",
        "    \"overall/mean_recall\": mean_recall,\n",
        "    \"overall/std_recall\": std_recall,\n",
        "    \"overall/mean_auc\": mean_auc,\n",
        "    \"overall/std_auc\": std_auc,\n",
        "})\n",
        "\n",
        "# Crea una tabella per W&B con i risultati per fold\n",
        "fold_table_data = []\n",
        "for result in all_fold_results:\n",
        "    fold_table_data.append([\n",
        "        result['fold'],\n",
        "        result['test_recipe'],\n",
        "        result['accuracy'],\n",
        "        result['f1'],\n",
        "        result['precision'],\n",
        "        result['recall'],\n",
        "        result['auc']\n",
        "    ])\n",
        "\n",
        "wandb.log({\n",
        "    \"fold_results_table\": wandb.Table(\n",
        "        columns=[\"Fold\", \"Test Recipe\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\", \"AUC\"],\n",
        "        data=fold_table_data\n",
        "    )\n",
        "})\n",
        "\n",
        "# Confusion Matrix aggregata (concatena tutti i target e le predizioni)\n",
        "all_targets = np.concatenate([r['test_targets'] for r in all_fold_results])\n",
        "all_preds = np.concatenate([r['test_preds'] for r in all_fold_results])\n",
        "\n",
        "cm_overall = confusion_matrix(all_targets, all_preds)\n",
        "print(f\"\\nOVERALL CONFUSION MATRIX:\")\n",
        "print(cm_overall)\n",
        "\n",
        "wandb.log({\n",
        "    \"overall/confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "        probs=None,\n",
        "        y_true=all_targets,\n",
        "        preds=all_preds,\n",
        "        class_names=[\"No Error\", \"Error\"]\n",
        "    )\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3490441",
      "metadata": {
        "id": "d3490441"
      },
      "outputs": [],
      "source": [
        "# Chiudi il run di W&B\n",
        "wandb.finish()\n",
        "print(\"üèÅ W&B run terminato\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.12.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
