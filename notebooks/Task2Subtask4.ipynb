{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00db5f23",
   "metadata": {},
   "source": [
    "# Environement Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d301206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente locale rilevato.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "try:\n",
    "    from google.colab import drive, userdata\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "REPO_NAME = 'MistakeDetection'\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"‚òÅÔ∏è Colab rilevato.\")\n",
    "    if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
    "\n",
    "    GITHUB_USER = 'MarcoPernoVDP'\n",
    "    try:\n",
    "        TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "        REPO_URL = f'https://{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "    except:\n",
    "        REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "\n",
    "    ROOT_DIR = f'/content/{REPO_NAME}'\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        !git clone {REPO_URL}\n",
    "    else:\n",
    "        %cd {ROOT_DIR}\n",
    "        !git pull\n",
    "        %cd /content\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Ambiente locale rilevato.\")\n",
    "    ROOT_DIR = os.getcwd()\n",
    "    while not os.path.exists(os.path.join(ROOT_DIR, '.gitignore')) and ROOT_DIR != os.path.dirname(ROOT_DIR):\n",
    "        ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
    "\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf787bb",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5150539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Progetto in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\n",
      "source_path: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "Setup Dati da: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "Inizio setup dati...\n",
      "   Sorgente: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\_file\n",
      "   Destinazione: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n",
      "Copia cartella: annotation_json...\n",
      "Copia cartella: omnivore...\n",
      "Estrazione ZIP: omnivore.zip...\n",
      "‚úÖ Setup completato! Dati pronti in: c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\marco\\_netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms339450\u001b[0m (\u001b[33ms339450-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Logged in.\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from utils import setup_project\n",
    "# Ora puoi passare agli import del modello\n",
    "from dataset.capitain_cook_4d_mlp_dataset import CaptainCook4DMLP_Dataset, DatasetSource\n",
    "from models.BaselineV2_Transformer import BaselineV2_Transformer\n",
    "from dataset.utils import SplitType\n",
    "\n",
    "# Esegue: Setup Dati (unzip/copy), Login WandB, Setup Device\n",
    "device = setup_project.initialize(ROOT_DIR)\n",
    "\n",
    "# Import wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e42308",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a7e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione esperimento\n",
    "DATASET_SOURCE = DatasetSource.HIERO\n",
    "\n",
    "config = {\n",
    "    \"dataset\": \"CaptainCook4D\",\n",
    "    \"feature_extractor\": DATASET_SOURCE.value,\n",
    "    \"input_dim\": DATASET_SOURCE.input_dims(),\n",
    "    \"batch_size\": 1,  # DEVE essere 1 per sequenze di lunghezza variabile\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"epochs\": 30,\n",
    "    \"pos_weight\": 0.75,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a88f766",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f0f9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video embeddings...\n",
      "Loading Hungarian matching results...\n",
      "Loading error annotations...\n",
      "Dataset initialized with 384 samples\n"
     ]
    }
   ],
   "source": [
    "from dataset.dagnn_dataset import DAGNNDataset\n",
    "\n",
    "if IS_COLAB:\n",
    "  dataset = DAGNNDataset(\n",
    "      video_embeddings_path=os.path.join(\"/content/drive/MyDrive/MistakeDetection\", \"hiero_all_video_steps.npz\"),\n",
    "      recipe_embeddings_dir=os.path.join(\"/content/drive/MyDrive/MistakeDetection\", \"recipe_text_step_embeddings\"),\n",
    "      hungarian_results_path=os.path.join(\"/content/drive/MyDrive/MistakeDetection\", \"hungarian_results\", \"hungarian_matching_results.json\"),\n",
    "      annotation_path=os.path.join(\"/content/drive/MyDrive/MistakeDetection\", \"annotation_json\", \"video_level_annotations.json\"),\n",
    "  )\n",
    "else:\n",
    "  dataset = DAGNNDataset(\n",
    "      video_embeddings_path=os.path.join(ROOT_DIR, \"data\", \"hiero_all_video_steps.npz\"),\n",
    "      recipe_embeddings_dir=os.path.join(ROOT_DIR, \"data\", \"recipe_text_step_embeddings\"),\n",
    "      hungarian_results_path=os.path.join(ROOT_DIR, \"hungarian_results\", \"hungarian_matching_results.json\"),\n",
    "      annotation_path=os.path.join(ROOT_DIR, \"data\", \"annotation_json\", \"video_level_annotations.json\"),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c017fcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1536])\n",
      "tensor([[14, 15,  1,  7, 18,  2, 11,  5,  3, 17, 19, 13, 16,  8, 10,  4,  6, 12,\n",
      "          0,  9, 15],\n",
      "        [ 1,  2,  3,  4,  5, 20,  7,  8,  9, 10, 11, 12, 13, 14, 15, 17, 18, 19,\n",
      "         16, 20,  6]])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1]['node_features'].shape)  # Esempio di accesso ai dati\n",
    "print(dataset[1]['edge_index'])  # Esempio di accesso agli indici degli edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898401a7",
   "metadata": {},
   "source": [
    "# Leave-One-Out Cross-Validation Setup\n",
    "\n",
    "Raggruppiamo i video per ricetta per fare LOO CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "291b839f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LEAVE-ONE-OUT CROSS-VALIDATION SETUP\n",
      "================================================================================\n",
      "Total videos: 384\n",
      "Total recipes: 24\n",
      "\n",
      "Videos per recipe:\n",
      "  blenderbananapancakes         : 19 videos\n",
      "  breakfastburritos             : 16 videos\n",
      "  broccolistirfry               : 16 videos\n",
      "  buttercorncup                 : 14 videos\n",
      "  capresebruschetta             : 18 videos\n",
      "  cheesepimiento                : 15 videos\n",
      "  coffee                        : 15 videos\n",
      "  cucumberraita                 : 20 videos\n",
      "  dressedupmeatballs            : 16 videos\n",
      "  herbomeletwithfriedtomatoes   : 17 videos\n",
      "  microwaveeggsandwich          : 18 videos\n",
      "  microwavefrenchtoast          : 14 videos\n",
      "  microwavemugpizza             : 13 videos\n",
      "  mugcake                       : 17 videos\n",
      "  panfriedtofu                  : 15 videos\n",
      "  pinwheels                     : 12 videos\n",
      "  ramen                         : 17 videos\n",
      "  sautedmushrooms               : 14 videos\n",
      "  scrambledeggs                 : 16 videos\n",
      "  spicedhotchocolate            : 16 videos\n",
      "  spicytunaavocadowraps         : 18 videos\n",
      "  tomatochutney                 : 15 videos\n",
      "  tomatomozzarellasalad         : 18 videos\n",
      "  zoodles                       : 15 videos\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Raggruppa i video per ricetta\n",
    "recipe_to_indices = defaultdict(list)\n",
    "for idx in range(len(dataset)):\n",
    "    sample = dataset.samples[idx]\n",
    "    recipe_name = sample['recipe_name']\n",
    "    recipe_to_indices[recipe_name].append(idx)\n",
    "\n",
    "# Ordina le ricette per avere un ordine consistente\n",
    "recipes = sorted(recipe_to_indices.keys())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"LEAVE-ONE-OUT CROSS-VALIDATION SETUP\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total videos: {len(dataset)}\")\n",
    "print(f\"Total recipes: {len(recipes)}\")\n",
    "print(f\"\\nVideos per recipe:\")\n",
    "for recipe_name in recipes:\n",
    "    print(f\"  {recipe_name:<30}: {len(recipe_to_indices[recipe_name])} videos\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b96e646",
   "metadata": {},
   "source": [
    "# DAGNN Model\n",
    "\n",
    "Implementiamo la DAGNN per error detection con:\n",
    "- ProjectionLayer per ridurre dimensioni (1536 ‚Üí 256)\n",
    "- Graph Convolutional layers\n",
    "- Global pooling\n",
    "- Binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ebf70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DAGNN model implementato\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class DAGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    DAGNN model for cooking mistake detection.\n",
    "    \n",
    "    Architecture:\n",
    "    1. ProjectionLayer: [1536] ‚Üí [256] (learnable)\n",
    "    2. GCN layers on the recipe graph\n",
    "    3. Global pooling over nodes\n",
    "    4. Binary classifier (error/no error)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 1536,\n",
    "        hidden_dim: int = 256,\n",
    "        num_gnn_layers: int = 3,\n",
    "        dropout: float = 0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature projection (learnable combination of text + visual)\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "        )\n",
    "        \n",
    "        # GNN layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_gnn_layers):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Binary classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1),  # Binary output\n",
    "        )\n",
    "    \n",
    "    def forward(self, batch_data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_data: Batched PyG Data object with:\n",
    "                - x: [total_nodes, 1536] node features\n",
    "                - edge_index: [2, total_edges] edges\n",
    "                - batch: [total_nodes] batch assignment\n",
    "        \n",
    "        Returns:\n",
    "            logits: [batch_size, 1] - logits for binary classification\n",
    "            probs: [batch_size, 1] - probabilities after sigmoid\n",
    "        \"\"\"\n",
    "        x = batch_data.x\n",
    "        edge_index = batch_data.edge_index\n",
    "        batch = batch_data.batch\n",
    "        \n",
    "        # 1. Project features [total_nodes, 1536] ‚Üí [total_nodes, 256]\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        # 2. GNN layers\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # 3. Global pooling (one embedding per graph)\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, 256]\n",
    "        \n",
    "        # 4. Classification\n",
    "        logits = self.classifier(x)  # [batch_size, 1]\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        return probs, logits\n",
    "\n",
    "print(\"‚úÖ DAGNN model implementato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760e60d9",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "Funzioni per convertire batch in formato PyTorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a809b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions aggiornate con validazione edge_index\n"
     ]
    }
   ],
   "source": [
    "from dataset.dagnn_dataset import collate_fn\n",
    "\n",
    "def collate_to_pyg(batch_dict):\n",
    "    \"\"\"\n",
    "    Convert batch from DAGNNDataset to PyTorch Geometric format.\n",
    "    \n",
    "    Args:\n",
    "        batch_dict: Dictionary from DAGNN collate_fn\n",
    "    \n",
    "    Returns:\n",
    "        Batched PyG Data object\n",
    "    \"\"\"\n",
    "    graphs = []\n",
    "    \n",
    "    for i in range(len(batch_dict['node_features'])):\n",
    "        # Verifica che edge_index sia nel formato corretto\n",
    "        edge_index = batch_dict['edge_index'][i]\n",
    "        num_nodes = batch_dict['node_features'][i].shape[0]\n",
    "        \n",
    "        # Debug: controlla che gli indici siano validi\n",
    "        if edge_index.numel() > 0:\n",
    "            max_idx = edge_index.max().item()\n",
    "            if max_idx >= num_nodes:\n",
    "                print(f\"‚ö†Ô∏è Warning: edge_index contiene indice {max_idx} ma ci sono solo {num_nodes} nodi\")\n",
    "                # Filtra edge invalidi\n",
    "                valid_edges = (edge_index[0] < num_nodes) & (edge_index[1] < num_nodes)\n",
    "                edge_index = edge_index[:, valid_edges]\n",
    "        \n",
    "        graph = Data(\n",
    "            x=batch_dict['node_features'][i],        # [N_i, 1536]\n",
    "            edge_index=edge_index,                    # [2, E_i]\n",
    "            y=batch_dict['labels'][i],               # Scalar\n",
    "        )\n",
    "        graphs.append(graph)\n",
    "    \n",
    "    # Batch graphs\n",
    "    batched = Batch.from_data_list(graphs)\n",
    "    \n",
    "    return batched\n",
    "\n",
    "print(\"‚úÖ Helper functions aggiornate con validazione edge_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba74f92",
   "metadata": {},
   "source": [
    "# Leave-One-Out Cross-Validation Training\n",
    "\n",
    "Training con LOO CV: ogni ricetta usata come test set una volta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce621a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\notebooks\\wandb\\run-20251222_131929-onz8hax1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/onz8hax1' target=\"_blank\">LOO-Task2Subtask4-DAGNN-hiero</a></strong> to <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/onz8hax1' target=\"_blank\">https://wandb.ai/s339450-politecnico-di-torino/mistake-detection/runs/onz8hax1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ W&B Run: LOO-Task2Subtask4-DAGNN-hiero (ID: onz8hax1)\n",
      "\n",
      "================================================================================\n",
      "FOLD 1/24 - Testing on Recipe: blenderbananapancakes\n",
      "================================================================================\n",
      "Train videos: 365 | Test videos: 19\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 1/30 - Loss: 0.5963 - Acc: 0.5671 - F1: 0.6789\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 2/30 - Loss: 0.5959 - Acc: 0.4712 - F1: 0.4239\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 3/30 - Loss: 0.5938 - Acc: 0.4822 - F1: 0.4906\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 4/30 - Loss: 0.5887 - Acc: 0.5781 - F1: 0.6071\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 5/30 - Loss: 0.5872 - Acc: 0.5808 - F1: 0.6203\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 6/30 - Loss: 0.5680 - Acc: 0.6329 - F1: 0.6492\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 7/30 - Loss: 0.5356 - Acc: 0.6411 - F1: 0.6632\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 8/30 - Loss: 0.4810 - Acc: 0.7315 - F1: 0.7586\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 9/30 - Loss: 0.4456 - Acc: 0.7178 - F1: 0.7379\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 10/30 - Loss: 0.3632 - Acc: 0.8247 - F1: 0.8462\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 11/30 - Loss: 0.2781 - Acc: 0.8712 - F1: 0.8851\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 12/30 - Loss: 0.2090 - Acc: 0.9014 - F1: 0.9130\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 13/30 - Loss: 0.1615 - Acc: 0.9178 - F1: 0.9272\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 14/30 - Loss: 0.0898 - Acc: 0.9699 - F1: 0.9735\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 15/30 - Loss: 0.0514 - Acc: 0.9890 - F1: 0.9903\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 16/30 - Loss: 0.1027 - Acc: 0.9616 - F1: 0.9662\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 17/30 - Loss: 0.0396 - Acc: 0.9918 - F1: 0.9928\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 18/30 - Loss: 0.0266 - Acc: 0.9945 - F1: 0.9952\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 19/30 - Loss: 0.0095 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 20/30 - Loss: 0.0045 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 21/30 - Loss: 0.0035 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 22/30 - Loss: 0.0026 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 23/30 - Loss: 0.0020 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 24/30 - Loss: 0.0025 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 25/30 - Loss: 0.0022 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 26/30 - Loss: 0.0011 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 27/30 - Loss: 0.0010 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 28/30 - Loss: 0.0008 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 29/30 - Loss: 0.0007 - Acc: 1.0000 - F1: 1.0000\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 30/30 - Loss: 0.0006 - Acc: 1.0000 - F1: 1.0000\n",
      "\n",
      "  Test Results for Recipe blenderbananapancakes:\n",
      "    Accuracy: 0.5789\n",
      "    F1: 0.6667\n",
      "    Precision: 0.6667\n",
      "    Recall: 0.6667\n",
      "    AUC: 0.6548\n",
      "\n",
      "================================================================================\n",
      "FOLD 2/24 - Testing on Recipe: breakfastburritos\n",
      "================================================================================\n",
      "Train videos: 368 | Test videos: 16\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 1/30 - Loss: 0.5968 - Acc: 0.5054 - F1: 0.5054\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 2/30 - Loss: 0.5927 - Acc: 0.5380 - F1: 0.6083\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 3/30 - Loss: 0.5940 - Acc: 0.5598 - F1: 0.6680\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 4/30 - Loss: 0.5912 - Acc: 0.4891 - F1: 0.4303\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 5/30 - Loss: 0.5731 - Acc: 0.5924 - F1: 0.5856\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 6/30 - Loss: 0.5512 - Acc: 0.6495 - F1: 0.6815\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 7/30 - Loss: 0.5121 - Acc: 0.6658 - F1: 0.6917\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 8/30 - Loss: 0.4395 - Acc: 0.7609 - F1: 0.7822\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 9/30 - Loss: 0.4012 - Acc: 0.7690 - F1: 0.7942\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n",
      "  Epoch 10/30 - Loss: 0.3020 - Acc: 0.8587 - F1: 0.8756\n",
      "Debugging sample: 13_5_360p_224.mp4_1s_1s buttercorncup\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 101\u001b[39m\n\u001b[32m     98\u001b[39m pyg_batch = collate_to_pyg(batch_dict).to(device)\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m probs, logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyg_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[32m    104\u001b[39m labels = pyg_batch.y.float().unsqueeze(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [batch_size, 1]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mDAGNN.forward\u001b[39m\u001b[34m(self, batch_data)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# 2. GNN layers\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.convs:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     x = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     x = F.relu(x)\n\u001b[32m     72\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:263\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    260\u001b[39m x = \u001b[38;5;28mself\u001b[39m.lin(x)\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    266\u001b[39m     out = out + \u001b[38;5;28mself\u001b[39m.bias\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_j3r0v86r.py:245\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, x, edge_weight, size)\u001b[39m\n\u001b[32m    236\u001b[39m             kwargs = CollectArgs(\n\u001b[32m    237\u001b[39m                 x_j=kwargs.x_j,\n\u001b[32m    238\u001b[39m                 edge_weight=kwargs.edge_weight,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m                 dim_size=hook_kwargs[\u001b[33m'\u001b[39m\u001b[33mdim_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    242\u001b[39m             )\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:594\u001b[39m, in \u001b[36mMessagePassing.aggregate\u001b[39m\u001b[34m(self, inputs, index, ptr, dim_size)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maggregate\u001b[39m(\n\u001b[32m    578\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    579\u001b[39m     inputs: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    583\u001b[39m ) -> Tensor:\n\u001b[32m    584\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[33;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[32m    586\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    592\u001b[39m \u001b[33;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[32m    593\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch_geometric\\experimental.py:117\u001b[39m, in \u001b[36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[33m'\u001b[39m\u001b[33mdisable_dynamic_shapes\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[32m    120\u001b[39m         index = required_args_pos[required_arg]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch_geometric\\nn\\aggr\\base.py:131\u001b[39m, in \u001b[36mAggregation.__call__\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     dim_size = \u001b[38;5;28mint\u001b[39m(index.max()) + \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch_geometric\\nn\\aggr\\basic.py:22\u001b[39m, in \u001b[36mSumAggregation.forward\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     20\u001b[39m             ptr: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     21\u001b[39m             dim: \u001b[38;5;28mint\u001b[39m = -\u001b[32m2\u001b[39m) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch_geometric\\nn\\aggr\\base.py:185\u001b[39m, in \u001b[36mAggregation.reduce\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAggregation requires \u001b[39m\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to be specified\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Advanced Machine Learning\\MistakeDetection\\venv\\Lib\\site-packages\\torch_geometric\\utils\\_scatter.py:70\u001b[39m, in \u001b[36mscatter\u001b[39m\u001b[34m(src, index, dim, dim_size, reduce)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce == \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce == \u001b[33m'\u001b[39m\u001b[33madd\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     69\u001b[39m     index = broadcast(index, src, dim)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m.scatter_add_(dim, index, src)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce == \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     73\u001b[39m     count = src.new_zeros(dim_size)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Inizializzazione W&B per l'intero esperimento LOO\n",
    "run = wandb.init(\n",
    "    project=\"mistake-detection\",\n",
    "    name=f\"LOO-Task2Subtask4-DAGNN-{DATASET_SOURCE.value}\",\n",
    "    config={\n",
    "        **config,\n",
    "        \"model\": \"DAGNN\",\n",
    "        \"hidden_dim\": 256,\n",
    "        \"num_gnn_layers\": 3,\n",
    "        \"dropout\": 0.3,\n",
    "        \"batch_size\": 4,  # Per grafi possiamo batchare\n",
    "    },\n",
    "    tags=[\"leave-one-out\", \"Task2Subtask4\", \"DAGNN\", DATASET_SOURCE.value],\n",
    "    notes=f\"Leave-One-Out CV with DAGNN for mistake detection using {DATASET_SOURCE.value} features\"\n",
    ")\n",
    "\n",
    "print(f\"üöÄ W&B Run: {run.name} (ID: {run.id})\")\n",
    "\n",
    "# Aggiorna config\n",
    "config.update({\n",
    "    \"model\": \"DAGNN\",\n",
    "    \"hidden_dim\": 256,\n",
    "    \"num_gnn_layers\": 3,\n",
    "    \"dropout\": 0.3,\n",
    "    \"batch_size\": 4,\n",
    "})\n",
    "\n",
    "# Statistiche per aggregare i risultati di tutti i fold\n",
    "all_fold_results = []\n",
    "\n",
    "# LOO: per ogni ricetta, usala come test set\n",
    "for fold_idx, test_recipe_name in enumerate(recipes):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FOLD {fold_idx + 1}/{len(recipes)} - Testing on Recipe: {test_recipe_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Indici del test set (ricetta corrente)\n",
    "    test_indices = recipe_to_indices[test_recipe_name]\n",
    "    \n",
    "    # Indici del training set (tutte le altre ricette)\n",
    "    train_indices = []\n",
    "    for recipe_name in recipes:\n",
    "        if recipe_name != test_recipe_name:\n",
    "            train_indices.extend(recipe_to_indices[recipe_name])\n",
    "    \n",
    "    print(f\"Train videos: {len(train_indices)} | Test videos: {len(test_indices)}\")\n",
    "    \n",
    "    # Crea i subset\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "    \n",
    "    # Crea i DataLoader con collate_fn custom\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config[\"batch_size\"], \n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config[\"batch_size\"], \n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Inizializza un nuovo modello per questo fold\n",
    "    model = DAGNN(\n",
    "        input_dim=1536,\n",
    "        hidden_dim=config[\"hidden_dim\"],\n",
    "        num_gnn_layers=config[\"num_gnn_layers\"],\n",
    "        dropout=config[\"dropout\"]\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    \n",
    "    # Loss function con pos_weight\n",
    "    train_pos_weight = torch.tensor([config[\"pos_weight\"]], device=device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=train_pos_weight)\n",
    "    \n",
    "    # Training loop per questo fold\n",
    "    best_train_loss = np.inf\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        # TRAIN\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_preds_list = []\n",
    "        train_targets_list = []\n",
    "        train_probs_list = []\n",
    "        \n",
    "        for batch_dict in train_loader:\n",
    "            # Converti a PyG format\n",
    "            pyg_batch = collate_to_pyg(batch_dict).to(device)\n",
    "            \n",
    "            # Forward\n",
    "            probs, logits = model(pyg_batch)\n",
    "            \n",
    "            # Loss\n",
    "            labels = pyg_batch.y.float().unsqueeze(1)  # [batch_size, 1]\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Metriche\n",
    "            total_loss += loss.item()\n",
    "            preds = (probs >= 0.5).long().cpu().numpy().flatten()\n",
    "            targets = labels.long().cpu().numpy().flatten()\n",
    "            probs_np = probs.detach().cpu().numpy().flatten()\n",
    "            \n",
    "            train_preds_list.extend(preds)\n",
    "            train_targets_list.extend(targets)\n",
    "            train_probs_list.extend(probs_np)\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Metriche di training\n",
    "        train_preds = np.array(train_preds_list)\n",
    "        train_targets = np.array(train_targets_list)\n",
    "        train_probs = np.array(train_probs_list)\n",
    "        \n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_f1 = f1_score(train_targets, train_preds, zero_division=0)\n",
    "        \n",
    "        # Log su W&B per questo fold\n",
    "        wandb.log({\n",
    "            f\"fold_{fold_idx+1}/train_loss\": avg_train_loss,\n",
    "            f\"fold_{fold_idx+1}/train_accuracy\": train_acc,\n",
    "            f\"fold_{fold_idx+1}/train_f1\": train_f1,\n",
    "            f\"fold_{fold_idx+1}/epoch\": epoch + 1\n",
    "        })\n",
    "        \n",
    "        print(f\"  Epoch {epoch+1}/{config['epochs']} - Loss: {avg_train_loss:.4f} - Acc: {train_acc:.4f} - F1: {train_f1:.4f}\")\n",
    "        \n",
    "        # Salva il miglior modello per questo fold\n",
    "        if avg_train_loss < best_train_loss:\n",
    "            best_train_loss = avg_train_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "    \n",
    "    # Carica il miglior modello\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # TEST per questo fold\n",
    "    model.eval()\n",
    "    test_preds_list = []\n",
    "    test_targets_list = []\n",
    "    test_probs_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_dict in test_loader:\n",
    "            # Converti a PyG format\n",
    "            pyg_batch = collate_to_pyg(batch_dict).to(device)\n",
    "            \n",
    "            # Forward\n",
    "            probs, logits = model(pyg_batch)\n",
    "            \n",
    "            # Predictions\n",
    "            labels = pyg_batch.y.long().cpu().numpy()\n",
    "            preds = (probs >= 0.5).long().cpu().numpy().flatten()\n",
    "            probs_np = probs.cpu().numpy().flatten()\n",
    "            \n",
    "            test_preds_list.extend(preds)\n",
    "            test_targets_list.extend(labels)\n",
    "            test_probs_list.extend(probs_np)\n",
    "    \n",
    "    # Metriche di test per questo fold\n",
    "    test_preds = np.array(test_preds_list)\n",
    "    test_targets = np.array(test_targets_list)\n",
    "    test_probs = np.array(test_probs_list)\n",
    "    \n",
    "    test_acc = accuracy_score(test_targets, test_preds)\n",
    "    test_f1 = f1_score(test_targets, test_preds, zero_division=0)\n",
    "    test_precision = precision_score(test_targets, test_preds, zero_division=0)\n",
    "    test_recall = recall_score(test_targets, test_preds, zero_division=0)\n",
    "    \n",
    "    try:\n",
    "        test_auc = roc_auc_score(test_targets, test_probs)\n",
    "    except ValueError:\n",
    "        test_auc = 0.0\n",
    "    \n",
    "    # Salva i risultati di questo fold\n",
    "    fold_result = {\n",
    "        'fold': fold_idx + 1,\n",
    "        'test_recipe': test_recipe_name,\n",
    "        'accuracy': test_acc,\n",
    "        'f1': test_f1,\n",
    "        'precision': test_precision,\n",
    "        'recall': test_recall,\n",
    "        'auc': test_auc,\n",
    "        'test_targets': test_targets,\n",
    "        'test_preds': test_preds\n",
    "    }\n",
    "    all_fold_results.append(fold_result)\n",
    "    \n",
    "    # Log su W&B\n",
    "    wandb.log({\n",
    "        f\"fold_{fold_idx+1}/test_accuracy\": test_acc,\n",
    "        f\"fold_{fold_idx+1}/test_f1\": test_f1,\n",
    "        f\"fold_{fold_idx+1}/test_precision\": test_precision,\n",
    "        f\"fold_{fold_idx+1}/test_recall\": test_recall,\n",
    "        f\"fold_{fold_idx+1}/test_auc\": test_auc,\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n  Test Results for Recipe {test_recipe_name}:\")\n",
    "    print(f\"    Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"    F1: {test_f1:.4f}\")\n",
    "    print(f\"    Precision: {test_precision:.4f}\")\n",
    "    print(f\"    Recall: {test_recall:.4f}\")\n",
    "    print(f\"    AUC: {test_auc:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üéâ Leave-One-Out Cross-Validation completato!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e8bd58",
   "metadata": {},
   "source": [
    "# Results Analysis\n",
    "\n",
    "Analisi dei risultati aggregati su tutti i fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa915363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola le statistiche aggregate su tutti i fold\n",
    "accuracies = [r['accuracy'] for r in all_fold_results]\n",
    "f1_scores = [r['f1'] for r in all_fold_results]\n",
    "precisions = [r['precision'] for r in all_fold_results]\n",
    "recalls = [r['recall'] for r in all_fold_results]\n",
    "aucs = [r['auc'] for r in all_fold_results]\n",
    "\n",
    "# Medie e deviazioni standard\n",
    "mean_acc = np.mean(accuracies)\n",
    "std_acc = np.std(accuracies)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "mean_precision = np.mean(precisions)\n",
    "std_precision = np.std(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "std_recall = np.std(recalls)\n",
    "mean_auc = np.mean(aucs)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Stampa i risultati aggregati\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AGGREGATED RESULTS ACROSS ALL FOLDS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nMetric            | Mean      | Std Dev\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"Accuracy          | {mean_acc:.4f}    | {std_acc:.4f}\")\n",
    "print(f\"F1 Score          | {mean_f1:.4f}    | {std_f1:.4f}\")\n",
    "print(f\"Precision         | {mean_precision:.4f}    | {std_precision:.4f}\")\n",
    "print(f\"Recall            | {mean_recall:.4f}    | {std_recall:.4f}\")\n",
    "print(f\"AUC               | {mean_auc:.4f}    | {std_auc:.4f}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Stampa i risultati per ogni fold\n",
    "print(f\"\\nRESULTS PER FOLD:\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"Fold | Recipe                         | Accuracy | F1       | Precision | Recall   | AUC\")\n",
    "print(f\"{'-'*80}\")\n",
    "for result in all_fold_results:\n",
    "    print(f\"{result['fold']:<4} | {result['test_recipe']:<30} | {result['accuracy']:.4f}   | {result['f1']:.4f}   | {result['precision']:.4f}    | {result['recall']:.4f}   | {result['auc']:.4f}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Log delle metriche aggregate su W&B\n",
    "wandb.log({\n",
    "    \"overall/mean_accuracy\": mean_acc,\n",
    "    \"overall/std_accuracy\": std_acc,\n",
    "    \"overall/mean_f1\": mean_f1,\n",
    "    \"overall/std_f1\": std_f1,\n",
    "    \"overall/mean_precision\": mean_precision,\n",
    "    \"overall/std_precision\": std_precision,\n",
    "    \"overall/mean_recall\": mean_recall,\n",
    "    \"overall/std_recall\": std_recall,\n",
    "    \"overall/mean_auc\": mean_auc,\n",
    "    \"overall/std_auc\": std_auc,\n",
    "})\n",
    "\n",
    "# Crea una tabella per W&B con i risultati per fold\n",
    "fold_table_data = []\n",
    "for result in all_fold_results:\n",
    "    fold_table_data.append([\n",
    "        result['fold'],\n",
    "        result['test_recipe'],\n",
    "        result['accuracy'],\n",
    "        result['f1'],\n",
    "        result['precision'],\n",
    "        result['recall'],\n",
    "        result['auc']\n",
    "    ])\n",
    "\n",
    "wandb.log({\n",
    "    \"fold_results_table\": wandb.Table(\n",
    "        columns=[\"Fold\", \"Test Recipe\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\", \"AUC\"],\n",
    "        data=fold_table_data\n",
    "    )\n",
    "})\n",
    "\n",
    "# Confusion Matrix aggregata (concatena tutti i target e le predizioni)\n",
    "all_targets = np.concatenate([r['test_targets'] for r in all_fold_results])\n",
    "all_preds = np.concatenate([r['test_preds'] for r in all_fold_results])\n",
    "\n",
    "cm_overall = confusion_matrix(all_targets, all_preds)\n",
    "print(f\"\\nOVERALL CONFUSION MATRIX:\")\n",
    "print(cm_overall)\n",
    "\n",
    "wandb.log({\n",
    "    \"overall/confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "        probs=None,\n",
    "        y_true=all_targets,\n",
    "        preds=all_preds,\n",
    "        class_names=[\"No Error\", \"Error\"]\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3490441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chiudi il run di W&B\n",
    "wandb.finish()\n",
    "print(\"üèÅ W&B run terminato\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
