{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd642940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚òÅÔ∏è Colab rilevato.\n",
      "/content/MistakeDetection\n",
      "Already up to date.\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "try:\n",
    "    from google.colab import drive, userdata\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "REPO_NAME = 'MistakeDetection'\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"‚òÅÔ∏è Colab rilevato.\")\n",
    "    if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
    "\n",
    "    GITHUB_USER = 'MarcoPernoVDP'\n",
    "    try:\n",
    "        TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "        REPO_URL = f'https://{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "    except:\n",
    "        REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "\n",
    "    ROOT_DIR = f'/content/{REPO_NAME}'\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        !git clone {REPO_URL}\n",
    "    else:\n",
    "        %cd {ROOT_DIR}\n",
    "        !git pull\n",
    "        %cd /content\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Ambiente locale rilevato.\")\n",
    "    ROOT_DIR = os.getcwd()\n",
    "    while not os.path.exists(os.path.join(ROOT_DIR, '.gitignore')) and ROOT_DIR != os.path.dirname(ROOT_DIR):\n",
    "        ROOT_DIR = os.path.dirname(ROOT_DIR)\n",
    "\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54fc35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica ambiente\n",
    "print(f\"üìç Working directory: {ROOT_DIR}\")\n",
    "print(f\"üêç Python environment: {'Colab' if IS_COLAB else 'Local'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00704b76",
   "metadata": {},
   "source": [
    "# Task 2 - Subtask 3: Hungarian Matching\n",
    "\n",
    "Matching tra video step embeddings e task graph text embeddings usando l'algoritmo Ungherese."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e65526",
   "metadata": {},
   "source": [
    "## 1. Installazione Dipendenze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe9d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    !pip install scipy matplotlib seaborn -q\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librerie caricate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb1284",
   "metadata": {},
   "source": [
    "## 2. Configurazione Path\n",
    "\n",
    "**Modifica questi path secondo la tua struttura:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    # ========== CONFIGURA QUESTI PATH PER COLAB ==========\n",
    "    VIDEO_FEATURES_ZIP = \"/content/drive/MyDrive/MistakeDetection/step_embeddings.zip\"\n",
    "    TEXT_FEATURES_ZIP = \"/content/drive/MyDrive/MistakeDetection/text_embeddings.zip\"\n",
    "    OUTPUT_DIR = \"/content/drive/MyDrive/MistakeDetection/hungarian_results\"\n",
    "    # ====================================================\n",
    "else:\n",
    "    # ========== CONFIGURA QUESTI PATH PER LOCALE ==========\n",
    "    VIDEO_FEATURES_ZIP = str(Path(ROOT_DIR) / \"data\" / \"step_embeddings.zip\")\n",
    "    TEXT_FEATURES_ZIP = str(Path(ROOT_DIR) / \"data\" / \"text_embeddings.zip\")\n",
    "    OUTPUT_DIR = str(Path(ROOT_DIR) / \"output\" / \"hungarian_results\")\n",
    "    # ====================================================\n",
    "\n",
    "# Crea cartella output\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Configurazione:\")\n",
    "print(f\"  Video features ZIP: {VIDEO_FEATURES_ZIP}\")\n",
    "print(f\"  Text features ZIP:  {TEXT_FEATURES_ZIP}\")\n",
    "print(f\"  Output directory:   {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad4167",
   "metadata": {},
   "source": [
    "## 3. Caricamento Features da ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features_from_zip(zip_path: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Carica tutte le features da un file ZIP\n",
    "    \n",
    "    Args:\n",
    "        zip_path: Path al file ZIP contenente .npz files\n",
    "        \n",
    "    Returns:\n",
    "        Dizionario {filename: features_array}\n",
    "    \"\"\"\n",
    "    features_dict = {}\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Lista tutti i file .npz nello zip\n",
    "        npz_files = [f for f in zip_ref.namelist() if f.endswith('.npz')]\n",
    "        \n",
    "        print(f\"üì¶ Trovati {len(npz_files)} file .npz in {Path(zip_path).name}\")\n",
    "        \n",
    "        for npz_file in npz_files:\n",
    "            try:\n",
    "                # Leggi il file npz dallo zip\n",
    "                with zip_ref.open(npz_file) as f:\n",
    "                    data = np.load(f, allow_pickle=True)\n",
    "                    \n",
    "                    # Estrai le features\n",
    "                    if 'features' in data:\n",
    "                        features = data['features']\n",
    "                        \n",
    "                        # Normalizzazione L2\n",
    "                        norms = np.linalg.norm(features, axis=1, keepdims=True)\n",
    "                        norms = np.where(norms == 0, 1, norms)\n",
    "                        features_normalized = features / norms\n",
    "                        \n",
    "                        # Usa il basename come chiave\n",
    "                        key = Path(npz_file).stem\n",
    "                        features_dict[key] = features_normalized\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Errore caricando {npz_file}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return features_dict\n",
    "\n",
    "# Carica features\n",
    "print(\"\\nüîÑ Caricamento video features...\")\n",
    "video_features = load_features_from_zip(VIDEO_FEATURES_ZIP)\n",
    "\n",
    "print(\"\\nüîÑ Caricamento text features...\")\n",
    "text_features = load_features_from_zip(TEXT_FEATURES_ZIP)\n",
    "\n",
    "print(f\"\\n‚úÖ Caricate:\")\n",
    "print(f\"  {len(video_features)} video features\")\n",
    "print(f\"  {len(text_features)} text features\")\n",
    "\n",
    "# Mostra esempi\n",
    "if video_features:\n",
    "    example_key = list(video_features.keys())[0]\n",
    "    print(f\"\\nüìä Esempio video feature '{example_key}': shape {video_features[example_key].shape}\")\n",
    "if text_features:\n",
    "    example_key = list(text_features.keys())[0]\n",
    "    print(f\"üìä Esempio text feature '{example_key}': shape {text_features[example_key].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ab1ec",
   "metadata": {},
   "source": [
    "## 4. Algoritmo di Hungarian Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb79570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hungarian_matching(video_feats: np.ndarray, \n",
    "                      text_feats: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Esegue Hungarian matching tra video e text features\n",
    "    \n",
    "    Args:\n",
    "        video_feats: Array (N, D) di embeddings video\n",
    "        text_feats: Array (M, D) di embeddings testo\n",
    "        \n",
    "    Returns:\n",
    "        - video_indices: Indici video matched\n",
    "        - text_indices: Indici testo matched  \n",
    "        - distances: Distanze coseno dei match\n",
    "        - avg_distance: Distanza media\n",
    "    \"\"\"\n",
    "    # Calcola matrice di costo (cosine distance = 1 - cosine similarity)\n",
    "    # Per features normalizzate: cosine_sim = dot product\n",
    "    similarity = video_feats @ text_feats.T\n",
    "    cost_matrix = 1.0 - similarity\n",
    "    \n",
    "    # Applica algoritmo Ungherese\n",
    "    video_indices, text_indices = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Estrai le distanze dei match\n",
    "    distances = cost_matrix[video_indices, text_indices]\n",
    "    avg_distance = distances.mean()\n",
    "    \n",
    "    return video_indices, text_indices, distances, avg_distance\n",
    "\n",
    "print(\"‚úÖ Funzione Hungarian matching definita\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dd05db",
   "metadata": {},
   "source": [
    "## 5. Matching Video-Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a166c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_video_to_text(video_features: Dict[str, np.ndarray],\n",
    "                       text_features: Dict[str, np.ndarray]) -> Dict:\n",
    "    \"\"\"\n",
    "    Matcha tutte le video features con le corrispondenti text features\n",
    "    \n",
    "    Args:\n",
    "        video_features: Dict {video_id: features}\n",
    "        text_features: Dict {recipe_id: features}\n",
    "        \n",
    "    Returns:\n",
    "        Dict con risultati del matching\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\nüöÄ Esecuzione Hungarian matching...\\n\")\n",
    "    \n",
    "    for video_id, vid_feats in video_features.items():\n",
    "        # Trova la text feature corrispondente\n",
    "        # Assumi che il video_id contenga il recipe_id\n",
    "        matched_text_id = None\n",
    "        \n",
    "        for text_id in text_features.keys():\n",
    "            # Rimuovi suffisso '_text' se presente\n",
    "            recipe_id = text_id.replace('_text', '')\n",
    "            \n",
    "            # Controlla se il recipe_id √® contenuto nel video_id\n",
    "            if recipe_id in video_id:\n",
    "                matched_text_id = text_id\n",
    "                break\n",
    "        \n",
    "        if matched_text_id is None:\n",
    "            print(f\"‚ö†Ô∏è Nessuna text feature trovata per {video_id}\")\n",
    "            continue\n",
    "        \n",
    "        txt_feats = text_features[matched_text_id]\n",
    "        \n",
    "        # Esegui matching\n",
    "        vid_idx, txt_idx, distances, avg_dist = hungarian_matching(vid_feats, txt_feats)\n",
    "        \n",
    "        # Salva risultati\n",
    "        results[video_id] = {\n",
    "            'text_id': matched_text_id,\n",
    "            'video_indices': vid_idx,\n",
    "            'text_indices': txt_idx,\n",
    "            'distances': distances,\n",
    "            'avg_distance': avg_dist,\n",
    "            'num_matches': len(vid_idx)\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úì {video_id} ‚Üí {matched_text_id}\")\n",
    "        print(f\"  Matches: {len(vid_idx)}, Avg distance: {avg_dist:.4f}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Esegui matching\n",
    "matching_results = match_video_to_text(video_features, text_features)\n",
    "\n",
    "# Statistiche globali\n",
    "if matching_results:\n",
    "    all_avg_dists = [r['avg_distance'] for r in matching_results.values()]\n",
    "    print(f\"\\nüìä STATISTICHE GLOBALI:\")\n",
    "    print(f\"  Total matches: {len(matching_results)}\")\n",
    "    print(f\"  Avg distance: {np.mean(all_avg_dists):.4f} ¬± {np.std(all_avg_dists):.4f}\")\n",
    "    print(f\"  Min distance: {np.min(all_avg_dists):.4f}\")\n",
    "    print(f\"  Max distance: {np.max(all_avg_dists):.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nessun matching trovato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3c63f",
   "metadata": {},
   "source": [
    "## 6. Salvataggio Risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0907a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva come JSON\n",
    "output_json = Path(OUTPUT_DIR) / \"matching_results.json\"\n",
    "\n",
    "json_results = {}\n",
    "for video_id, result in matching_results.items():\n",
    "    json_results[video_id] = {\n",
    "        'text_id': result['text_id'],\n",
    "        'video_indices': result['video_indices'].tolist(),\n",
    "        'text_indices': result['text_indices'].tolist(),\n",
    "        'distances': result['distances'].tolist(),\n",
    "        'avg_distance': float(result['avg_distance']),\n",
    "        'num_matches': int(result['num_matches'])\n",
    "    }\n",
    "\n",
    "with open(output_json, 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Risultati salvati in: {output_json}\")\n",
    "\n",
    "# Salva come NPZ (per uso in Python)\n",
    "output_npz = Path(OUTPUT_DIR) / \"matching_results.npz\"\n",
    "np.savez_compressed(output_npz, **matching_results)\n",
    "print(f\"üíæ Risultati salvati in: {output_npz}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a139f05",
   "metadata": {},
   "source": [
    "## 7. Visualizzazione (Opzionale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6619279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribuzione distanze\n",
    "if matching_results:\n",
    "    all_distances = []\n",
    "    for result in matching_results.values():\n",
    "        all_distances.extend(result['distances'].tolist())\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Istogramma\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(all_distances, bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Cosine Distance', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.title('Distribuzione delle Distanze di Matching', fontsize=14)\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Distanze medie per video\n",
    "    plt.subplot(1, 2, 2)\n",
    "    video_ids = list(matching_results.keys())\n",
    "    avg_dists = [matching_results[vid]['avg_distance'] for vid in video_ids]\n",
    "    \n",
    "    plt.bar(range(len(avg_dists)), avg_dists, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Video Index', fontsize=12)\n",
    "    plt.ylabel('Average Distance', fontsize=12)\n",
    "    plt.title('Distanza Media per Video', fontsize=14)\n",
    "    plt.axhline(np.mean(avg_dists), color='red', linestyle='--', \n",
    "                label=f'Media: {np.mean(avg_dists):.3f}')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva plot\n",
    "    plot_path = Path(OUTPUT_DIR) / 'matching_distances.png'\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"üíæ Plot salvato in: {plot_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nessun risultato da visualizzare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381863f0",
   "metadata": {},
   "source": [
    "## 8. Esempio di Analisi Dettagliata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizza un esempio specifico\n",
    "if matching_results:\n",
    "    # Prendi il primo risultato\n",
    "    example_video_id = list(matching_results.keys())[0]\n",
    "    result = matching_results[example_video_id]\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ESEMPIO DI MATCHING: {example_video_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Text ID matched: {result['text_id']}\")\n",
    "    print(f\"Numero di matches: {result['num_matches']}\")\n",
    "    print(f\"Distanza media: {result['avg_distance']:.4f}\\n\")\n",
    "    \n",
    "    print(f\"{'Video Step':<15} {'Text Step':<15} {'Distance':<12}\")\n",
    "    print(f\"{'-'*45}\")\n",
    "    \n",
    "    for vid_idx, txt_idx, dist in zip(\n",
    "        result['video_indices'][:10],  # Mostra solo i primi 10\n",
    "        result['text_indices'][:10],\n",
    "        result['distances'][:10]\n",
    "    ):\n",
    "        print(f\"{vid_idx:<15} {txt_idx:<15} {dist:<12.4f}\")\n",
    "    \n",
    "    if result['num_matches'] > 10:\n",
    "        print(f\"... (altri {result['num_matches'] - 10} matches)\")\n",
    "    \n",
    "    # Plot matrice di costo per questo esempio\n",
    "    vid_feats = video_features[example_video_id]\n",
    "    txt_feats = text_features[result['text_id']]\n",
    "    \n",
    "    # Calcola matrice di costo\n",
    "    similarity = vid_feats @ txt_feats.T\n",
    "    cost_matrix = 1.0 - similarity\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cost_matrix, cmap='YlOrRd', aspect='auto')\n",
    "    \n",
    "    # Evidenzia i match ottimali\n",
    "    for vid_idx, txt_idx in zip(result['video_indices'], result['text_indices']):\n",
    "        plt.plot(txt_idx, vid_idx, 'b*', markersize=10, markeredgecolor='blue', markeredgewidth=2)\n",
    "    \n",
    "    plt.colorbar(label='Cosine Distance')\n",
    "    plt.xlabel('Text Step Index', fontsize=12)\n",
    "    plt.ylabel('Video Step Index', fontsize=12)\n",
    "    plt.title(f'Cost Matrix - {example_video_id}\\n(Blue stars = optimal matches)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    cost_matrix_path = Path(OUTPUT_DIR) / f'cost_matrix_{example_video_id}.png'\n",
    "    plt.savefig(cost_matrix_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\nüíæ Cost matrix salvata in: {cost_matrix_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nessun risultato disponibile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea7f63f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Istruzioni d'Uso\n",
    "\n",
    "### 1Ô∏è‚É£ Preparazione Dati\n",
    "\n",
    "Assicurati di avere:\n",
    "- **File ZIP con video features**: contiene file .npz con embeddings video step-level\n",
    "- **File ZIP con text features**: contiene file .npz con embeddings testuali dei task graph\n",
    "\n",
    "Ogni file .npz deve contenere almeno la chiave `'features'` con un array numpy.\n",
    "\n",
    "### 2Ô∏è‚É£ Configurazione\n",
    "\n",
    "Modifica la **cella 3** (Configurazione Path) e inserisci i percorsi corretti:\n",
    "\n",
    "```python\n",
    "# Per Colab\n",
    "VIDEO_FEATURES_ZIP = \"/content/drive/MyDrive/.../step_embeddings.zip\"\n",
    "TEXT_FEATURES_ZIP = \"/content/drive/MyDrive/.../text_embeddings.zip\"\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/.../hungarian_results\"\n",
    "\n",
    "# Per Locale\n",
    "VIDEO_FEATURES_ZIP = \"path/to/step_embeddings.zip\"\n",
    "TEXT_FEATURES_ZIP = \"path/to/text_embeddings.zip\"\n",
    "OUTPUT_DIR = \"path/to/output\"\n",
    "```\n",
    "\n",
    "### 3Ô∏è‚É£ Esecuzione\n",
    "\n",
    "Esegui tutte le celle in ordine. Il notebook:\n",
    "1. Carica le features dai file ZIP\n",
    "2. Normalizza le features (L2 normalization)\n",
    "3. Esegue Hungarian matching usando cosine distance\n",
    "4. Salva i risultati in JSON e NPZ\n",
    "5. Genera visualizzazioni\n",
    "\n",
    "### 4Ô∏è‚É£ Output\n",
    "\n",
    "I risultati vengono salvati in `OUTPUT_DIR`:\n",
    "- `matching_results.json`: risultati in formato leggibile\n",
    "- `matching_results.npz`: risultati in formato numpy (per Python)\n",
    "- `matching_distances.png`: grafici delle distanze\n",
    "- `cost_matrix_*.png`: matrici di costo per esempi specifici\n",
    "\n",
    "### üîç Cosa fa l'Hungarian Matching?\n",
    "\n",
    "L'algoritmo Ungherese risolve il problema di assegnamento ottimale tra:\n",
    "- **N video steps** (righe)\n",
    "- **M task graph nodes** (colonne)\n",
    "\n",
    "Trova l'accoppiamento 1-a-1 che **minimizza la distanza coseno totale**.\n",
    "\n",
    "**Cosine Distance** = 1 - Cosine Similarity  \n",
    "(pi√π basso = pi√π simili)\n",
    "\n",
    "### ‚ö° Note Importanti\n",
    "\n",
    "- Le features sono **normalizzate L2** automaticamente\n",
    "- I file vengono matchati per **nome**: il nome del video deve contenere l'ID della ricetta\n",
    "- Se non trovi match, controlla la convenzione di naming dei tuoi file .npz"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
